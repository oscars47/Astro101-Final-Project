{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File to implement nn with wandb\n",
    "(note that we can't run wandb in terminal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-18 04:45:40.620608: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-18 04:45:40.690566: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-18 04:45:40.692276: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-18 04:45:40.692282: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-11-18 04:45:40.940585: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-18 04:45:40.940616: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-18 04:45:40.940618: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-18 04:45:41.565993: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-18 04:45:41.566456: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-18 04:45:41.566478: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-11-18 04:45:41.566493: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-11-18 04:45:41.566508: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-11-18 04:45:41.566523: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-11-18 04:45:41.566536: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-11-18 04:45:41.566549: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-11-18 04:45:41.566562: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-11-18 04:45:41.566566: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33moscarscholin\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_044542-2bk9pzob</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/2bk9pzob\" target=\"_blank\">chocolate-wind-1</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Malformed sweep config detected! This may cause your sweep to behave in unexpected ways.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m To avoid this, please fix the sweep config schema violations below:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m   Violation 1. Additional properties are not allowed ('goal' was unexpected)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m   Violation 2. 'val_accuracy' is not of type 'object'\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: jp6ffgsr\n",
      "Sweep URL: https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Waiting for W&B process to finish... (success).\n",
      "wandb: Synced chocolate-wind-1: https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/2bk9pzob\n",
      "wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "wandb: Find logs at: ./wandb/run-20221118_044542-2bk9pzob/logs\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: o2j2quim with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1886337325733656\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 41\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.04671489595440448\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 238\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 182\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 209\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 162\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_044555-o2j2quim</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/o2j2quim\" target=\"_blank\">happy-sweep-1</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-18 04:45:59.605961: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/41\n",
      "1505/1527 [============================>.] - ETA: 0s - loss: 173.9023INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_044555-o2j2quim/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_044555-o2j2quim/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 4s 2ms/step - loss: 171.4386 - val_loss: 0.8265\n",
      "Epoch 2/41\n",
      "1526/1527 [============================>.] - ETA: 0s - loss: 0.8970INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_044555-o2j2quim/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_044555-o2j2quim/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.8969 - val_loss: 0.8093\n",
      "Epoch 3/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 16084233.0000 - val_loss: 135869440.0000\n",
      "Epoch 4/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 783053.6875 - val_loss: 66184.6797\n",
      "Epoch 5/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 35002.7734 - val_loss: 9758.3955\n",
      "Epoch 6/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 14502.5322 - val_loss: 6026.7856\n",
      "Epoch 7/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 7930953.5000 - val_loss: 39818.8125\n",
      "Epoch 8/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 34942.1758 - val_loss: 9394.0322\n",
      "Epoch 9/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 13231.7080 - val_loss: 5335.3818\n",
      "Epoch 10/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 6084.6099 - val_loss: 2376.6833\n",
      "Epoch 11/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 2899.0608 - val_loss: 1457.4109\n",
      "Epoch 12/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1283.4584 - val_loss: 548.0749\n",
      "Epoch 13/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 19427192.0000 - val_loss: 69436.2969\n",
      "Epoch 14/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 63726.5859 - val_loss: 30404.8281\n",
      "Epoch 15/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 30872.0098 - val_loss: 10119.2158\n",
      "Epoch 16/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 14572.3984 - val_loss: 6774.0933\n",
      "Epoch 17/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 48635716.0000 - val_loss: 467995.9688\n",
      "Epoch 18/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 231979.3750 - val_loss: 241044.6250\n",
      "Epoch 19/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 89311.6641 - val_loss: 32465.7148\n",
      "Epoch 20/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 14795392.0000 - val_loss: 1732714.0000\n",
      "Epoch 21/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 283173.1250 - val_loss: 76046.6875\n",
      "Epoch 22/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 56149.9727 - val_loss: 25516.9180\n",
      "Epoch 23/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 26178.3066 - val_loss: 11322.8867\n",
      "Epoch 24/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 11173.5156 - val_loss: 3789.2888\n",
      "Epoch 25/41\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 5551.2246 - val_loss: 3556.8782\n",
      "Epoch 26/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 8711004.0000 - val_loss: 45265.4727\n",
      "Epoch 27/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 42362.7812 - val_loss: 14093.4883\n",
      "Epoch 28/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 19174.4551 - val_loss: 8411.4697\n",
      "Epoch 29/41\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 9252.5664 - val_loss: 4619.8955\n",
      "Epoch 30/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 5343.7305 - val_loss: 2110.0767\n",
      "Epoch 31/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 15241949.0000 - val_loss: 74798.5156\n",
      "Epoch 32/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 107525.6953 - val_loss: 31945.2539\n",
      "Epoch 33/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 26585.8652 - val_loss: 15103.7568\n",
      "Epoch 34/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 16067.7705 - val_loss: 6451.0566\n",
      "Epoch 35/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 40771124.0000 - val_loss: 164989.6250\n",
      "Epoch 36/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 194429.9531 - val_loss: 60583.2148\n",
      "Epoch 37/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 82012.8672 - val_loss: 24562.4902\n",
      "Epoch 38/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 38275.5977 - val_loss: 14728.5850\n",
      "Epoch 39/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 23088.7305 - val_loss: 8583.3506\n",
      "Epoch 40/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 9602858.0000 - val_loss: 65518.2344\n",
      "Epoch 41/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 58108.7578 - val_loss: 25300.1855\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>loss</td><td>▁▁▃▁▁▁▂▁▁▁▁▁▄▁▁▁█▁▁▃▁▁▁▁▁▂▁▁▁▁▃▁▁▁▇▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>1</td></tr><tr><td>best_val_loss</td><td>0.80926</td></tr><tr><td>epoch</td><td>40</td></tr><tr><td>loss</td><td>58108.75781</td></tr><tr><td>val_loss</td><td>25300.18555</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">happy-sweep-1</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/o2j2quim\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/o2j2quim</a><br/>Synced 6 W&B file(s), 1 media file(s), 9 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_044555-o2j2quim/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 59c6b36l with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3117500134534999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 56\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.09304974678359436\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 219\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 114\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 180\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 167\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_044757-59c6b36l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/59c6b36l\" target=\"_blank\">sleek-sweep-2</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/56\n",
      "4575/4581 [============================>.] - ETA: 0s - loss: 6778.1860INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_044757-59c6b36l/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_044757-59c6b36l/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4581/4581 [==============================] - 6s 1ms/step - loss: 6770.4668 - val_loss: 1.2212\n",
      "Epoch 2/56\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 719211968.0000 - val_loss: 795955.0000\n",
      "Epoch 3/56\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 861189248.0000 - val_loss: 6667064.0000\n",
      "Epoch 4/56\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 4604330.0000 - val_loss: 719708.3750\n",
      "Epoch 5/56\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1617913728.0000 - val_loss: 16377178.0000\n",
      "Epoch 6/56\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 144902784.0000 - val_loss: 1960391.7500\n",
      "Epoch 7/56\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 907863.2500 - val_loss: 194037.8594\n",
      "Epoch 8/56\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 889338752.0000 - val_loss: 4170996.0000\n",
      "Epoch 9/56\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 667471872.0000 - val_loss: 17483484.0000\n",
      "Epoch 10/56\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 6644549.5000 - val_loss: 1666635.3750\n",
      "Epoch 11/56\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 705862528.0000 - val_loss: 5455506.0000\n",
      "Epoch 12/56\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 4371091.5000 - val_loss: 925423.1875\n",
      "Epoch 13/56\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1280233472.0000 - val_loss: 10431869.0000\n",
      "Epoch 14/56\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 4940960.0000 - val_loss: 3160455.2500\n",
      "Epoch 15/56\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1034607424.0000 - val_loss: 5780810.0000\n",
      "Epoch 16/56\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 3080834.5000 - val_loss: 1479103.5000\n",
      "Epoch 17/56\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 724171136.0000 - val_loss: 3286369.5000\n",
      "Epoch 18/56\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 3063564.0000 - val_loss: 1206831.6250\n",
      "Epoch 19/56\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 649146240.0000 - val_loss: 3585251.7500\n",
      "Epoch 20/56\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 2798717.0000 - val_loss: 761580.5000\n",
      "Epoch 21/56\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 666094336.0000 - val_loss: 10107219.0000\n",
      "Epoch 22/56\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 5529076.0000 - val_loss: 3070843.5000\n",
      "Epoch 23/56\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1047865792.0000 - val_loss: 15062559.0000\n",
      "Epoch 24/56\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 4825182.5000 - val_loss: 840045.3750\n",
      "Epoch 25/56\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 841490176.0000 - val_loss: 6041495.0000\n",
      "Epoch 26/56\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 5373226.5000 - val_loss: 1406017.2500\n",
      "Epoch 27/56\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1077042176.0000 - val_loss: 8589165.0000\n",
      "Epoch 28/56\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1482624128.0000 - val_loss: 34525644.0000\n",
      "Epoch 29/56\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 14751190.0000 - val_loss: 2925888.0000\n",
      "Epoch 30/56\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1507266944.0000 - val_loss: 14850447.0000\n",
      "Epoch 31/56\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 15599638.0000 - val_loss: 4881452.0000\n",
      "Epoch 32/56\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 3237464.7500 - val_loss: 467846.5312\n",
      "Epoch 33/56\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1596709504.0000 - val_loss: 5873069.0000\n",
      "Epoch 34/56\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 2384662272.0000 - val_loss: 123488712.0000\n",
      "Epoch 35/56\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 39212224.0000 - val_loss: 7354930.0000\n",
      "Epoch 36/56\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 996415232.0000 - val_loss: 17290000.0000\n",
      "Epoch 37/56\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 696119424.0000 - val_loss: 22635620.0000\n",
      "Epoch 38/56\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 9630742.0000 - val_loss: 3677673.2500\n",
      "Epoch 39/56\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 580553920.0000 - val_loss: 7878082.0000\n",
      "Epoch 40/56\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 4515049.5000 - val_loss: 1693596.3750\n",
      "Epoch 41/56\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1164374272.0000 - val_loss: 15106100.0000\n",
      "Epoch 42/56\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 5994144.0000 - val_loss: 7525073.5000\n",
      "Epoch 43/56\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1733173248.0000 - val_loss: 18116754.0000\n",
      "Epoch 44/56\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 12215690.0000 - val_loss: 3201597.5000\n",
      "Epoch 45/56\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2297540096.0000 - val_loss: 11871776.0000\n",
      "Epoch 46/56\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2213509888.0000 - val_loss: 45857992.0000\n",
      "Epoch 47/56\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 26287226.0000 - val_loss: 4694128.0000\n",
      "Epoch 48/56\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1315390336.0000 - val_loss: 20952104.0000\n",
      "Epoch 49/56\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 11372185.0000 - val_loss: 2111816.7500\n",
      "Epoch 50/56\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1657541504.0000 - val_loss: 16078400.0000\n",
      "Epoch 51/56\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 274237184.0000 - val_loss: 4803884.0000\n",
      "Epoch 52/56\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 3069369.7500 - val_loss: 1565937.6250\n",
      "Epoch 53/56\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 668538624.0000 - val_loss: 4707150.0000\n",
      "Epoch 54/56\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 484723680.0000 - val_loss: 15693636.0000\n",
      "Epoch 55/56\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 7447294.5000 - val_loss: 2273539.0000\n",
      "Epoch 56/56\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1266029312.0000 - val_loss: 31049930.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▃▄▆▁▄▃▁▁▅▄▁▃▃▁▁▄▁▁▄▁▅▁▆█▄▃▃▁▄▆▁▇▁▅▆▂▃▂▅</td></tr><tr><td>val_loss</td><td>▁▁▁▂▁▁▂▁▁▂▁▁▁▁▁▁▂▁▁▁▁▂▁▁█▂▂▁▁▂▂▁▄▁▂▂▁▁▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>1.22123</td></tr><tr><td>epoch</td><td>55</td></tr><tr><td>loss</td><td>1266029312.0</td></tr><tr><td>val_loss</td><td>31049930.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">sleek-sweep-2</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/59c6b36l\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/59c6b36l</a><br/>Synced 6 W&B file(s), 1 media file(s), 5 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_044757-59c6b36l/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: za51dqqo with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4169094250554108\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 77\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.03422459031667951\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 215\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 186\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 161\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_045321-za51dqqo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/za51dqqo\" target=\"_blank\">true-sweep-3</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/77\n",
      "2279/2291 [============================>.] - ETA: 0s - loss: 2.1559INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_045321-za51dqqo/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_045321-za51dqqo/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 2.1501 - val_loss: 0.8684\n",
      "Epoch 2/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 850593.6250 - val_loss: 38546.7031\n",
      "Epoch 3/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 8844.4873 - val_loss: 1104.1523\n",
      "Epoch 4/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1207.4867 - val_loss: 398.0194\n",
      "Epoch 5/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 445.8142 - val_loss: 108.1260\n",
      "Epoch 6/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 532448.0625 - val_loss: 1761.2859\n",
      "Epoch 7/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1430.7056 - val_loss: 629.4246\n",
      "Epoch 8/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 512.7289 - val_loss: 137.4579\n",
      "Epoch 9/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 289829.4688 - val_loss: 2277.9731\n",
      "Epoch 10/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1767.4486 - val_loss: 761.9378\n",
      "Epoch 11/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 566.2686 - val_loss: 240.5997\n",
      "Epoch 12/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 191.6160 - val_loss: 70.2678\n",
      "Epoch 13/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 814748.8125 - val_loss: 3420.7610\n",
      "Epoch 14/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3141.1484 - val_loss: 825.4132\n",
      "Epoch 15/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 536894.2500 - val_loss: 17257.8457\n",
      "Epoch 16/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 6628.4033 - val_loss: 2510.7480\n",
      "Epoch 17/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1902.2141 - val_loss: 672.8657\n",
      "Epoch 18/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 629.4243 - val_loss: 226.5355\n",
      "Epoch 19/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 384779.4688 - val_loss: 2640.5146\n",
      "Epoch 20/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1563.9067 - val_loss: 596.0157\n",
      "Epoch 21/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 520.4415 - val_loss: 162.4560\n",
      "Epoch 22/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 748149.2500 - val_loss: 6389.9463\n",
      "Epoch 23/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 5347.7144 - val_loss: 1814.2247\n",
      "Epoch 24/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1944.5447 - val_loss: 1042.7307\n",
      "Epoch 25/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 959.4571 - val_loss: 521.2864\n",
      "Epoch 26/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 566475.5000 - val_loss: 3071.4602\n",
      "Epoch 27/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3456.9304 - val_loss: 1160.3241\n",
      "Epoch 28/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1196.6759 - val_loss: 819.3689\n",
      "Epoch 29/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 501.4382 - val_loss: 837.8098\n",
      "Epoch 30/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 714614.7500 - val_loss: 9064.0664\n",
      "Epoch 31/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 6074.4106 - val_loss: 3362.5535\n",
      "Epoch 32/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1793.1343 - val_loss: 835.6683\n",
      "Epoch 33/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 498685.4375 - val_loss: 7173.6470\n",
      "Epoch 34/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 5022.6846 - val_loss: 1781.5061\n",
      "Epoch 35/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1614.1478 - val_loss: 809.0101\n",
      "Epoch 36/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 503.3406 - val_loss: 192.3177\n",
      "Epoch 37/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 171.8699 - val_loss: 145.9276\n",
      "Epoch 38/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 193104.6875 - val_loss: 1836.0952\n",
      "Epoch 39/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 900.2310 - val_loss: 410.4008\n",
      "Epoch 40/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 369.5728 - val_loss: 210.2136\n",
      "Epoch 41/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 383528.5312 - val_loss: 2814.3882\n",
      "Epoch 42/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2167.1650 - val_loss: 734.3296\n",
      "Epoch 43/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 818.4882 - val_loss: 550.5284\n",
      "Epoch 44/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 305.5876 - val_loss: 204.9013\n",
      "Epoch 45/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 541075.7500 - val_loss: 20186.6113\n",
      "Epoch 46/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 4844.2012 - val_loss: 1600.9987\n",
      "Epoch 47/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1497.5267 - val_loss: 486.4709\n",
      "Epoch 48/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 582.0904 - val_loss: 174.1990\n",
      "Epoch 49/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 479758.7500 - val_loss: 6330.6519\n",
      "Epoch 50/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 5124.0996 - val_loss: 2472.3962\n",
      "Epoch 51/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1534.8889 - val_loss: 576.3607\n",
      "Epoch 52/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 425159.6562 - val_loss: 17652.7871\n",
      "Epoch 53/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 5166.5034 - val_loss: 2002.3546\n",
      "Epoch 54/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1447.1814 - val_loss: 543.0107\n",
      "Epoch 55/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 497.7388 - val_loss: 764.0718\n",
      "Epoch 56/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 556158.5625 - val_loss: 7409.9624\n",
      "Epoch 57/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3970.8401 - val_loss: 1742.1099\n",
      "Epoch 58/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1480.2819 - val_loss: 797.6782\n",
      "Epoch 59/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 402091.9375 - val_loss: 2114.6555\n",
      "Epoch 60/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2423.7207 - val_loss: 954.3256\n",
      "Epoch 61/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 862.4827 - val_loss: 366.4359\n",
      "Epoch 62/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 611631.6250 - val_loss: 39027.9180\n",
      "Epoch 63/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 10775.3516 - val_loss: 4378.4478\n",
      "Epoch 64/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2409.8445 - val_loss: 1409.9465\n",
      "Epoch 65/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 898.2095 - val_loss: 404.2916\n",
      "Epoch 66/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 536336.6875 - val_loss: 5573.3047\n",
      "Epoch 67/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 4019.5486 - val_loss: 1280.4264\n",
      "Epoch 68/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1321.6530 - val_loss: 492.3528\n",
      "Epoch 69/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 680832.1250 - val_loss: 20526.3594\n",
      "Epoch 70/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 8107.7070 - val_loss: 2318.2747\n",
      "Epoch 71/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2530.9253 - val_loss: 2177.1858\n",
      "Epoch 72/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1027.3899 - val_loss: 324.1656\n",
      "Epoch 73/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 644214.6250 - val_loss: 9548.5879\n",
      "Epoch 74/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 6786.3354 - val_loss: 1721.9426\n",
      "Epoch 75/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 340768.6562 - val_loss: 3778.1819\n",
      "Epoch 76/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2622.5103 - val_loss: 992.0536\n",
      "Epoch 77/77\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 582764.5000 - val_loss: 20049.3438\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁█▁▅▁▁▁▁▁▁▁▇▁▆▁▇▁▁▁▃▁▄▁▅▁▅▁▁▁▁▄▁▁▁▁▇▁▆▄▆</td></tr><tr><td>val_loss</td><td>▁█▁▁▁▁▁▁▁▁▁▂▁▂▁▃▁▁▁▁▁▂▁▅▁▂▁▁▁▁▁▁▂▁▁▅▁▃▂▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.86836</td></tr><tr><td>epoch</td><td>76</td></tr><tr><td>loss</td><td>582764.5</td></tr><tr><td>val_loss</td><td>20049.34375</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">true-sweep-3</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/za51dqqo\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/za51dqqo</a><br/>Synced 6 W&B file(s), 1 media file(s), 5 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_045321-za51dqqo/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pel3rtzp with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5637498650294573\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 53\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.05854011594612496\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 90\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 212\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 245\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 155\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_045747-pel3rtzp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/pel3rtzp\" target=\"_blank\">volcanic-sweep-4</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/53\n",
      "2285/2291 [============================>.] - ETA: 0s - loss: 107.0755INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_045747-pel3rtzp/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_045747-pel3rtzp/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 106.8386 - val_loss: 0.7987\n",
      "Epoch 2/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 17459838.0000 - val_loss: 30041.0254\n",
      "Epoch 3/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 29711.9531 - val_loss: 17879.5273\n",
      "Epoch 4/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 9584.6592 - val_loss: 3880.2126\n",
      "Epoch 5/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 58671676.0000 - val_loss: 1936512.3750\n",
      "Epoch 6/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 666124.9375 - val_loss: 106330.7969\n",
      "Epoch 7/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 127885.6094 - val_loss: 70168.9141\n",
      "Epoch 8/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 39970.5117 - val_loss: 9004.5283\n",
      "Epoch 9/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 18976440.0000 - val_loss: 302279.8438\n",
      "Epoch 10/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 190358.3906 - val_loss: 51915.9414\n",
      "Epoch 11/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 48709.3398 - val_loss: 17983.7012\n",
      "Epoch 12/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 20392162.0000 - val_loss: 395523.6250\n",
      "Epoch 13/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 174314.8438 - val_loss: 80524.6250\n",
      "Epoch 14/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 49133.1445 - val_loss: 22174.4180\n",
      "Epoch 15/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 83245312.0000 - val_loss: 658209.0625\n",
      "Epoch 16/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 490787.9688 - val_loss: 175855.7031\n",
      "Epoch 17/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 153837.8750 - val_loss: 64732.6133\n",
      "Epoch 18/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 21112972.0000 - val_loss: 134056.1250\n",
      "Epoch 19/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 117132.8672 - val_loss: 36700.7617\n",
      "Epoch 20/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 39883.7227 - val_loss: 19193.2578\n",
      "Epoch 21/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 16063.1543 - val_loss: 8150.6592\n",
      "Epoch 22/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 42900532.0000 - val_loss: 279436.2188\n",
      "Epoch 23/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 283026.8125 - val_loss: 76478.5156\n",
      "Epoch 24/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 78046.0859 - val_loss: 19742.2402\n",
      "Epoch 25/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 26318.3359 - val_loss: 10741.0371\n",
      "Epoch 26/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 96776656.0000 - val_loss: 1001798.3125\n",
      "Epoch 27/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 663817.1875 - val_loss: 207720.5000\n",
      "Epoch 28/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 217549.5000 - val_loss: 86222.2344\n",
      "Epoch 29/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 75851.9766 - val_loss: 42831.2344\n",
      "Epoch 30/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 47754096.0000 - val_loss: 296152.2500\n",
      "Epoch 31/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 313411.5312 - val_loss: 120622.1406\n",
      "Epoch 32/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 104864.3984 - val_loss: 29690.3086\n",
      "Epoch 33/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 34415824.0000 - val_loss: 410339872.0000\n",
      "Epoch 34/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 19916250.0000 - val_loss: 189948.5469\n",
      "Epoch 35/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 216438.5625 - val_loss: 104139.9531\n",
      "Epoch 36/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 90026.5938 - val_loss: 42730.4102\n",
      "Epoch 37/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 41974.0664 - val_loss: 11144.4131\n",
      "Epoch 38/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 47694000.0000 - val_loss: 1549139.3750\n",
      "Epoch 39/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 501697.4688 - val_loss: 175763.8750\n",
      "Epoch 40/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 153311.0938 - val_loss: 59344.7656\n",
      "Epoch 41/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 63729.2891 - val_loss: 23750.9980\n",
      "Epoch 42/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 23387.8516 - val_loss: 15548.3037\n",
      "Epoch 43/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 70409864.0000 - val_loss: 531252.1875\n",
      "Epoch 44/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 396561.1250 - val_loss: 98936.7656\n",
      "Epoch 45/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 130083.6562 - val_loss: 58656.5859\n",
      "Epoch 46/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 19669626.0000 - val_loss: 120692.7031\n",
      "Epoch 47/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 124883.4141 - val_loss: 40168.5391\n",
      "Epoch 48/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 45743.3008 - val_loss: 29417.8066\n",
      "Epoch 49/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 21113.2832 - val_loss: 7581.7905\n",
      "Epoch 50/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 105375104.0000 - val_loss: 247976.8281\n",
      "Epoch 51/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 345994.3438 - val_loss: 167922.3750\n",
      "Epoch 52/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 130160.4219 - val_loss: 48688.3320\n",
      "Epoch 53/53\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 22842124.0000 - val_loss: 1643485.3750\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▂▁▅▁▁▂▁▁▁▁▇▁▂▁▁▄▁▁▇▁▁▄▁▃▂▁▁▄▁▁▁▆▁▂▁▁█▁▃</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.79872</td></tr><tr><td>epoch</td><td>52</td></tr><tr><td>loss</td><td>22842124.0</td></tr><tr><td>val_loss</td><td>1643485.375</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">volcanic-sweep-4</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/pel3rtzp\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/pel3rtzp</a><br/>Synced 6 W&B file(s), 1 media file(s), 5 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_045747-pel3rtzp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: b9jyowkm with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1576223949775966\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 37\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.03938954339049375\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 148\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 204\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 220\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 170\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_050052-b9jyowkm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/b9jyowkm\" target=\"_blank\">fearless-sweep-5</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/37\n",
      "1521/1527 [============================>.] - ETA: 0s - loss: 12.1617INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_050052-b9jyowkm/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_050052-b9jyowkm/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 3s 2ms/step - loss: 12.1191 - val_loss: 0.7656\n",
      "Epoch 2/37\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 0.7952 - val_loss: 0.7912\n",
      "Epoch 3/37\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.7964 - val_loss: 0.7913\n",
      "Epoch 4/37\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.8024 - val_loss: 0.8023\n",
      "Epoch 5/37\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.8373 - val_loss: 0.8438\n",
      "Epoch 6/37\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 9723215.0000 - val_loss: 133663.7812\n",
      "Epoch 7/37\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 27946.5371 - val_loss: 10592.7529\n",
      "Epoch 8/37\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 12036.4678 - val_loss: 3385.8196\n",
      "Epoch 9/37\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 7732.5073 - val_loss: 1653.3790\n",
      "Epoch 10/37\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1364.6190 - val_loss: 505.9409\n",
      "Epoch 11/37\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 944.9318 - val_loss: 1295.4958\n",
      "Epoch 12/37\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 254.9692 - val_loss: 113.1430\n",
      "Epoch 13/37\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 4350531.0000 - val_loss: 87551.2578\n",
      "Epoch 14/37\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 28436.5020 - val_loss: 8722.0225\n",
      "Epoch 15/37\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 9164.6406 - val_loss: 3304.5229\n",
      "Epoch 16/37\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 3970.4243 - val_loss: 2666.2512\n",
      "Epoch 17/37\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 3142.6387 - val_loss: 1005.6060\n",
      "Epoch 18/37\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 848.4293 - val_loss: 2242.6829\n",
      "Epoch 19/37\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 5195008.5000 - val_loss: 37880.0547\n",
      "Epoch 20/37\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 20072.9258 - val_loss: 11918.9473\n",
      "Epoch 21/37\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 9291.3740 - val_loss: 4339.7998\n",
      "Epoch 22/37\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 4304.8442 - val_loss: 2197.3586\n",
      "Epoch 23/37\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 2229.9570 - val_loss: 826.1364\n",
      "Epoch 24/37\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 6391422.0000 - val_loss: 27468.4434\n",
      "Epoch 25/37\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 27130.0293 - val_loss: 12757.7168\n",
      "Epoch 26/37\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 13405.3535 - val_loss: 8371.6641\n",
      "Epoch 27/37\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 6322.1118 - val_loss: 3023.0488\n",
      "Epoch 28/37\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 3214.3040 - val_loss: 2331.5417\n",
      "Epoch 29/37\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 5739900.0000 - val_loss: 42274.6406\n",
      "Epoch 30/37\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 39654.3164 - val_loss: 10564.5000\n",
      "Epoch 31/37\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 16542.5391 - val_loss: 11336.0918\n",
      "Epoch 32/37\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 9543.9727 - val_loss: 2841.3845\n",
      "Epoch 33/37\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 3494.4773 - val_loss: 1190.8927\n",
      "Epoch 34/37\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 3107276.5000 - val_loss: 22040.0684\n",
      "Epoch 35/37\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 13104.9043 - val_loss: 7537.5771\n",
      "Epoch 36/37\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 6696.6118 - val_loss: 3487.8721\n",
      "Epoch 37/37\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 3731.6541 - val_loss: 2946.1680\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▁▁▁█▁▁▁▁▁▁▄▁▁▁▁▁▅▁▁▁▁▆▁▁▁▁▅▁▁▁▁▃▁▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁█▂▁▁▁▁▁▆▁▁▁▁▁▃▂▁▁▁▂▂▁▁▁▃▂▂▁▁▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.76557</td></tr><tr><td>epoch</td><td>36</td></tr><tr><td>loss</td><td>3731.65405</td></tr><tr><td>val_loss</td><td>2946.16797</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">fearless-sweep-5</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/b9jyowkm\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/b9jyowkm</a><br/>Synced 6 W&B file(s), 1 media file(s), 5 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_050052-b9jyowkm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4v9splo0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5709814724183551\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 45\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.05909337755842904\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 194\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 129\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 162\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 145\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_050240-4v9splo0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/4v9splo0\" target=\"_blank\">celestial-sweep-6</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n",
      "1499/1527 [============================>.] - ETA: 0s - loss: 484.4446INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_050240-4v9splo0/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_050240-4v9splo0/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 4s 2ms/step - loss: 475.6643 - val_loss: 0.9666\n",
      "Epoch 2/45\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 77188544.0000 - val_loss: 170060.6094\n",
      "Epoch 3/45\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 225826.4062 - val_loss: 70019.7969\n",
      "Epoch 4/45\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 87839.1328 - val_loss: 34903.9727\n",
      "Epoch 5/45\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 39279.7188 - val_loss: 22201.3145\n",
      "Epoch 6/45\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 19168.2852 - val_loss: 8116.4146\n",
      "Epoch 7/45\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 66290964.0000 - val_loss: 15609029.0000\n",
      "Epoch 8/45\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 721796.2500 - val_loss: 179685.1094\n",
      "Epoch 9/45\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 142349.7031 - val_loss: 56879.2578\n",
      "Epoch 10/45\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 66608.6094 - val_loss: 26937.0508\n",
      "Epoch 11/45\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 31052.7637 - val_loss: 10456.9502\n",
      "Epoch 12/45\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 78092992.0000 - val_loss: 326176.9062\n",
      "Epoch 13/45\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 430248.3750 - val_loss: 106372.3594\n",
      "Epoch 14/45\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 188677.3125 - val_loss: 61064.6641\n",
      "Epoch 15/45\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 86941.3828 - val_loss: 28287.0645\n",
      "Epoch 16/45\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 39469.1211 - val_loss: 14700.8896\n",
      "Epoch 17/45\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 68281496.0000 - val_loss: 456043.6562\n",
      "Epoch 18/45\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 284985.6250 - val_loss: 94758.2969\n",
      "Epoch 19/45\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 128525.5078 - val_loss: 36008.5977\n",
      "Epoch 20/45\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 50270.9297 - val_loss: 32071.6426\n",
      "Epoch 21/45\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 98525208.0000 - val_loss: 1484685.3750\n",
      "Epoch 22/45\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1094732.0000 - val_loss: 278882.0625\n",
      "Epoch 23/45\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 338083.5312 - val_loss: 109228.7109\n",
      "Epoch 24/45\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 156385.2656 - val_loss: 55094.3945\n",
      "Epoch 25/45\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 76054.9141 - val_loss: 25778.7070\n",
      "Epoch 26/45\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 39408.4219 - val_loss: 19955.3066\n",
      "Epoch 27/45\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 74723608.0000 - val_loss: 360549.0938\n",
      "Epoch 28/45\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 337234.7812 - val_loss: 125931.9922\n",
      "Epoch 29/45\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 148118.5781 - val_loss: 65058.4922\n",
      "Epoch 30/45\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 85945.0156 - val_loss: 26938.4492\n",
      "Epoch 31/45\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 31820.7832 - val_loss: 19159.1465\n",
      "Epoch 32/45\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 70648968.0000 - val_loss: 405341.5625\n",
      "Epoch 33/45\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 422325.1562 - val_loss: 104691.3125\n",
      "Epoch 34/45\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 153642.4688 - val_loss: 52065.8438\n",
      "Epoch 35/45\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 68579.8125 - val_loss: 31293.3809\n",
      "Epoch 36/45\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 35359.5391 - val_loss: 12732.3701\n",
      "Epoch 37/45\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 17241.2578 - val_loss: 6643.1294\n",
      "Epoch 38/45\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 88413464.0000 - val_loss: 363787.0312\n",
      "Epoch 39/45\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 373941.5312 - val_loss: 154003.7969\n",
      "Epoch 40/45\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 170093.2344 - val_loss: 110498.9688\n",
      "Epoch 41/45\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 90318.7422 - val_loss: 54668.4062\n",
      "Epoch 42/45\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 55361108.0000 - val_loss: 777915.0000\n",
      "Epoch 43/45\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 619094.3125 - val_loss: 194729.5156\n",
      "Epoch 44/45\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 215562.8906 - val_loss: 85509.7266\n",
      "Epoch 45/45\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 115532.8281 - val_loss: 49413.0547\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▆▁▁▁▁▆▁▁▁▇▁▁▁▁▆▁▁█▁▁▁▁▁▁▁▁▁▆▁▁▁▁▇▁▁▁▅▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.96655</td></tr><tr><td>epoch</td><td>44</td></tr><tr><td>loss</td><td>115532.82812</td></tr><tr><td>val_loss</td><td>49413.05469</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">celestial-sweep-6</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/4v9splo0\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/4v9splo0</a><br/>Synced 6 W&B file(s), 1 media file(s), 5 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_050240-4v9splo0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7kc35ppi with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5244392171971292\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 40\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.03578200146392744\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 133\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 102\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 224\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_050458-7kc35ppi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/7kc35ppi\" target=\"_blank\">exalted-sweep-7</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "2284/2291 [============================>.] - ETA: 0s - loss: 2.7399INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_050458-7kc35ppi/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_050458-7kc35ppi/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 2.7345 - val_loss: 1.0024\n",
      "Epoch 2/40\n",
      "2252/2291 [============================>.] - ETA: 0s - loss: 0.8960INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_050458-7kc35ppi/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_050458-7kc35ppi/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 0.8973 - val_loss: 0.9704\n",
      "Epoch 3/40\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 502574.9375 - val_loss: 2349.8127\n",
      "Epoch 4/40\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1774.4872 - val_loss: 1040.0573\n",
      "Epoch 5/40\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 250369.3750 - val_loss: 2482.2295\n",
      "Epoch 6/40\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1020.7773 - val_loss: 624.4894\n",
      "Epoch 7/40\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 392.5331 - val_loss: 162.8301\n",
      "Epoch 8/40\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 143.0188 - val_loss: 49.2061\n",
      "Epoch 9/40\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 50.1995 - val_loss: 14.8912\n",
      "Epoch 10/40\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 498937.7188 - val_loss: 1773.6224\n",
      "Epoch 11/40\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1976.2365 - val_loss: 854.7191\n",
      "Epoch 12/40\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 629.7335 - val_loss: 284.5840\n",
      "Epoch 13/40\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 266807.3438 - val_loss: 1893.6593\n",
      "Epoch 14/40\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1371.1528 - val_loss: 615.9780\n",
      "Epoch 15/40\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 432.0390 - val_loss: 144.4333\n",
      "Epoch 16/40\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 167.0949 - val_loss: 68.1953\n",
      "Epoch 17/40\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 439913.9688 - val_loss: 2662.1377\n",
      "Epoch 18/40\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1980.1249 - val_loss: 911.9538\n",
      "Epoch 19/40\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 744.2713 - val_loss: 380.9061\n",
      "Epoch 20/40\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1121273.7500 - val_loss: 4907.5571\n",
      "Epoch 21/40\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 5412.9058 - val_loss: 2074.3767\n",
      "Epoch 22/40\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1761.6016 - val_loss: 556.7141\n",
      "Epoch 23/40\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 562186.0625 - val_loss: 4326.3716\n",
      "Epoch 24/40\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 4390.9805 - val_loss: 1507.7611\n",
      "Epoch 25/40\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1559.2067 - val_loss: 773.7390\n",
      "Epoch 26/40\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 645491.6875 - val_loss: 7397.9585\n",
      "Epoch 27/40\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 4743.0557 - val_loss: 1666.1139\n",
      "Epoch 28/40\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1767.5867 - val_loss: 580.7563\n",
      "Epoch 29/40\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 236536.2188 - val_loss: 6248.2827\n",
      "Epoch 30/40\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3069.8884 - val_loss: 1034.1415\n",
      "Epoch 31/40\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 884.2620 - val_loss: 475.1423\n",
      "Epoch 32/40\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 355.0001 - val_loss: 159.0623\n",
      "Epoch 33/40\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 447056.8125 - val_loss: 5502.3901\n",
      "Epoch 34/40\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3707.7837 - val_loss: 1055.2401\n",
      "Epoch 35/40\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1089.4634 - val_loss: 332.7907\n",
      "Epoch 36/40\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 395.8892 - val_loss: 215.2510\n",
      "Epoch 37/40\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 443033.1250 - val_loss: 4305.8477\n",
      "Epoch 38/40\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2797.4785 - val_loss: 1728.2628\n",
      "Epoch 39/40\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 968.5973 - val_loss: 333.2976\n",
      "Epoch 40/40\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 609200.4375 - val_loss: 11966.0635\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▄▁▃▁▁▁▁▄▁▁▃▁▁▁▄▁▁█▁▁▅▁▁▅▁▁▂▁▁▁▄▁▁▁▄▁▁▅</td></tr><tr><td>val_loss</td><td>▁▁▂▂▂▁▁▁▁▂▁▁▂▁▁▁▃▂▁▄▂▁▄▂▁▅▂▁▅▂▁▁▄▂▁▁▄▂▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>1</td></tr><tr><td>best_val_loss</td><td>0.97036</td></tr><tr><td>epoch</td><td>39</td></tr><tr><td>loss</td><td>609200.4375</td></tr><tr><td>val_loss</td><td>11966.06348</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">exalted-sweep-7</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/7kc35ppi\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/7kc35ppi</a><br/>Synced 6 W&B file(s), 1 media file(s), 9 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_050458-7kc35ppi/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: oc01zt09 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.04498864378057694\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 66\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.04267475985479122\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 187\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 93\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 65\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 249\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_050722-oc01zt09</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/oc01zt09\" target=\"_blank\">ancient-sweep-8</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/66\n",
      "4564/4581 [============================>.] - ETA: 0s - loss: 6.3430INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_050722-oc01zt09/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_050722-oc01zt09/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4581/4581 [==============================] - 6s 1ms/step - loss: 6.3236 - val_loss: 0.8490\n",
      "Epoch 2/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 961853.6875 - val_loss: 3576.6489\n",
      "Epoch 3/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2078.5835 - val_loss: 762.1087\n",
      "Epoch 4/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1403378.7500 - val_loss: 3454.7166\n",
      "Epoch 5/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 368533.9062 - val_loss: 4813.8770\n",
      "Epoch 6/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1708.9224 - val_loss: 472.6745\n",
      "Epoch 7/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 693072.4375 - val_loss: 2190.9185\n",
      "Epoch 8/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1395.7729 - val_loss: 160.6052\n",
      "Epoch 9/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1101201.2500 - val_loss: 8246.3145\n",
      "Epoch 10/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2851.8191 - val_loss: 979.8431\n",
      "Epoch 11/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1628832.7500 - val_loss: 9088.2910\n",
      "Epoch 12/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 4884.0303 - val_loss: 959.3303\n",
      "Epoch 13/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1725086.5000 - val_loss: 6780.0942\n",
      "Epoch 14/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 4322.2856 - val_loss: 1129.8732\n",
      "Epoch 15/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 4217340.5000 - val_loss: 8806.3428\n",
      "Epoch 16/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2325919.2500 - val_loss: 142172.5469\n",
      "Epoch 17/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 36145.7656 - val_loss: 8548.9199\n",
      "Epoch 18/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1191876.8750 - val_loss: 18642.0117\n",
      "Epoch 19/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 9918.1934 - val_loss: 6668.8477\n",
      "Epoch 20/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2687931.0000 - val_loss: 74033.1328\n",
      "Epoch 21/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 24157.1602 - val_loss: 6198.4028\n",
      "Epoch 22/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2179132.7500 - val_loss: 67781.5938\n",
      "Epoch 23/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 18557.9238 - val_loss: 7285.6553\n",
      "Epoch 24/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1835095.3750 - val_loss: 28392.4336\n",
      "Epoch 25/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 15602.2578 - val_loss: 6516.3667\n",
      "Epoch 26/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1484644.7500 - val_loss: 52778.3203\n",
      "Epoch 27/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 10610.0762 - val_loss: 2833.3921\n",
      "Epoch 28/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 3581.7893 - val_loss: 236.8649\n",
      "Epoch 29/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 845860.2500 - val_loss: 5275.7451\n",
      "Epoch 30/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1419254.8750 - val_loss: 41410.1680\n",
      "Epoch 31/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 16530.3438 - val_loss: 6098.3394\n",
      "Epoch 32/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1064310.8750 - val_loss: 15082.9736\n",
      "Epoch 33/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 7596.8022 - val_loss: 1591.6775\n",
      "Epoch 34/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1183399.6250 - val_loss: 9568.4092\n",
      "Epoch 35/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 5789.5610 - val_loss: 1769.5554\n",
      "Epoch 36/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1228727.0000 - val_loss: 7752.2300\n",
      "Epoch 37/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2991813.0000 - val_loss: 23205.0332\n",
      "Epoch 38/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 17847.6484 - val_loss: 4536.1133\n",
      "Epoch 39/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 447579.7812 - val_loss: 3387.4106\n",
      "Epoch 40/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1998.9755 - val_loss: 681.4995\n",
      "Epoch 41/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 3375952.5000 - val_loss: 19803.2246\n",
      "Epoch 42/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 9965.6973 - val_loss: 4012.0906\n",
      "Epoch 43/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1333403.5000 - val_loss: 8735.2520\n",
      "Epoch 44/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1499525.6250 - val_loss: 37556.6719\n",
      "Epoch 45/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 14387.5127 - val_loss: 5252.2837\n",
      "Epoch 46/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1117205.2500 - val_loss: 7612.7949\n",
      "Epoch 47/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1343866.2500 - val_loss: 57677.9492\n",
      "Epoch 48/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 14762.2939 - val_loss: 4710.1758\n",
      "Epoch 49/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1395449.5000 - val_loss: 30753.4160\n",
      "Epoch 50/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 10474.0645 - val_loss: 2859.8262\n",
      "Epoch 51/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1447640.8750 - val_loss: 20485.8320\n",
      "Epoch 52/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 12188.5713 - val_loss: 2906.3379\n",
      "Epoch 53/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1339803.0000 - val_loss: 41101.8867\n",
      "Epoch 54/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 17914.4082 - val_loss: 3849.5737\n",
      "Epoch 55/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1133255.2500 - val_loss: 6060.8008\n",
      "Epoch 56/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 4158.0742 - val_loss: 743.8702\n",
      "Epoch 57/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2649581.2500 - val_loss: 22097.0117\n",
      "Epoch 58/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1691980.8750 - val_loss: 23332.7285\n",
      "Epoch 59/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1140905.2500 - val_loss: 90853.6484\n",
      "Epoch 60/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 24964.5195 - val_loss: 6281.6357\n",
      "Epoch 61/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1279274.5000 - val_loss: 21818.5352\n",
      "Epoch 62/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 12746.5391 - val_loss: 6113.9263\n",
      "Epoch 63/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2740846.5000 - val_loss: 76034.3359\n",
      "Epoch 64/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 26819.7148 - val_loss: 5474.6284\n",
      "Epoch 65/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 3150634.2500 - val_loss: 42222.5273\n",
      "Epoch 66/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 21694.0781 - val_loss: 6134.1445\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▃▄▁▂▃▄▁▁▆▁▁▁▆▅▄▁▃▁▃▃▄▇▂█▁▄▃▄▄▄▁▁▁▆▃▄▁▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁█▁▁▁▄▂▄▁▁▁▂▁▁▂▁▂▁▃▁▄▃▂▁▁▁▂▅▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.84901</td></tr><tr><td>epoch</td><td>65</td></tr><tr><td>loss</td><td>21694.07812</td></tr><tr><td>val_loss</td><td>6134.14453</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">ancient-sweep-8</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/oc01zt09\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/oc01zt09</a><br/>Synced 6 W&B file(s), 1 media file(s), 5 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_050722-oc01zt09/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: k50p7ssl with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2834186136270899\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 38\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.08778625412096079\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 190\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 198\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 182\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 213\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_051312-k50p7ssl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/k50p7ssl\" target=\"_blank\">glorious-sweep-9</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/38\n",
      "2248/2291 [============================>.] - ETA: 0s - loss: 2687.6841INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_051312-k50p7ssl/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_051312-k50p7ssl/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 2638.3064 - val_loss: 2.9164\n",
      "Epoch 2/38\n",
      "2272/2291 [============================>.] - ETA: 0s - loss: 2.0058INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_051312-k50p7ssl/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_051312-k50p7ssl/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 5s 2ms/step - loss: 2.0010 - val_loss: 1.2623\n",
      "Epoch 3/38\n",
      "2282/2291 [============================>.] - ETA: 0s - loss: 1.1745INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_051312-k50p7ssl/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_051312-k50p7ssl/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1.1738 - val_loss: 0.9343\n",
      "Epoch 4/38\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 524374752.0000 - val_loss: 430900.7500\n",
      "Epoch 5/38\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 455864.8750 - val_loss: 130111.2812\n",
      "Epoch 6/38\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 157786.2500 - val_loss: 34079.6406\n",
      "Epoch 7/38\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 353860224.0000 - val_loss: 657685.7500\n",
      "Epoch 8/38\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 635165.6250 - val_loss: 237121.7031\n",
      "Epoch 9/38\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1449386624.0000 - val_loss: 155599088.0000\n",
      "Epoch 10/38\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 17500792.0000 - val_loss: 5061945.5000\n",
      "Epoch 11/38\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3511370.2500 - val_loss: 3799014.5000\n",
      "Epoch 12/38\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1120644.7500 - val_loss: 325090.7188\n",
      "Epoch 13/38\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 606498496.0000 - val_loss: 21866178.0000\n",
      "Epoch 14/38\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2646708.0000 - val_loss: 783294.7500\n",
      "Epoch 15/38\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 923889.8750 - val_loss: 568746.5625\n",
      "Epoch 16/38\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 522794784.0000 - val_loss: 1907362.1250\n",
      "Epoch 17/38\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1591388.2500 - val_loss: 560094.4375\n",
      "Epoch 18/38\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1222438656.0000 - val_loss: 18812704.0000\n",
      "Epoch 19/38\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 10250276.0000 - val_loss: 6138982.0000\n",
      "Epoch 20/38\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3049185.5000 - val_loss: 1243828.6250\n",
      "Epoch 21/38\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 898667712.0000 - val_loss: 39080700.0000\n",
      "Epoch 22/38\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 10909244.0000 - val_loss: 5260366.0000\n",
      "Epoch 23/38\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2964939.5000 - val_loss: 831815.1250\n",
      "Epoch 24/38\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1046421.2500 - val_loss: 473315.4375\n",
      "Epoch 25/38\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1522095872.0000 - val_loss: 20884922.0000\n",
      "Epoch 26/38\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 10665292.0000 - val_loss: 3654472.0000\n",
      "Epoch 27/38\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3578134.2500 - val_loss: 1254220.2500\n",
      "Epoch 28/38\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1461659.1250 - val_loss: 715116.2500\n",
      "Epoch 29/38\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1652817920.0000 - val_loss: 10289225.0000\n",
      "Epoch 30/38\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 6981166.0000 - val_loss: 4455787.0000\n",
      "Epoch 31/38\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 4787604.0000 - val_loss: 969574.8125\n",
      "Epoch 32/38\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2668767232.0000 - val_loss: 12957437.0000\n",
      "Epoch 33/38\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 9643785.0000 - val_loss: 3876530.2500\n",
      "Epoch 34/38\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 4102192.7500 - val_loss: 1780026.3750\n",
      "Epoch 35/38\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1605656.0000 - val_loss: 542459.5000\n",
      "Epoch 36/38\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1283834112.0000 - val_loss: 13805854.0000\n",
      "Epoch 37/38\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 6572878.5000 - val_loss: 5793643.5000\n",
      "Epoch 38/38\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 3005828.7500 - val_loss: 1629813.1250\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▁▂▁▁▂▁▅▁▁▁▃▁▁▂▁▄▁▁▃▁▁▁▅▁▁▁▅▁▁█▁▁▁▄▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁█▁▁▁▂▁▁▁▁▂▁▁▃▁▁▁▂▁▁▁▁▁▁▂▁▁▁▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>2</td></tr><tr><td>best_val_loss</td><td>0.93429</td></tr><tr><td>epoch</td><td>37</td></tr><tr><td>loss</td><td>3005828.75</td></tr><tr><td>val_loss</td><td>1629813.125</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">glorious-sweep-9</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/k50p7ssl\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/k50p7ssl</a><br/>Synced 6 W&B file(s), 1 media file(s), 13 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_051312-k50p7ssl/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: m3nn4ee6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.32096321432110836\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 37\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.029174512332356628\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 87\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 119\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 124\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 150\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 199\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_051539-m3nn4ee6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/m3nn4ee6\" target=\"_blank\">snowy-sweep-10</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/37\n",
      "2285/2291 [============================>.] - ETA: 0s - loss: 1.2248INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_051539-m3nn4ee6/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_051539-m3nn4ee6/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1.2239 - val_loss: 0.8881\n",
      "Epoch 2/37\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 122491.9766 - val_loss: 1237.2733\n",
      "Epoch 3/37\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 606.9609 - val_loss: 185.3711\n",
      "Epoch 4/37\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 174.5365 - val_loss: 59.9416\n",
      "Epoch 5/37\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 54.2229 - val_loss: 32.7179\n",
      "Epoch 6/37\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 164043.6094 - val_loss: 914.6762\n",
      "Epoch 7/37\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 638.3873 - val_loss: 963.0278\n",
      "Epoch 8/37\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 262.4387 - val_loss: 72.7398\n",
      "Epoch 9/37\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 67609.8672 - val_loss: 684.8679\n",
      "Epoch 10/37\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 440.3556 - val_loss: 170.2898\n",
      "Epoch 11/37\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 145.8562 - val_loss: 92.8473\n",
      "Epoch 12/37\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 49.2575 - val_loss: 17.8754\n",
      "Epoch 13/37\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 173668.3125 - val_loss: 518.1676\n",
      "Epoch 14/37\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 462.5190 - val_loss: 177.5495\n",
      "Epoch 15/37\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 174.4501 - val_loss: 68.6166\n",
      "Epoch 16/37\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 188248.2031 - val_loss: 1546.4679\n",
      "Epoch 17/37\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 986.8932 - val_loss: 274.2484\n",
      "Epoch 18/37\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 300.9054 - val_loss: 104.2078\n",
      "Epoch 19/37\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 160.7666 - val_loss: 28.8871\n",
      "Epoch 20/37\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 147633.5625 - val_loss: 1266.2573\n",
      "Epoch 21/37\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 745.9373 - val_loss: 312.3526\n",
      "Epoch 22/37\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 261.6870 - val_loss: 86.6556\n",
      "Epoch 23/37\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 110740.9609 - val_loss: 3565.7461\n",
      "Epoch 24/37\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1209.8040 - val_loss: 790.7283\n",
      "Epoch 25/37\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 395.9684 - val_loss: 141.1258\n",
      "Epoch 26/37\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 149.2661 - val_loss: 72.9772\n",
      "Epoch 27/37\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 61.6700 - val_loss: 18.3180\n",
      "Epoch 28/37\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 259845.8906 - val_loss: 1087.9702\n",
      "Epoch 29/37\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1108.7052 - val_loss: 539.0894\n",
      "Epoch 30/37\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 374.5029 - val_loss: 138.4227\n",
      "Epoch 31/37\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 200054.9219 - val_loss: 2435.4993\n",
      "Epoch 32/37\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1581.9651 - val_loss: 668.3948\n",
      "Epoch 33/37\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 553.8218 - val_loss: 397.2090\n",
      "Epoch 34/37\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 344259.1875 - val_loss: 8707.3936\n",
      "Epoch 35/37\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3024.0344 - val_loss: 1256.0023\n",
      "Epoch 36/37\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 940.9648 - val_loss: 479.0866\n",
      "Epoch 37/37\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1849.9435 - val_loss: 109.0429\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▃▁▁▁▄▁▁▂▁▁▁▅▁▁▅▁▁▁▄▁▁▃▁▁▁▁▆▁▁▅▁▁█▁▁▁</td></tr><tr><td>val_loss</td><td>▁▂▁▁▁▂▂▁▂▁▁▁▁▁▁▂▁▁▁▂▁▁▄▂▁▁▁▂▁▁▃▂▁█▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.88815</td></tr><tr><td>epoch</td><td>36</td></tr><tr><td>loss</td><td>1849.94348</td></tr><tr><td>val_loss</td><td>109.04288</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">snowy-sweep-10</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/m3nn4ee6\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/m3nn4ee6</a><br/>Synced 6 W&B file(s), 1 media file(s), 5 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_051539-m3nn4ee6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mi8lckzx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.22033117920924797\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 51\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.03867890875781595\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 178\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 217\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 187\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 90\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 80\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_051743-mi8lckzx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/mi8lckzx\" target=\"_blank\">smooth-sweep-11</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/51\n",
      "2270/2291 [============================>.] - ETA: 0s - loss: 4.9040INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_051743-mi8lckzx/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_051743-mi8lckzx/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 4.8685 - val_loss: 0.7642\n",
      "Epoch 2/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.8322 - val_loss: 0.9324\n",
      "Epoch 3/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.9036 - val_loss: 1.0450\n",
      "Epoch 4/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 969875.4375 - val_loss: 2968.6360\n",
      "Epoch 5/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1144.4485 - val_loss: 384.4326\n",
      "Epoch 6/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 328.4238 - val_loss: 159.4905\n",
      "Epoch 7/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 541704.8125 - val_loss: 2524.5083\n",
      "Epoch 8/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1622.7518 - val_loss: 1468.0991\n",
      "Epoch 9/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 511.7936 - val_loss: 136.3844\n",
      "Epoch 10/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1764642.7500 - val_loss: 5817.7290\n",
      "Epoch 11/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 5232.5547 - val_loss: 3249.4351\n",
      "Epoch 12/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1792.4161 - val_loss: 943.0736\n",
      "Epoch 13/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 288125.4688 - val_loss: 2093.4915\n",
      "Epoch 14/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1280.2699 - val_loss: 263.0627\n",
      "Epoch 15/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 437.2561 - val_loss: 119.2475\n",
      "Epoch 16/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 840290.6250 - val_loss: 27446.6113\n",
      "Epoch 17/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 7065.3184 - val_loss: 1782.6537\n",
      "Epoch 18/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1861.5342 - val_loss: 518.0847\n",
      "Epoch 19/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 572.3510 - val_loss: 227.6601\n",
      "Epoch 20/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2260459.2500 - val_loss: 11605.8486\n",
      "Epoch 21/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 9416.2969 - val_loss: 4318.7085\n",
      "Epoch 22/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3041.8804 - val_loss: 1064.9753\n",
      "Epoch 23/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1946564.7500 - val_loss: 73410.2422\n",
      "Epoch 24/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 19882.4023 - val_loss: 6235.0864\n",
      "Epoch 25/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 5718.4922 - val_loss: 1833.4296\n",
      "Epoch 26/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1945.4916 - val_loss: 954.7301\n",
      "Epoch 27/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1178931.2500 - val_loss: 49792.4805\n",
      "Epoch 28/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 6629.3696 - val_loss: 1984.1967\n",
      "Epoch 29/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2324.6162 - val_loss: 1432.5929\n",
      "Epoch 30/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1278335.1250 - val_loss: 9685.0420\n",
      "Epoch 31/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 7029.6577 - val_loss: 1752.6547\n",
      "Epoch 32/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2221.8374 - val_loss: 999.4733\n",
      "Epoch 33/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1048.1600 - val_loss: 484.6605\n",
      "Epoch 34/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1166415.1250 - val_loss: 8299.5938\n",
      "Epoch 35/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 5069.4780 - val_loss: 1894.5182\n",
      "Epoch 36/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1591.7284 - val_loss: 1040.0348\n",
      "Epoch 37/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2614226.7500 - val_loss: 30471.4746\n",
      "Epoch 38/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 17562.2969 - val_loss: 6551.9321\n",
      "Epoch 39/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 6470.9966 - val_loss: 2882.2415\n",
      "Epoch 40/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2668.1396 - val_loss: 1577.6643\n",
      "Epoch 41/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1601.5895 - val_loss: 385.6239\n",
      "Epoch 42/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2055035.0000 - val_loss: 17348.7129\n",
      "Epoch 43/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 11389.7715 - val_loss: 4720.1074\n",
      "Epoch 44/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3971.8667 - val_loss: 1299.6923\n",
      "Epoch 45/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1715625.7500 - val_loss: 135963.8125\n",
      "Epoch 46/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 43437.0234 - val_loss: 14405.3213\n",
      "Epoch 47/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 7954.2051 - val_loss: 6250.0430\n",
      "Epoch 48/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2311683.7500 - val_loss: 127294.1094\n",
      "Epoch 49/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 25174.2656 - val_loss: 9727.3652\n",
      "Epoch 50/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 8003.2817 - val_loss: 4196.0723\n",
      "Epoch 51/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2618516.0000 - val_loss: 25621.5664\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▁▄▁▂▁▁▁▁▂▁▃▁▁▇▁▁▁▁▁▄▁▄▁▁▄▁▁▁▁▁▆▁▁▆▁▇▁█</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▂▁▁▁▁▁▄▁▁▁▁▁▁▁▁▁▁▂▁▁█▁█▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.76416</td></tr><tr><td>epoch</td><td>50</td></tr><tr><td>loss</td><td>2618516.0</td></tr><tr><td>val_loss</td><td>25621.56641</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">smooth-sweep-11</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/mi8lckzx\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/mi8lckzx</a><br/>Synced 6 W&B file(s), 1 media file(s), 5 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_051743-mi8lckzx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pyqokvkq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5036914126843215\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 83\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.018141304045154884\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 220\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 229\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 89\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 137\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_052037-pyqokvkq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/pyqokvkq\" target=\"_blank\">devout-sweep-12</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/83\n",
      "4553/4581 [============================>.] - ETA: 0s - loss: 2277.2517INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_052037-pyqokvkq/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_052037-pyqokvkq/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2263.7795 - val_loss: 7.9525\n",
      "Epoch 2/83\n",
      "4571/4581 [============================>.] - ETA: 0s - loss: 5.6116INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_052037-pyqokvkq/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_052037-pyqokvkq/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4581/4581 [==============================] - 6s 1ms/step - loss: 5.6049 - val_loss: 1.8334\n",
      "Epoch 3/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2415.7415 - val_loss: 7.0779\n",
      "Epoch 4/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 204.0745 - val_loss: 3.1236\n",
      "Epoch 5/83\n",
      "4574/4581 [============================>.] - ETA: 0s - loss: 1.9452INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_052037-pyqokvkq/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_052037-pyqokvkq/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1.9442 - val_loss: 1.0627\n",
      "Epoch 6/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1759.6562 - val_loss: 47.3202\n",
      "Epoch 7/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 230.9987 - val_loss: 5.0618\n",
      "Epoch 8/83\n",
      "4536/4581 [============================>.] - ETA: 0s - loss: 2.9454INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_052037-pyqokvkq/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_052037-pyqokvkq/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2.9319 - val_loss: 1.0273\n",
      "Epoch 9/83\n",
      "4576/4581 [============================>.] - ETA: 0s - loss: 1.1482INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_052037-pyqokvkq/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_052037-pyqokvkq/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1.1483 - val_loss: 0.9461\n",
      "Epoch 10/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 4055.5774 - val_loss: 13.0724\n",
      "Epoch 11/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1245.5469 - val_loss: 19.5189\n",
      "Epoch 12/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 11.0608 - val_loss: 1.8182\n",
      "Epoch 13/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 817.9440 - val_loss: 16.4587\n",
      "Epoch 14/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 7.9124 - val_loss: 1.6433\n",
      "Epoch 15/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1695.2246 - val_loss: 8.8329\n",
      "Epoch 16/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 5.8649 - val_loss: 1.6648\n",
      "Epoch 17/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2673.7197 - val_loss: 8.7668\n",
      "Epoch 18/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1752.0614 - val_loss: 35.8091\n",
      "Epoch 19/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 18.2474 - val_loss: 4.1591\n",
      "Epoch 20/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1392.9266 - val_loss: 36984.2227\n",
      "Epoch 21/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2199.9138 - val_loss: 10.1527\n",
      "Epoch 22/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2196.3286 - val_loss: 15.7137\n",
      "Epoch 23/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 923.5080 - val_loss: 15.4180\n",
      "Epoch 24/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 8.6038 - val_loss: 1.8075\n",
      "Epoch 25/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 4329.2681 - val_loss: 50.6237\n",
      "Epoch 26/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 31.6601 - val_loss: 7.0719\n",
      "Epoch 27/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1701.6859 - val_loss: 174.6834\n",
      "Epoch 28/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 42.0578 - val_loss: 4.1350\n",
      "Epoch 29/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 4.5459 - val_loss: 7.5617\n",
      "Epoch 30/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1642.3118 - val_loss: 5.7599\n",
      "Epoch 31/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 4.8157 - val_loss: 1.4811\n",
      "Epoch 32/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2740.3735 - val_loss: 12.0123\n",
      "Epoch 33/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 9.0283 - val_loss: 1.7030\n",
      "Epoch 34/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1749.0072 - val_loss: 4.8667\n",
      "Epoch 35/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 3.7787 - val_loss: 1.6021\n",
      "Epoch 36/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2028.5669 - val_loss: 12.7902\n",
      "Epoch 37/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 7.4469 - val_loss: 2.2844\n",
      "Epoch 38/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 845.5105 - val_loss: 8.3092\n",
      "Epoch 39/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 839.1343 - val_loss: 21.7302\n",
      "Epoch 40/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 9.7868 - val_loss: 2.2652\n",
      "Epoch 41/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1619.9420 - val_loss: 24.4933\n",
      "Epoch 42/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 15.4371 - val_loss: 2.9003\n",
      "Epoch 43/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2962.4644 - val_loss: 46.8391\n",
      "Epoch 44/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 22.7505 - val_loss: 3.9205\n",
      "Epoch 45/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 893.4487 - val_loss: 9.6652\n",
      "Epoch 46/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 7.5801 - val_loss: 1.9273\n",
      "Epoch 47/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2041.9279 - val_loss: 18.0951\n",
      "Epoch 48/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 8.7793 - val_loss: 2.4413\n",
      "Epoch 49/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1865.7371 - val_loss: 12.6598\n",
      "Epoch 50/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 6.8327 - val_loss: 2.5791\n",
      "Epoch 51/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1241.1012 - val_loss: 9.9770\n",
      "Epoch 52/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 6.5749 - val_loss: 2.4713\n",
      "Epoch 53/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 735.6083 - val_loss: 5.1022\n",
      "Epoch 54/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 4.2725 - val_loss: 2.6248\n",
      "Epoch 55/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2337.9368 - val_loss: 13.4352\n",
      "Epoch 56/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2294.5300 - val_loss: 40.7088\n",
      "Epoch 57/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 23.6605 - val_loss: 4.2655\n",
      "Epoch 58/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1276.5630 - val_loss: 18.5706\n",
      "Epoch 59/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 7.5704 - val_loss: 1.6643\n",
      "Epoch 60/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1713.3882 - val_loss: 23.1422\n",
      "Epoch 61/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 14.9076 - val_loss: 3.5289\n",
      "Epoch 62/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2239.4673 - val_loss: 36889.2266\n",
      "Epoch 63/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 181.9781 - val_loss: 6.5866\n",
      "Epoch 64/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1932.5021 - val_loss: 20.2185\n",
      "Epoch 65/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 12.5817 - val_loss: 4.2238\n",
      "Epoch 66/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1648.2180 - val_loss: 5.8826\n",
      "Epoch 67/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 5.2576 - val_loss: 2.5063\n",
      "Epoch 68/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1521.6873 - val_loss: 6.9095\n",
      "Epoch 69/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1837.3267 - val_loss: 196.4699\n",
      "Epoch 70/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 46.7652 - val_loss: 5.9761\n",
      "Epoch 71/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2302.8662 - val_loss: 63.2143\n",
      "Epoch 72/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 25.5127 - val_loss: 3.7155\n",
      "Epoch 73/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1476.0509 - val_loss: 14.0411\n",
      "Epoch 74/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 8.8926 - val_loss: 2.3037\n",
      "Epoch 75/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 3310.3752 - val_loss: 22.6836\n",
      "Epoch 76/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 16.9107 - val_loss: 2.6503\n",
      "Epoch 77/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 4009.1121 - val_loss: 111.2330\n",
      "Epoch 78/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 51.9560 - val_loss: 8.2493\n",
      "Epoch 79/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1342.7924 - val_loss: 22.4064\n",
      "Epoch 80/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 8.5195 - val_loss: 2.1396\n",
      "Epoch 81/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1926.1663 - val_loss: 27.9880\n",
      "Epoch 82/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 12.5871 - val_loss: 3.5148\n",
      "Epoch 83/83\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1725.9143 - val_loss: 12.1272\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "716e2ddb5232422892c5577c4b4c279d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='7.848 MB of 7.848 MB uploaded (0.016 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▆▇▁▂▁▄▃▅▇▁▆▁▁▁▅▇▅▆▃▁█▃▆▅▄▃▇▁▁▁▆▅▅▁▁▁▁▁▁▅</td></tr><tr><td>val_loss</td><td>▂▂▁▂▁▄▃▂▂▁▃▁▂▁▂▃▂▃▂▁█▂▄▃▂▂▃▂▁▁▄▂▂▂▁▁▁▂▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>8</td></tr><tr><td>best_val_loss</td><td>0.94606</td></tr><tr><td>epoch</td><td>82</td></tr><tr><td>loss</td><td>1725.91431</td></tr><tr><td>val_loss</td><td>12.12724</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">devout-sweep-12</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/pyqokvkq\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/pyqokvkq</a><br/>Synced 6 W&B file(s), 1 media file(s), 21 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_052037-pyqokvkq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 30ekeebo with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2994415608910723\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 65\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.018993144600271274\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 90\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 202\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 171\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 233\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 139\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_052752-30ekeebo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/30ekeebo\" target=\"_blank\">splendid-sweep-13</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/65\n",
      "2288/2291 [============================>.] - ETA: 0s - loss: 1.0870INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_052752-30ekeebo/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_052752-30ekeebo/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 5s 2ms/step - loss: 1.0869 - val_loss: 0.8260\n",
      "Epoch 2/65\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 5408.2617 - val_loss: 61.2514\n",
      "Epoch 3/65\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 28.1219 - val_loss: 12.4307\n",
      "Epoch 4/65\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 8.8729 - val_loss: 3.4895\n",
      "Epoch 5/65\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 3.9165 - val_loss: 2.4419\n",
      "Epoch 6/65\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 21582.7637 - val_loss: 247.6964\n",
      "Epoch 7/65\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 87.3462 - val_loss: 34.7801\n",
      "Epoch 8/65\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 30.9341 - val_loss: 13.2866\n",
      "Epoch 9/65\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 11420.7764 - val_loss: 87.1984\n",
      "Epoch 10/65\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 62.2306 - val_loss: 14.5906\n",
      "Epoch 11/65\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 18.4298 - val_loss: 6.7580\n",
      "Epoch 12/65\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 11177.6465 - val_loss: 51.3273\n",
      "Epoch 13/65\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 53.7505 - val_loss: 19.3554\n",
      "Epoch 14/65\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 22.2275 - val_loss: 7.7240\n",
      "Epoch 15/65\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 15837.6299 - val_loss: 132.4750\n",
      "Epoch 16/65\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 112.8410 - val_loss: 47.2110\n",
      "Epoch 17/65\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 42.4175 - val_loss: 13.9849\n",
      "Epoch 18/65\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 25282.8633 - val_loss: 344.0122\n",
      "Epoch 19/65\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 182.6452 - val_loss: 58.9225\n",
      "Epoch 20/65\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 59.5135 - val_loss: 21.2158\n",
      "Epoch 21/65\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 15.1551 - val_loss: 7.9038\n",
      "Epoch 22/65\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 29148.6445 - val_loss: 562.6464\n",
      "Epoch 23/65\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 301.1125 - val_loss: 113.2873\n",
      "Epoch 24/65\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 85.2474 - val_loss: 66.1293\n",
      "Epoch 25/65\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 11808.2275 - val_loss: 199.7468\n",
      "Epoch 26/65\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 132.4050 - val_loss: 40.0240\n",
      "Epoch 27/65\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 45.5267 - val_loss: 20.7506\n",
      "Epoch 28/65\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 15.7720 - val_loss: 13.4833\n",
      "Epoch 29/65\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 22213.6289 - val_loss: 255.4028\n",
      "Epoch 30/65\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 115.3872 - val_loss: 61.5531\n",
      "Epoch 31/65\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 41.4664 - val_loss: 35.2546\n",
      "Epoch 32/65\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 23503.6895 - val_loss: 373.5832\n",
      "Epoch 33/65\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 210.2118 - val_loss: 76.6915\n",
      "Epoch 34/65\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 75.9492 - val_loss: 39.4325\n",
      "Epoch 35/65\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 29.2790 - val_loss: 11.3434\n",
      "Epoch 36/65\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 28052.5547 - val_loss: 332.2940\n",
      "Epoch 37/65\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 200.2800 - val_loss: 73.9576\n",
      "Epoch 38/65\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 73.4848 - val_loss: 32.0924\n",
      "Epoch 39/65\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 22.9970 - val_loss: 7.3279\n",
      "Epoch 40/65\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 14728.9229 - val_loss: 79.8166\n",
      "Epoch 41/65\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 80.7645 - val_loss: 39.9965\n",
      "Epoch 42/65\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 30.4030 - val_loss: 14.9744\n",
      "Epoch 43/65\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 27474.1191 - val_loss: 343.2046\n",
      "Epoch 44/65\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 247.9663 - val_loss: 91.2852\n",
      "Epoch 45/65\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 85.6054 - val_loss: 64.6816\n",
      "Epoch 46/65\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 30.2678 - val_loss: 27.6396\n",
      "Epoch 47/65\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 20722.5469 - val_loss: 239.1833\n",
      "Epoch 48/65\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 139.0125 - val_loss: 57.8965\n",
      "Epoch 49/65\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 7168.7910 - val_loss: 115.1317\n",
      "Epoch 50/65\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 92.7043 - val_loss: 35.0271\n",
      "Epoch 51/65\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 29.1358 - val_loss: 8.1238\n",
      "Epoch 52/65\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 11.1217 - val_loss: 10.0555\n",
      "Epoch 53/65\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 33487.2461 - val_loss: 324.7801\n",
      "Epoch 54/65\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 207.5524 - val_loss: 75.7793\n",
      "Epoch 55/65\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 70.9230 - val_loss: 22.4612\n",
      "Epoch 56/65\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 23.2063 - val_loss: 15.3678\n",
      "Epoch 57/65\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 8.5102 - val_loss: 5.5718\n",
      "Epoch 58/65\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 11476.2871 - val_loss: 251.6538\n",
      "Epoch 59/65\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 140.1096 - val_loss: 85.0872\n",
      "Epoch 60/65\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 42.1720 - val_loss: 22.6105\n",
      "Epoch 61/65\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 14.0108 - val_loss: 8.2337\n",
      "Epoch 62/65\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 7.0233 - val_loss: 4.0056\n",
      "Epoch 63/65\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 33885.1211 - val_loss: 199.3599\n",
      "Epoch 64/65\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 183.6663 - val_loss: 74.5933\n",
      "Epoch 65/65\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 75.5916 - val_loss: 55.0041\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3399393761af4da3adb93ad0bd1c41c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.270 MB of 3.270 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▂▁▁▁▃▁▃▁▄▁▁▁▇▁▃▁▁▁▆▁▁▁▁▄▁▇▁▁▁▁▁█▁▁▃▁▁█▁</td></tr><tr><td>val_loss</td><td>▁▂▁▁▁▂▁▂▁▃▁▂▁█▂▃▁▁▂▆▂▁▂▁▂▁▅▂▁▂▁▁▅▁▁▄▁▁▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.82602</td></tr><tr><td>epoch</td><td>64</td></tr><tr><td>loss</td><td>75.59155</td></tr><tr><td>val_loss</td><td>55.00414</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">splendid-sweep-13</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/30ekeebo\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/30ekeebo</a><br/>Synced 6 W&B file(s), 1 media file(s), 5 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_052752-30ekeebo/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9bgkkbgv with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5818346992650782\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 92\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.040656842978008395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 69\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 187\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 210\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 174\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 86\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_053153-9bgkkbgv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/9bgkkbgv\" target=\"_blank\">serene-sweep-14</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/92\n",
      "2283/2291 [============================>.] - ETA: 0s - loss: 6.8624INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_053153-9bgkkbgv/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_053153-9bgkkbgv/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 6.8438 - val_loss: 0.8217\n",
      "Epoch 2/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.8601 - val_loss: 0.8945\n",
      "Epoch 3/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.9668 - val_loss: 0.9384\n",
      "Epoch 4/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1257830.3750 - val_loss: 4391.0073\n",
      "Epoch 5/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 4622.1362 - val_loss: 1686.4094\n",
      "Epoch 6/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 973.8989 - val_loss: 662.8282\n",
      "Epoch 7/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2563680.7500 - val_loss: 48797.5820\n",
      "Epoch 8/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 11146.1211 - val_loss: 2720.1311\n",
      "Epoch 9/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3518.9170 - val_loss: 1043.4835\n",
      "Epoch 10/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1683749.1250 - val_loss: 15494.8516\n",
      "Epoch 11/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 8165.9585 - val_loss: 3597.8770\n",
      "Epoch 12/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2504.0913 - val_loss: 802.5079\n",
      "Epoch 13/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 833292.8125 - val_loss: 16486.1504\n",
      "Epoch 14/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 9440.6533 - val_loss: 3714.7688\n",
      "Epoch 15/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2537.6206 - val_loss: 633.6930\n",
      "Epoch 16/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 831.7550 - val_loss: 215.1607\n",
      "Epoch 17/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1181564.0000 - val_loss: 16650.8906\n",
      "Epoch 18/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 9733.3545 - val_loss: 3383.8254\n",
      "Epoch 19/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2392.8840 - val_loss: 770.8605\n",
      "Epoch 20/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 725.4883 - val_loss: 301.9942\n",
      "Epoch 21/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 248.2885 - val_loss: 576.7585\n",
      "Epoch 22/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 4395019.0000 - val_loss: 13251.6885\n",
      "Epoch 23/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 14847.4307 - val_loss: 4259.3623\n",
      "Epoch 24/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1548942.5000 - val_loss: 6778.4800\n",
      "Epoch 25/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 6648.3140 - val_loss: 2392.0100\n",
      "Epoch 26/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2180.0793 - val_loss: 1004.5682\n",
      "Epoch 27/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 729.9911 - val_loss: 387.5672\n",
      "Epoch 28/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1659503.6250 - val_loss: 18387.5332\n",
      "Epoch 29/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 8408.2812 - val_loss: 2289.8147\n",
      "Epoch 30/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3062.3489 - val_loss: 885.7454\n",
      "Epoch 31/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1107020.7500 - val_loss: 4237.4868\n",
      "Epoch 32/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 4867.2915 - val_loss: 1538.6343\n",
      "Epoch 33/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1439.1752 - val_loss: 536.5643\n",
      "Epoch 34/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 639.9858 - val_loss: 126.0949\n",
      "Epoch 35/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 383752.9375 - val_loss: 4078.4084\n",
      "Epoch 36/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2374.9104 - val_loss: 908.2723\n",
      "Epoch 37/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 803.8725 - val_loss: 208.7859\n",
      "Epoch 38/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1687436.1250 - val_loss: 39815.7969\n",
      "Epoch 39/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 21074.2539 - val_loss: 7012.8384\n",
      "Epoch 40/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 4865.0483 - val_loss: 1354.2927\n",
      "Epoch 41/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1440.3361 - val_loss: 635.0947\n",
      "Epoch 42/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 775726.5625 - val_loss: 19102.5977\n",
      "Epoch 43/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 10390.9629 - val_loss: 2216.8960\n",
      "Epoch 44/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2100.7454 - val_loss: 607.3539\n",
      "Epoch 45/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 626.4117 - val_loss: 194.9269\n",
      "Epoch 46/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 244.4144 - val_loss: 74.4649\n",
      "Epoch 47/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 990027.9375 - val_loss: 6737.8408\n",
      "Epoch 48/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 5028.9937 - val_loss: 1740.2731\n",
      "Epoch 49/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1780.3926 - val_loss: 516.4261\n",
      "Epoch 50/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 608.6270 - val_loss: 243.9855\n",
      "Epoch 51/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 236.2968 - val_loss: 80.6127\n",
      "Epoch 52/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1613098.3750 - val_loss: 14360.6230\n",
      "Epoch 53/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 8672.5234 - val_loss: 2529.8635\n",
      "Epoch 54/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 823107.7500 - val_loss: 68742.9844\n",
      "Epoch 55/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 17939.4531 - val_loss: 4207.4673\n",
      "Epoch 56/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3785.4912 - val_loss: 1515.1033\n",
      "Epoch 57/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1332.9758 - val_loss: 679.6854\n",
      "Epoch 58/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 654535.4375 - val_loss: 4186.2397\n",
      "Epoch 59/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3390.4016 - val_loss: 1143.1497\n",
      "Epoch 60/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 939.9545 - val_loss: 444.5236\n",
      "Epoch 61/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1021619.6875 - val_loss: 217641.5781\n",
      "Epoch 62/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 25546.0430 - val_loss: 4944.9888\n",
      "Epoch 63/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 4460.3398 - val_loss: 1662.6705\n",
      "Epoch 64/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1501.0623 - val_loss: 782.5148\n",
      "Epoch 65/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 566.8536 - val_loss: 185.4579\n",
      "Epoch 66/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1844647.5000 - val_loss: 24294.4023\n",
      "Epoch 67/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 15462.6240 - val_loss: 6688.3052\n",
      "Epoch 68/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 5098.9009 - val_loss: 1444.6520\n",
      "Epoch 69/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2026.8326 - val_loss: 867.7531\n",
      "Epoch 70/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 948098.8750 - val_loss: 4638.8857\n",
      "Epoch 71/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 5549.7832 - val_loss: 1921.6591\n",
      "Epoch 72/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1757.5017 - val_loss: 930.8673\n",
      "Epoch 73/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1049.6036 - val_loss: 587.0031\n",
      "Epoch 74/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 991141.8750 - val_loss: 3493.1279\n",
      "Epoch 75/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3650.0718 - val_loss: 968.6564\n",
      "Epoch 76/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1304.4095 - val_loss: 422.9467\n",
      "Epoch 77/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1119707.7500 - val_loss: 7774.8306\n",
      "Epoch 78/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 6361.5879 - val_loss: 2650.8184\n",
      "Epoch 79/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2583.8215 - val_loss: 3329.2944\n",
      "Epoch 80/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1124200.8750 - val_loss: 6910.3257\n",
      "Epoch 81/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 4508.1875 - val_loss: 1563.3492\n",
      "Epoch 82/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1423.3026 - val_loss: 5708.0869\n",
      "Epoch 83/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 525443.8125 - val_loss: 6534.4580\n",
      "Epoch 84/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 4618.6167 - val_loss: 1623.3284\n",
      "Epoch 85/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1329.8790 - val_loss: 360.3568\n",
      "Epoch 86/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 768948.1875 - val_loss: 4087.3135\n",
      "Epoch 87/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3989.9766 - val_loss: 1514.0656\n",
      "Epoch 88/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1367.5953 - val_loss: 663.2765\n",
      "Epoch 89/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 498046.9688 - val_loss: 11863.7207\n",
      "Epoch 90/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 4393.3911 - val_loss: 1259.0226\n",
      "Epoch 91/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1175.9669 - val_loss: 462.9009\n",
      "Epoch 92/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 316.7197 - val_loss: 112.3872\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▁▁▄▁▁▃▁█▃▁▁▃▁▁▄▁▁▁▃▁▄▂▁▁▃▁▄▁▁▁▁▁▃▁▁▁▂▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▃▁▁█▁▂▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.82169</td></tr><tr><td>epoch</td><td>91</td></tr><tr><td>loss</td><td>316.7197</td></tr><tr><td>val_loss</td><td>112.38716</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">serene-sweep-14</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/9bgkkbgv\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/9bgkkbgv</a><br/>Synced 6 W&B file(s), 1 media file(s), 5 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_053153-9bgkkbgv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: v5ebdakh with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4406250175804713\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 62\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.005068541295890572\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 191\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 189\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 88\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 163\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 87\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_053700-v5ebdakh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/v5ebdakh\" target=\"_blank\">eternal-sweep-15</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/62\n",
      "2273/2291 [============================>.] - ETA: 0s - loss: 0.8855INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_053700-v5ebdakh/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_053700-v5ebdakh/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 0.8854 - val_loss: 0.8080\n",
      "Epoch 2/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.8049 - val_loss: 0.9260\n",
      "Epoch 3/62\n",
      "2269/2291 [============================>.] - ETA: 0s - loss: 0.7837INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_053700-v5ebdakh/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_053700-v5ebdakh/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 0.7836 - val_loss: 0.7365\n",
      "Epoch 4/62\n",
      "2249/2291 [============================>.] - ETA: 0s - loss: 1.9945INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_053700-v5ebdakh/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_053700-v5ebdakh/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1.9723 - val_loss: 0.6919\n",
      "Epoch 5/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7334 - val_loss: 0.9025\n",
      "Epoch 6/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7479 - val_loss: 0.7882\n",
      "Epoch 7/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7666 - val_loss: 0.7687\n",
      "Epoch 8/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7544 - val_loss: 0.7451\n",
      "Epoch 9/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.1483 - val_loss: 0.7359\n",
      "Epoch 10/62\n",
      "2261/2291 [============================>.] - ETA: 0s - loss: 0.7279INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_053700-v5ebdakh/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_053700-v5ebdakh/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 0.7272 - val_loss: 0.6902\n",
      "Epoch 11/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7317 - val_loss: 0.7984\n",
      "Epoch 12/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7416 - val_loss: 0.7134\n",
      "Epoch 13/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7408 - val_loss: 0.8501\n",
      "Epoch 14/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7464 - val_loss: 0.7822\n",
      "Epoch 15/62\n",
      "2277/2291 [============================>.] - ETA: 0s - loss: 1.1226INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_053700-v5ebdakh/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_053700-v5ebdakh/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1.1207 - val_loss: 0.6826\n",
      "Epoch 16/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7286 - val_loss: 0.7049\n",
      "Epoch 17/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7388 - val_loss: 0.7329\n",
      "Epoch 18/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7316 - val_loss: 0.7556\n",
      "Epoch 19/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7430 - val_loss: 0.7390\n",
      "Epoch 20/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.1446 - val_loss: 1.7205\n",
      "Epoch 21/62\n",
      "2283/2291 [============================>.] - ETA: 0s - loss: 0.7458INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_053700-v5ebdakh/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_053700-v5ebdakh/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 0.7458 - val_loss: 0.6791\n",
      "Epoch 22/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7324 - val_loss: 0.7128\n",
      "Epoch 23/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7361 - val_loss: 0.7127\n",
      "Epoch 24/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7378 - val_loss: 0.7038\n",
      "Epoch 25/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.0447 - val_loss: 0.7010\n",
      "Epoch 26/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7188 - val_loss: 0.7158\n",
      "Epoch 27/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7273 - val_loss: 0.6945\n",
      "Epoch 28/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7328 - val_loss: 0.7201\n",
      "Epoch 29/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7240 - val_loss: 0.7068\n",
      "Epoch 30/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.3151 - val_loss: 0.7851\n",
      "Epoch 31/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7176 - val_loss: 0.8137\n",
      "Epoch 32/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7312 - val_loss: 0.7145\n",
      "Epoch 33/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7309 - val_loss: 0.7381\n",
      "Epoch 34/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7365 - val_loss: 0.6981\n",
      "Epoch 35/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7241 - val_loss: 0.7023\n",
      "Epoch 36/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7253 - val_loss: 0.7068\n",
      "Epoch 37/62\n",
      "2282/2291 [============================>.] - ETA: 0s - loss: 1.8526INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_053700-v5ebdakh/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_053700-v5ebdakh/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1.8484 - val_loss: 0.6783\n",
      "Epoch 38/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7097 - val_loss: 0.7317\n",
      "Epoch 39/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7252 - val_loss: 0.7414\n",
      "Epoch 40/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7311 - val_loss: 0.6834\n",
      "Epoch 41/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7276 - val_loss: 0.7073\n",
      "Epoch 42/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.2099 - val_loss: 0.7269\n",
      "Epoch 43/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7174 - val_loss: 0.7204\n",
      "Epoch 44/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7206 - val_loss: 0.7015\n",
      "Epoch 45/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7290 - val_loss: 0.7443\n",
      "Epoch 46/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7243 - val_loss: 0.7125\n",
      "Epoch 47/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.7956 - val_loss: 0.7040\n",
      "Epoch 48/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7093 - val_loss: 0.7136\n",
      "Epoch 49/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7174 - val_loss: 0.6884\n",
      "Epoch 50/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7291 - val_loss: 0.7217\n",
      "Epoch 51/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7232 - val_loss: 1.0399\n",
      "Epoch 52/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.5171 - val_loss: 0.7069\n",
      "Epoch 53/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7222 - val_loss: 0.7141\n",
      "Epoch 54/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7246 - val_loss: 0.7327\n",
      "Epoch 55/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7238 - val_loss: 0.6990\n",
      "Epoch 56/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 4.2932 - val_loss: 0.7380\n",
      "Epoch 57/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7434 - val_loss: 0.6855\n",
      "Epoch 58/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7085 - val_loss: 0.6957\n",
      "Epoch 59/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7226 - val_loss: 0.7592\n",
      "Epoch 60/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7351 - val_loss: 0.7221\n",
      "Epoch 61/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7266 - val_loss: 0.7421\n",
      "Epoch 62/62\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7336 - val_loss: 0.7046\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▂▂█▁▁▁▁▁▁▃▁▁▁▁▁▁▁▁▁▄▁▁▁▁▁▁▁▁▁▁▇▁▁▅▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▄▆▁▅▃▂▁▃▄▁▁▂▂▁▂▁▂▁▂▃▂▂▁▂▂▁▂▂▁▂▁▁█▂▂▁▁▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>36</td></tr><tr><td>best_val_loss</td><td>0.67831</td></tr><tr><td>epoch</td><td>61</td></tr><tr><td>loss</td><td>0.73357</td></tr><tr><td>val_loss</td><td>0.70464</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">eternal-sweep-15</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/v5ebdakh\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/v5ebdakh</a><br/>Synced 6 W&B file(s), 1 media file(s), 29 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_053700-v5ebdakh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2arbww9x with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4491906281405757\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0037983055979038177\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 139\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 212\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 233\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 203\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 103\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_054025-2arbww9x</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/2arbww9x\" target=\"_blank\">wise-sweep-16</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/96\n",
      "1520/1527 [============================>.] - ETA: 0s - loss: 0.8692INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_054025-2arbww9x/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_054025-2arbww9x/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 4s 3ms/step - loss: 0.8693 - val_loss: 0.7729\n",
      "Epoch 2/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.7895 - val_loss: 0.7747\n",
      "Epoch 3/96\n",
      "1513/1527 [============================>.] - ETA: 0s - loss: 0.7645INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_054025-2arbww9x/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_054025-2arbww9x/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.7644 - val_loss: 0.7170\n",
      "Epoch 4/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.7523 - val_loss: 0.7532\n",
      "Epoch 5/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.7408 - val_loss: 0.7486\n",
      "Epoch 6/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 2.8002 - val_loss: 0.7241\n",
      "Epoch 7/96\n",
      "1509/1527 [============================>.] - ETA: 0s - loss: 0.7187INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_054025-2arbww9x/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_054025-2arbww9x/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 4s 2ms/step - loss: 0.7187 - val_loss: 0.6856\n",
      "Epoch 8/96\n",
      "1520/1527 [============================>.] - ETA: 0s - loss: 0.7045INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_054025-2arbww9x/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_054025-2arbww9x/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 4s 2ms/step - loss: 0.7050 - val_loss: 0.6764\n",
      "Epoch 9/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.7124 - val_loss: 0.6931\n",
      "Epoch 10/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.7196 - val_loss: 0.7170\n",
      "Epoch 11/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.7327 - val_loss: 0.6909\n",
      "Epoch 12/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.7249 - val_loss: 0.6964\n",
      "Epoch 13/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.7291 - val_loss: 0.6775\n",
      "Epoch 14/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.7206 - val_loss: 0.7116\n",
      "Epoch 15/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.7176 - val_loss: 0.7025\n",
      "Epoch 16/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.7144 - val_loss: 0.6803\n",
      "Epoch 17/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.7108 - val_loss: 0.6836\n",
      "Epoch 18/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.7139 - val_loss: 0.6781\n",
      "Epoch 19/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1.0952 - val_loss: 0.6908\n",
      "Epoch 20/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.7038 - val_loss: 0.6913\n",
      "Epoch 21/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.7049 - val_loss: 0.7240\n",
      "Epoch 22/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.7100 - val_loss: 0.7178\n",
      "Epoch 23/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.7108 - val_loss: 0.6989\n",
      "Epoch 24/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.7059 - val_loss: 0.7256\n",
      "Epoch 25/96\n",
      "1501/1527 [============================>.] - ETA: 0s - loss: 0.7077INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_054025-2arbww9x/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_054025-2arbww9x/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 4s 2ms/step - loss: 0.7089 - val_loss: 0.6678\n",
      "Epoch 26/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.7042 - val_loss: 0.6877\n",
      "Epoch 27/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1.3211 - val_loss: 0.6828\n",
      "Epoch 28/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.6947 - val_loss: 0.7075\n",
      "Epoch 29/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.7007 - val_loss: 0.6879\n",
      "Epoch 30/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.7042 - val_loss: 0.7026\n",
      "Epoch 31/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.7005 - val_loss: 0.7355\n",
      "Epoch 32/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.7032 - val_loss: 0.7063\n",
      "Epoch 33/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.7085 - val_loss: 0.7277\n",
      "Epoch 34/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1.1088 - val_loss: 0.6782\n",
      "Epoch 35/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.6912 - val_loss: 0.6814\n",
      "Epoch 36/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.6976 - val_loss: 0.6898\n",
      "Epoch 37/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.7016 - val_loss: 0.7168\n",
      "Epoch 38/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.7023 - val_loss: 0.7186\n",
      "Epoch 39/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.7028 - val_loss: 0.6715\n",
      "Epoch 40/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.6996 - val_loss: 0.6901\n",
      "Epoch 41/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.7053 - val_loss: 0.7144\n",
      "Epoch 42/96\n",
      "1499/1527 [============================>.] - ETA: 0s - loss: 0.6986INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_054025-2arbww9x/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_054025-2arbww9x/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.6984 - val_loss: 0.6638\n",
      "Epoch 43/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 2.7099 - val_loss: 0.6979\n",
      "Epoch 44/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.6931 - val_loss: 0.6653\n",
      "Epoch 45/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.6871 - val_loss: 0.6743\n",
      "Epoch 46/96\n",
      "1526/1527 [============================>.] - ETA: 0s - loss: 0.6911INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_054025-2arbww9x/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_054025-2arbww9x/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.6910 - val_loss: 0.6576\n",
      "Epoch 47/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.6949 - val_loss: 0.6777\n",
      "Epoch 48/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.6983 - val_loss: 0.6872\n",
      "Epoch 49/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.6991 - val_loss: 0.6765\n",
      "Epoch 50/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.7013 - val_loss: 0.7180\n",
      "Epoch 51/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.7008 - val_loss: 0.6896\n",
      "Epoch 52/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.6999 - val_loss: 0.6805\n",
      "Epoch 53/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.6955 - val_loss: 0.6710\n",
      "Epoch 54/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.9685 - val_loss: 0.7195\n",
      "Epoch 55/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.6941 - val_loss: 0.7179\n",
      "Epoch 56/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.6963 - val_loss: 0.6975\n",
      "Epoch 57/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.7011 - val_loss: 0.6925\n",
      "Epoch 58/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.6980 - val_loss: 0.6872\n",
      "Epoch 59/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.6948 - val_loss: 0.6931\n",
      "Epoch 60/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1.5264 - val_loss: 0.7116\n",
      "Epoch 61/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.7029 - val_loss: 0.6659\n",
      "Epoch 62/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.6911 - val_loss: 0.6605\n",
      "Epoch 63/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.6955 - val_loss: 0.6796\n",
      "Epoch 64/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.6957 - val_loss: 0.6981\n",
      "Epoch 65/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.6933 - val_loss: 0.7311\n",
      "Epoch 66/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.6948 - val_loss: 0.6761\n",
      "Epoch 67/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.6970 - val_loss: 0.6760\n",
      "Epoch 68/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.9020 - val_loss: 0.6841\n",
      "Epoch 69/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.6951 - val_loss: 0.6651\n",
      "Epoch 70/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.6919 - val_loss: 0.6833\n",
      "Epoch 71/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.6943 - val_loss: 0.6860\n",
      "Epoch 72/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.6976 - val_loss: 0.6700\n",
      "Epoch 73/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.6937 - val_loss: 0.6631\n",
      "Epoch 74/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.6937 - val_loss: 0.6645\n",
      "Epoch 75/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.6962 - val_loss: 0.6814\n",
      "Epoch 76/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.6980 - val_loss: 0.6900\n",
      "Epoch 77/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.6934 - val_loss: 0.6660\n",
      "Epoch 78/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.6912 - val_loss: 0.6747\n",
      "Epoch 79/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1.7532 - val_loss: 0.7168\n",
      "Epoch 80/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.6996 - val_loss: 0.7151\n",
      "Epoch 81/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.6947 - val_loss: 0.6755\n",
      "Epoch 82/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.6884 - val_loss: 0.6805\n",
      "Epoch 83/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.6938 - val_loss: 0.6738\n",
      "Epoch 84/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.6961 - val_loss: 0.6723\n",
      "Epoch 85/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.6965 - val_loss: 0.6610\n",
      "Epoch 86/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1.2580 - val_loss: 0.6897\n",
      "Epoch 87/96\n",
      "1506/1527 [============================>.] - ETA: 0s - loss: 0.6939INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_054025-2arbww9x/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_054025-2arbww9x/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.6940 - val_loss: 0.6560\n",
      "Epoch 88/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.6909 - val_loss: 0.7096\n",
      "Epoch 89/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.6990 - val_loss: 0.6781\n",
      "Epoch 90/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.6989 - val_loss: 0.6746\n",
      "Epoch 91/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.6974 - val_loss: 0.7086\n",
      "Epoch 92/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.7042 - val_loss: 0.6910\n",
      "Epoch 93/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.6918 - val_loss: 0.7097\n",
      "Epoch 94/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1.7636 - val_loss: 0.6918\n",
      "Epoch 95/96\n",
      "1519/1527 [============================>.] - ETA: 0s - loss: 0.6925INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_054025-2arbww9x/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_054025-2arbww9x/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 4s 2ms/step - loss: 0.6923 - val_loss: 0.6533\n",
      "Epoch 96/96\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.6878 - val_loss: 0.7166\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▃▂▂▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▄▁▁▁▁▁▁▁▁▁▁▁▁▇▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▅▇▂▅▂▄▂▃▅▂▃▄▄▃▅▂▂▂▂▂▃▅▃▃▂▄▂▂▃▂▃▂▂▂▃▄▄▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>94</td></tr><tr><td>best_val_loss</td><td>0.65327</td></tr><tr><td>epoch</td><td>95</td></tr><tr><td>loss</td><td>0.68782</td></tr><tr><td>val_loss</td><td>0.71663</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">wise-sweep-16</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/2arbww9x\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/2arbww9x</a><br/>Synced 6 W&B file(s), 1 media file(s), 37 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_054025-2arbww9x/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5dp1jx3f with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1563731510612403\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 27\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.046679883069579875\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 187\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 72\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 102\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 236\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_054528-5dp1jx3f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/5dp1jx3f\" target=\"_blank\">fine-sweep-17</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/27\n",
      "1139/1146 [============================>.] - ETA: 0s - loss: 13.1168INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_054528-5dp1jx3f/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_054528-5dp1jx3f/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 2ms/step - loss: 13.0519 - val_loss: 0.8242\n",
      "Epoch 2/27\n",
      "1138/1146 [============================>.] - ETA: 0s - loss: 0.7751INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_054528-5dp1jx3f/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_054528-5dp1jx3f/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.7759 - val_loss: 0.8193\n",
      "Epoch 3/27\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.7662 - val_loss: 1.0438\n",
      "Epoch 4/27\n",
      "1113/1146 [============================>.] - ETA: 0s - loss: 0.7720INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_054528-5dp1jx3f/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_054528-5dp1jx3f/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.7721 - val_loss: 0.7532\n",
      "Epoch 5/27\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.7829 - val_loss: 0.9567\n",
      "Epoch 6/27\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.8166 - val_loss: 0.9134\n",
      "Epoch 7/27\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.8840 - val_loss: 1.0643\n",
      "Epoch 8/27\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 3394305.2500 - val_loss: 32840.2188\n",
      "Epoch 9/27\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 9335.0674 - val_loss: 5768.8721\n",
      "Epoch 10/27\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 3153.2764 - val_loss: 3664.8201\n",
      "Epoch 11/27\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 1896.3624 - val_loss: 5109.7842\n",
      "Epoch 12/27\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 995.9938 - val_loss: 776.3598\n",
      "Epoch 13/27\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 590.9453 - val_loss: 663.3644\n",
      "Epoch 14/27\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 4403613.5000 - val_loss: 88474.0156\n",
      "Epoch 15/27\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 26738.0996 - val_loss: 20495.5449\n",
      "Epoch 16/27\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 9805.6826 - val_loss: 7423.3120\n",
      "Epoch 17/27\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 5295.7612 - val_loss: 2544.8364\n",
      "Epoch 18/27\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2991.8770 - val_loss: 1641.8031\n",
      "Epoch 19/27\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 3322244.7500 - val_loss: 40833.0586\n",
      "Epoch 20/27\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 23731.3906 - val_loss: 13018.9355\n",
      "Epoch 21/27\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 8726.1973 - val_loss: 5136.1899\n",
      "Epoch 22/27\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 4326.9058 - val_loss: 2641.1584\n",
      "Epoch 23/27\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2460.9824 - val_loss: 1838.3629\n",
      "Epoch 24/27\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 1534.8270 - val_loss: 1637.1077\n",
      "Epoch 25/27\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 843.6364 - val_loss: 646.1737\n",
      "Epoch 26/27\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1418978.6250 - val_loss: 39483988.0000\n",
      "Epoch 27/27\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 850744.9375 - val_loss: 8099.7988\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇██</td></tr><tr><td>loss</td><td>▁▁▁▁▁▁▁▆▁▁▁▁▁█▁▁▁▁▆▁▁▁▁▁▁▃▂</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>3</td></tr><tr><td>best_val_loss</td><td>0.75323</td></tr><tr><td>epoch</td><td>26</td></tr><tr><td>loss</td><td>850744.9375</td></tr><tr><td>val_loss</td><td>8099.79883</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">fine-sweep-17</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/5dp1jx3f\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/5dp1jx3f</a><br/>Synced 6 W&B file(s), 1 media file(s), 13 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_054528-5dp1jx3f/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: apuhhjjh with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2823285847987715\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 51\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.008659294529462248\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 247\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 189\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 87\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 111\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_054630-apuhhjjh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/apuhhjjh\" target=\"_blank\">worthy-sweep-18</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/51\n",
      "2286/2291 [============================>.] - ETA: 0s - loss: 0.9000INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_054630-apuhhjjh/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_054630-apuhhjjh/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 0.9000 - val_loss: 0.8097\n",
      "Epoch 2/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 30.3240 - val_loss: 0.9074\n",
      "Epoch 3/51\n",
      "2251/2291 [============================>.] - ETA: 0s - loss: 0.8412INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_054630-apuhhjjh/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_054630-apuhhjjh/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 0.8407 - val_loss: 0.7550\n",
      "Epoch 4/51\n",
      "2260/2291 [============================>.] - ETA: 0s - loss: 0.7691INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_054630-apuhhjjh/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_054630-apuhhjjh/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 0.7690 - val_loss: 0.7354\n",
      "Epoch 5/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7488 - val_loss: 0.7651\n",
      "Epoch 6/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7592 - val_loss: 0.7522\n",
      "Epoch 7/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7800 - val_loss: 0.7401\n",
      "Epoch 8/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 9.9410 - val_loss: 5.3186\n",
      "Epoch 9/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.9206 - val_loss: 0.7371\n",
      "Epoch 10/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7270 - val_loss: 0.7408\n",
      "Epoch 11/51\n",
      "2268/2291 [============================>.] - ETA: 0s - loss: 0.7358INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_054630-apuhhjjh/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_054630-apuhhjjh/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 0.7350 - val_loss: 0.7041\n",
      "Epoch 12/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7690 - val_loss: 0.7683\n",
      "Epoch 13/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7654 - val_loss: 0.7494\n",
      "Epoch 14/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7607 - val_loss: 1.0580\n",
      "Epoch 15/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 19.3026 - val_loss: 0.7207\n",
      "Epoch 16/51\n",
      "2260/2291 [============================>.] - ETA: 0s - loss: 0.7466INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_054630-apuhhjjh/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_054630-apuhhjjh/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 0.7461 - val_loss: 0.6882\n",
      "Epoch 17/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7201 - val_loss: 0.7178\n",
      "Epoch 18/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7418 - val_loss: 0.6974\n",
      "Epoch 19/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7541 - val_loss: 0.7415\n",
      "Epoch 20/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 33.1309 - val_loss: 1.2332\n",
      "Epoch 21/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.0057 - val_loss: 0.8385\n",
      "Epoch 22/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7778 - val_loss: 0.7540\n",
      "Epoch 23/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7517 - val_loss: 0.7105\n",
      "Epoch 24/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7456 - val_loss: 0.7308\n",
      "Epoch 25/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 30.2104 - val_loss: 0.8425\n",
      "Epoch 26/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.8326 - val_loss: 0.7427\n",
      "Epoch 27/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7449 - val_loss: 0.7227\n",
      "Epoch 28/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7406 - val_loss: 0.7832\n",
      "Epoch 29/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7430 - val_loss: 0.7703\n",
      "Epoch 30/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7731 - val_loss: 0.7961\n",
      "Epoch 31/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7625 - val_loss: 0.7165\n",
      "Epoch 32/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 10.4476 - val_loss: 0.7467\n",
      "Epoch 33/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7369 - val_loss: 0.7180\n",
      "Epoch 34/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7290 - val_loss: 0.7423\n",
      "Epoch 35/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7423 - val_loss: 0.7575\n",
      "Epoch 36/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7563 - val_loss: 0.7901\n",
      "Epoch 37/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 8.3973 - val_loss: 0.7631\n",
      "Epoch 38/51\n",
      "2270/2291 [============================>.] - ETA: 0s - loss: 0.7592INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_054630-apuhhjjh/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_054630-apuhhjjh/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 0.7587 - val_loss: 0.6836\n",
      "Epoch 39/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7113 - val_loss: 0.7080\n",
      "Epoch 40/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7231 - val_loss: 0.7631\n",
      "Epoch 41/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7471 - val_loss: 0.7495\n",
      "Epoch 42/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7475 - val_loss: 0.7472\n",
      "Epoch 43/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 34.1638 - val_loss: 0.7793\n",
      "Epoch 44/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7886 - val_loss: 0.9299\n",
      "Epoch 45/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7440 - val_loss: 0.7500\n",
      "Epoch 46/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7389 - val_loss: 0.7490\n",
      "Epoch 47/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7548 - val_loss: 0.9310\n",
      "Epoch 48/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 35.1936 - val_loss: 0.8030\n",
      "Epoch 49/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7815 - val_loss: 0.6917\n",
      "Epoch 50/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7303 - val_loss: 0.7259\n",
      "Epoch 51/51\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.7306 - val_loss: 0.7961\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▇▁▁▁▁▃▁▁▁▁▅▁▁▁█▁▁▁▇▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁█▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>37</td></tr><tr><td>best_val_loss</td><td>0.68363</td></tr><tr><td>epoch</td><td>50</td></tr><tr><td>loss</td><td>0.73064</td></tr><tr><td>val_loss</td><td>0.79613</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">worthy-sweep-18</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/apuhhjjh\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/apuhhjjh</a><br/>Synced 6 W&B file(s), 1 media file(s), 25 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_054630-apuhhjjh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3yxntxyx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5694649980998371\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 82\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.03297842922838725\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 183\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 76\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 119\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 92\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_054920-3yxntxyx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/3yxntxyx\" target=\"_blank\">apricot-sweep-19</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/82\n",
      "1123/1146 [============================>.] - ETA: 0s - loss: 1.4046INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_054920-3yxntxyx/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_054920-3yxntxyx/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 2ms/step - loss: 1.3950 - val_loss: 0.8523\n",
      "Epoch 2/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.8812 - val_loss: 0.9267\n",
      "Epoch 3/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.9077 - val_loss: 1.0352\n",
      "Epoch 4/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 370519.6250 - val_loss: 576.6581\n",
      "Epoch 5/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 558.6426 - val_loss: 377.9131\n",
      "Epoch 6/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 253.9695 - val_loss: 216.9294\n",
      "Epoch 7/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 158.5290 - val_loss: 329.1703\n",
      "Epoch 8/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 156767.4062 - val_loss: 1427.7811\n",
      "Epoch 9/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 865.4887 - val_loss: 317.7882\n",
      "Epoch 10/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 396.1442 - val_loss: 174.2122\n",
      "Epoch 11/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 190.7574 - val_loss: 84.5273\n",
      "Epoch 12/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 101.9185 - val_loss: 70.5629\n",
      "Epoch 13/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 61.8730 - val_loss: 21.2006\n",
      "Epoch 14/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 31.6704 - val_loss: 22.1411\n",
      "Epoch 15/82\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 17.1071 - val_loss: 10.1922\n",
      "Epoch 16/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 187763.6406 - val_loss: 1581.2024\n",
      "Epoch 17/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 1050.8765 - val_loss: 1040.8960\n",
      "Epoch 18/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 545.3040 - val_loss: 246.7688\n",
      "Epoch 19/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 287.4407 - val_loss: 138.6084\n",
      "Epoch 20/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 146.9042 - val_loss: 60.3858\n",
      "Epoch 21/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 83.6873 - val_loss: 150.4836\n",
      "Epoch 22/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 66057.7031 - val_loss: 4708653.0000\n",
      "Epoch 23/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 97036.5078 - val_loss: 1572.9261\n",
      "Epoch 24/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 595.0226 - val_loss: 454.1098\n",
      "Epoch 25/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 314.4165 - val_loss: 143.5596\n",
      "Epoch 26/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 168.0907 - val_loss: 103.1030\n",
      "Epoch 27/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 93.1575 - val_loss: 52.9911\n",
      "Epoch 28/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 46.3041 - val_loss: 18.8076\n",
      "Epoch 29/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 24.8365 - val_loss: 41.5151\n",
      "Epoch 30/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 137836.2188 - val_loss: 984.5081\n",
      "Epoch 31/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 570.7200 - val_loss: 267.0030\n",
      "Epoch 32/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 318.9609 - val_loss: 133.6619\n",
      "Epoch 33/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 172.3628 - val_loss: 108.1756\n",
      "Epoch 34/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 96.8739 - val_loss: 71.1956\n",
      "Epoch 35/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 52.8093 - val_loss: 56.8960\n",
      "Epoch 36/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 30.8250 - val_loss: 16.3151\n",
      "Epoch 37/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 191855.7812 - val_loss: 1309.1919\n",
      "Epoch 38/82\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 809.0901 - val_loss: 563.8146\n",
      "Epoch 39/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 380.6435 - val_loss: 141.7285\n",
      "Epoch 40/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 181.7465 - val_loss: 151.4774\n",
      "Epoch 41/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 1644.7623 - val_loss: 11861297.0000\n",
      "Epoch 42/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 253599.7031 - val_loss: 2390.1790\n",
      "Epoch 43/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 1176.8962 - val_loss: 1372.9979\n",
      "Epoch 44/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 574.7611 - val_loss: 281.0333\n",
      "Epoch 45/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 319.2751 - val_loss: 149.9996\n",
      "Epoch 46/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 178.0654 - val_loss: 97.1945\n",
      "Epoch 47/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 95.9692 - val_loss: 119.6932\n",
      "Epoch 48/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 55.8112 - val_loss: 32.0919\n",
      "Epoch 49/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 220006.8906 - val_loss: 867.1052\n",
      "Epoch 50/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 1170.6355 - val_loss: 405.1096\n",
      "Epoch 51/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 475.9567 - val_loss: 318.7929\n",
      "Epoch 52/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 279.3103 - val_loss: 118.9460\n",
      "Epoch 53/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 140.9461 - val_loss: 69.7549\n",
      "Epoch 54/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 85.7549 - val_loss: 41.7928\n",
      "Epoch 55/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 48.3973 - val_loss: 24.8414\n",
      "Epoch 56/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 31.5756 - val_loss: 13.2482\n",
      "Epoch 57/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 275317.4062 - val_loss: 5560.6650\n",
      "Epoch 58/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 2181.1243 - val_loss: 806.7166\n",
      "Epoch 59/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 921.4423 - val_loss: 649.9077\n",
      "Epoch 60/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 498.8718 - val_loss: 348.7774\n",
      "Epoch 61/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 314.7326 - val_loss: 195.8198\n",
      "Epoch 62/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 114415.5938 - val_loss: 195633.6875\n",
      "Epoch 63/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 5425.8979 - val_loss: 570.5298\n",
      "Epoch 64/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 598.6415 - val_loss: 275.4014\n",
      "Epoch 65/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 325.7998 - val_loss: 170.6967\n",
      "Epoch 66/82\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 179.9177 - val_loss: 64.7868\n",
      "Epoch 67/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 92.6311 - val_loss: 70.7512\n",
      "Epoch 68/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 52.5003 - val_loss: 28.3636\n",
      "Epoch 69/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 31.1185 - val_loss: 14.7182\n",
      "Epoch 70/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 18.1452 - val_loss: 12.0571\n",
      "Epoch 71/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 173372.7188 - val_loss: 795.6827\n",
      "Epoch 72/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 702.9722 - val_loss: 516.6472\n",
      "Epoch 73/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 366.4737 - val_loss: 211.6823\n",
      "Epoch 74/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 207.2942 - val_loss: 86.4363\n",
      "Epoch 75/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 131.2972 - val_loss: 68.5980\n",
      "Epoch 76/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 78.1550 - val_loss: 27.8372\n",
      "Epoch 77/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 38.6353 - val_loss: 18.9550\n",
      "Epoch 78/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 21.7546 - val_loss: 15.4781\n",
      "Epoch 79/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 13.0261 - val_loss: 9.6568\n",
      "Epoch 80/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 528290.6250 - val_loss: 3148.3335\n",
      "Epoch 81/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 1876.5156 - val_loss: 895.1577\n",
      "Epoch 82/82\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 1160.9143 - val_loss: 555.0178\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▃▁▁▅▁▁▁▁▁▇▁▁▁▁▁▁█▁▁▁▁▁▁▅▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▂▁▁▃▁▁▂▁▁▁▂▁▄▁▁▁▂▁▁█▂▁▂▁▁▁▂▁▁▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.85233</td></tr><tr><td>epoch</td><td>81</td></tr><tr><td>loss</td><td>1160.91431</td></tr><tr><td>val_loss</td><td>555.01782</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">apricot-sweep-19</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/3yxntxyx\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/3yxntxyx</a><br/>Synced 6 W&B file(s), 1 media file(s), 5 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_054920-3yxntxyx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: m9vvdxpm with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5294109874278685\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.05303855960596382\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 235\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 72\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 138\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 211\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 94\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_055153-m9vvdxpm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/m9vvdxpm\" target=\"_blank\">dutiful-sweep-20</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1525/1527 [============================>.] - ETA: 0s - loss: 41.1767INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_055153-m9vvdxpm/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_055153-m9vvdxpm/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 3s 2ms/step - loss: 41.1307 - val_loss: 0.8453\n",
      "Epoch 2/50\n",
      "1521/1527 [============================>.] - ETA: 0s - loss: 0.8270INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_055153-m9vvdxpm/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_055153-m9vvdxpm/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.8267 - val_loss: 0.7409\n",
      "Epoch 3/50\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 0.8126 - val_loss: 0.8137\n",
      "Epoch 4/50\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 0.8337 - val_loss: 0.7757\n",
      "Epoch 5/50\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 0.8488 - val_loss: 0.8034\n",
      "Epoch 6/50\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 0.9174 - val_loss: 0.9195\n",
      "Epoch 7/50\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 9771631.0000 - val_loss: 20498.8730\n",
      "Epoch 8/50\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 28009.5312 - val_loss: 8610.4463\n",
      "Epoch 9/50\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 12203.4033 - val_loss: 5480.1172\n",
      "Epoch 10/50\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 5032.4990 - val_loss: 1722.0125\n",
      "Epoch 11/50\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 12611893.0000 - val_loss: 1417484.5000\n",
      "Epoch 12/50\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 202659.9688 - val_loss: 28658.7617\n",
      "Epoch 13/50\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 48598.4180 - val_loss: 12876.8223\n",
      "Epoch 14/50\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 19740.5020 - val_loss: 7311.2427\n",
      "Epoch 15/50\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 7898.5259 - val_loss: 6014.3257\n",
      "Epoch 16/50\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 8835734.0000 - val_loss: 20680.0508\n",
      "Epoch 17/50\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 27288.0293 - val_loss: 11154.8418\n",
      "Epoch 18/50\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 13639.8232 - val_loss: 5246.8057\n",
      "Epoch 19/50\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 6413.9048 - val_loss: 3013.9197\n",
      "Epoch 20/50\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 18197846.0000 - val_loss: 108012.8828\n",
      "Epoch 21/50\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 92808.2969 - val_loss: 30571.8652\n",
      "Epoch 22/50\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 38500.5625 - val_loss: 17188.4121\n",
      "Epoch 23/50\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 23291.0332 - val_loss: 9045.2539\n",
      "Epoch 24/50\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 11638.9814 - val_loss: 3047.4856\n",
      "Epoch 25/50\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 4815.2515 - val_loss: 1875.6764\n",
      "Epoch 26/50\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 2300.8044 - val_loss: 720.2574\n",
      "Epoch 27/50\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 18468706.0000 - val_loss: 89007.2109\n",
      "Epoch 28/50\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 87737.2578 - val_loss: 39398.5859\n",
      "Epoch 29/50\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 41154.6758 - val_loss: 12146.0459\n",
      "Epoch 30/50\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 18175.0645 - val_loss: 8052.5298\n",
      "Epoch 31/50\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 8606.8428 - val_loss: 3726.5696\n",
      "Epoch 32/50\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 11897211.0000 - val_loss: 6075261.5000\n",
      "Epoch 33/50\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 218864.9688 - val_loss: 19996.2598\n",
      "Epoch 34/50\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 29870.7383 - val_loss: 11213.7939\n",
      "Epoch 35/50\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 15101.3594 - val_loss: 8848.9756\n",
      "Epoch 36/50\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 8336.7832 - val_loss: 2744.8994\n",
      "Epoch 37/50\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 14374768.0000 - val_loss: 172157.7969\n",
      "Epoch 38/50\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 85622.1172 - val_loss: 40423.7734\n",
      "Epoch 39/50\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 38536.2852 - val_loss: 13683.3301\n",
      "Epoch 40/50\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 18227.3496 - val_loss: 10069.3037\n",
      "Epoch 41/50\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 8334.4541 - val_loss: 2513.8452\n",
      "Epoch 42/50\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 13236970.0000 - val_loss: 61834.4570\n",
      "Epoch 43/50\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 88789.7109 - val_loss: 35424.1641\n",
      "Epoch 44/50\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 34389.8945 - val_loss: 11001.9102\n",
      "Epoch 45/50\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 16596.5078 - val_loss: 9840.5820\n",
      "Epoch 46/50\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 6532144.0000 - val_loss: 34514.6172\n",
      "Epoch 47/50\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 31930.6699 - val_loss: 11949.0801\n",
      "Epoch 48/50\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 13915.5986 - val_loss: 5711.4653\n",
      "Epoch 49/50\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 6681.0288 - val_loss: 4052.6133\n",
      "Epoch 50/50\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 3363.7964 - val_loss: 1208.2598\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▁▁▁▅▁▁▆▁▁▁▄▁▁▁▁▁▁▁▁█▁▁▁▆▁▁▁▆▁▁▁▆▁▁▃▁▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>1</td></tr><tr><td>best_val_loss</td><td>0.74091</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>loss</td><td>3363.79639</td></tr><tr><td>val_loss</td><td>1208.25977</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">dutiful-sweep-20</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/m9vvdxpm\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/m9vvdxpm</a><br/>Synced 6 W&B file(s), 1 media file(s), 9 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_055153-m9vvdxpm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1vc9e0cv with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.29971472974708313\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 92\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.06577280830998228\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 169\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 74\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 140\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 244\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_055402-1vc9e0cv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/1vc9e0cv\" target=\"_blank\">apricot-sweep-21</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/92\n",
      "1117/1146 [============================>.] - ETA: 0s - loss: 306.8317INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_055402-1vc9e0cv/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_055402-1vc9e0cv/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 3ms/step - loss: 299.3412 - val_loss: 1.2527\n",
      "Epoch 2/92\n",
      "1119/1146 [============================>.] - ETA: 0s - loss: 0.9449INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_055402-1vc9e0cv/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_055402-1vc9e0cv/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.9429 - val_loss: 0.7834\n",
      "Epoch 3/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.8434 - val_loss: 0.8047\n",
      "Epoch 4/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.7959 - val_loss: 1.3430\n",
      "Epoch 5/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.7745 - val_loss: 0.9001\n",
      "Epoch 6/92\n",
      "1133/1146 [============================>.] - ETA: 0s - loss: 0.7788INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_055402-1vc9e0cv/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_055402-1vc9e0cv/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.7779 - val_loss: 0.7564\n",
      "Epoch 7/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 20224394.0000 - val_loss: 68801.0547\n",
      "Epoch 8/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 45601.1133 - val_loss: 131936.9219\n",
      "Epoch 9/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 15093.8330 - val_loss: 8025.2290\n",
      "Epoch 10/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 7786.0850 - val_loss: 10625.9209\n",
      "Epoch 11/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 6746.2983 - val_loss: 1999.6234\n",
      "Epoch 12/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 12526155.0000 - val_loss: 134598.6250\n",
      "Epoch 13/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 33821.2148 - val_loss: 71779.8672\n",
      "Epoch 14/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 17839.7910 - val_loss: 12884.1504\n",
      "Epoch 15/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 7635.9429 - val_loss: 4320.0391\n",
      "Epoch 16/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 4515.9092 - val_loss: 1914.7078\n",
      "Epoch 17/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2485.7485 - val_loss: 2291.1863\n",
      "Epoch 18/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 140651280.0000 - val_loss: 2253767.0000\n",
      "Epoch 19/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1154581.8750 - val_loss: 325706.9062\n",
      "Epoch 20/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 296372.3125 - val_loss: 1507285.0000\n",
      "Epoch 21/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 155558.3906 - val_loss: 151509.9062\n",
      "Epoch 22/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 90443.5469 - val_loss: 40356.3789\n",
      "Epoch 23/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 51700.4648 - val_loss: 45294.8008\n",
      "Epoch 24/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 165284512.0000 - val_loss: 4664573.0000\n",
      "Epoch 25/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1159693.5000 - val_loss: 361580.3438\n",
      "Epoch 26/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 461019.5625 - val_loss: 286190.1875\n",
      "Epoch 27/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 216857.9062 - val_loss: 100643.2500\n",
      "Epoch 28/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 125100.4297 - val_loss: 64504.3828\n",
      "Epoch 29/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 79377.2812 - val_loss: 32660.3652\n",
      "Epoch 30/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 58225.9336 - val_loss: 29963.7090\n",
      "Epoch 31/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 29501.2598 - val_loss: 17158.1523\n",
      "Epoch 32/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 27897904.0000 - val_loss: 261217.9531\n",
      "Epoch 33/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 122990.7891 - val_loss: 91218.3047\n",
      "Epoch 34/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 60495.5781 - val_loss: 47908.4258\n",
      "Epoch 35/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 34877.6328 - val_loss: 17779.8301\n",
      "Epoch 36/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 18864.6074 - val_loss: 11270.4873\n",
      "Epoch 37/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 249041712.0000 - val_loss: 9116510.0000\n",
      "Epoch 38/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1968865.8750 - val_loss: 843495.5625\n",
      "Epoch 39/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 587328.8125 - val_loss: 551298.3125\n",
      "Epoch 40/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 329828.9375 - val_loss: 185922.1719\n",
      "Epoch 41/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 206210.8281 - val_loss: 116318.6484\n",
      "Epoch 42/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 132639.4062 - val_loss: 173837.5625\n",
      "Epoch 43/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 83281.6641 - val_loss: 50714.1016\n",
      "Epoch 44/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 39205.1250 - val_loss: 16644.9023\n",
      "Epoch 45/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 142470240.0000 - val_loss: 1168579.7500\n",
      "Epoch 46/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 927927.6250 - val_loss: 437709.6875\n",
      "Epoch 47/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 442849.2188 - val_loss: 304059.1875\n",
      "Epoch 48/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 277116.6250 - val_loss: 106777.9453\n",
      "Epoch 49/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 138862.3906 - val_loss: 66635.5312\n",
      "Epoch 50/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 82300.4453 - val_loss: 33389.9297\n",
      "Epoch 51/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 58940236.0000 - val_loss: 918920.7500\n",
      "Epoch 52/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 565742.2500 - val_loss: 1000726.9375\n",
      "Epoch 53/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 222783.6094 - val_loss: 143733.0000\n",
      "Epoch 54/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 138313.7188 - val_loss: 144241.6094\n",
      "Epoch 55/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 93348.9062 - val_loss: 59280.9336\n",
      "Epoch 56/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 60472.7461 - val_loss: 24614.6504\n",
      "Epoch 57/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 108830272.0000 - val_loss: 400882.0000\n",
      "Epoch 58/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 530670.9375 - val_loss: 284306.1875\n",
      "Epoch 59/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 300613.6562 - val_loss: 195721.7344\n",
      "Epoch 60/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 174648.1562 - val_loss: 103183.5312\n",
      "Epoch 61/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 129924.6641 - val_loss: 55337.7148\n",
      "Epoch 62/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 72344432.0000 - val_loss: 4091424.5000\n",
      "Epoch 63/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1044945.0000 - val_loss: 397966.8125\n",
      "Epoch 64/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 350923.2188 - val_loss: 332261.1875\n",
      "Epoch 65/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 223340.8906 - val_loss: 81326.6875\n",
      "Epoch 66/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 111082.7500 - val_loss: 76858.4297\n",
      "Epoch 67/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 80692.5000 - val_loss: 47034.3672\n",
      "Epoch 68/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 37667.5117 - val_loss: 24012.2832\n",
      "Epoch 69/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 64045732.0000 - val_loss: 1996224.0000\n",
      "Epoch 70/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 754250.1875 - val_loss: 381621.4688\n",
      "Epoch 71/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 269790.4062 - val_loss: 210051.3750\n",
      "Epoch 72/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 138045.3906 - val_loss: 92152.6328\n",
      "Epoch 73/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 87083.9062 - val_loss: 119331.1562\n",
      "Epoch 74/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 66700.7656 - val_loss: 45892.1055\n",
      "Epoch 75/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 36384.7617 - val_loss: 30769.3770\n",
      "Epoch 76/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 213072128.0000 - val_loss: 1390533.7500\n",
      "Epoch 77/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1026560.6875 - val_loss: 447935.6250\n",
      "Epoch 78/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 585324.6250 - val_loss: 1975522.3750\n",
      "Epoch 79/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 378462.0625 - val_loss: 187166.9375\n",
      "Epoch 80/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 208188.5312 - val_loss: 1304895.0000\n",
      "Epoch 81/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 149478.8750 - val_loss: 99434.7578\n",
      "Epoch 82/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8486150.0000 - val_loss: 232771552.0000\n",
      "Epoch 83/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 46195220.0000 - val_loss: 2821253.2500\n",
      "Epoch 84/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 281507.4062 - val_loss: 122846.0000\n",
      "Epoch 85/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 139174.5156 - val_loss: 68387.8516\n",
      "Epoch 86/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 86800.8672 - val_loss: 52083.2344\n",
      "Epoch 87/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 47011.6562 - val_loss: 38542.4766\n",
      "Epoch 88/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 29978.7402 - val_loss: 13348.6797\n",
      "Epoch 89/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 16412.7090 - val_loss: 9484.5850\n",
      "Epoch 90/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 11325.0410 - val_loss: 7018.2402\n",
      "Epoch 91/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 17256428.0000 - val_loss: 15140436992.0000\n",
      "Epoch 92/92\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 110935000.0000 - val_loss: 499250.6250\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be0be1267f0e4c648c132d3886b66856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.962 MB of 3.962 MB uploaded (0.016 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▁▁▁▂▁▁▁▁█▁▁▁▁▁▁▁▁▇▁▁▁▁▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▆</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>5</td></tr><tr><td>best_val_loss</td><td>0.75636</td></tr><tr><td>epoch</td><td>91</td></tr><tr><td>loss</td><td>110935000.0</td></tr><tr><td>val_loss</td><td>499250.625</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">apricot-sweep-21</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/1vc9e0cv\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/1vc9e0cv</a><br/>Synced 6 W&B file(s), 1 media file(s), 13 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_055402-1vc9e0cv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fn778zd3 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.17840494667640008\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 63\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.024346964440533636\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 196\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 129\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 102\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 199\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 184\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_055721-fn778zd3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/fn778zd3\" target=\"_blank\">smooth-sweep-22</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/63\n",
      "2247/2291 [============================>.] - ETA: 0s - loss: 1.9565INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_055721-fn778zd3/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_055721-fn778zd3/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1.9361 - val_loss: 0.9013\n",
      "Epoch 2/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.8555 - val_loss: 1.0436\n",
      "Epoch 3/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 172207.1094 - val_loss: 33403.7070\n",
      "Epoch 4/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2367.5503 - val_loss: 484.3769\n",
      "Epoch 5/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 320.7297 - val_loss: 109.8535\n",
      "Epoch 6/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 79.8709 - val_loss: 27.8901\n",
      "Epoch 7/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 37.9608 - val_loss: 16.9648\n",
      "Epoch 8/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 55394.4375 - val_loss: 399.4877\n",
      "Epoch 9/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 253.8448 - val_loss: 146.6162\n",
      "Epoch 10/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 88.3999 - val_loss: 55.6080\n",
      "Epoch 11/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 183568.8281 - val_loss: 1263.6378\n",
      "Epoch 12/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 675.9226 - val_loss: 305.5955\n",
      "Epoch 13/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 215.8794 - val_loss: 135.3655\n",
      "Epoch 14/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 196651.8438 - val_loss: 7374.6191\n",
      "Epoch 15/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1851.7262 - val_loss: 886.0441\n",
      "Epoch 16/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 522.7859 - val_loss: 195.2766\n",
      "Epoch 17/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 213.6406 - val_loss: 67.4814\n",
      "Epoch 18/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 224138.4062 - val_loss: 2174.5710\n",
      "Epoch 19/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1039.3872 - val_loss: 310.2761\n",
      "Epoch 20/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 339.0237 - val_loss: 197.9390\n",
      "Epoch 21/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 88253.6484 - val_loss: 1315.2849\n",
      "Epoch 22/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 697.3983 - val_loss: 417.2326\n",
      "Epoch 23/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 202.8255 - val_loss: 132.3378\n",
      "Epoch 24/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 145491.8594 - val_loss: 877.5353\n",
      "Epoch 25/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 790.2921 - val_loss: 351.9581\n",
      "Epoch 26/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 275.6617 - val_loss: 225.5086\n",
      "Epoch 27/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 121.7066 - val_loss: 39.9922\n",
      "Epoch 28/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 58755.7812 - val_loss: 394.7032\n",
      "Epoch 29/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 295.1682 - val_loss: 159.6030\n",
      "Epoch 30/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 113.6966 - val_loss: 52.7483\n",
      "Epoch 31/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 43.0987 - val_loss: 19.2089\n",
      "Epoch 32/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 393565.8438 - val_loss: 4588.1948\n",
      "Epoch 33/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2345.0667 - val_loss: 879.8558\n",
      "Epoch 34/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 706.9521 - val_loss: 368.1462\n",
      "Epoch 35/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 90135.2969 - val_loss: 1227.9249\n",
      "Epoch 36/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 899.6313 - val_loss: 272.4135\n",
      "Epoch 37/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 345.7934 - val_loss: 156.2453\n",
      "Epoch 38/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 36642.8242 - val_loss: 339.6551\n",
      "Epoch 39/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 208.0289 - val_loss: 144.2434\n",
      "Epoch 40/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 88.4252 - val_loss: 38.6889\n",
      "Epoch 41/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 34.1216 - val_loss: 10.5674\n",
      "Epoch 42/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 527895.5000 - val_loss: 8464.9648\n",
      "Epoch 43/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1684.1721 - val_loss: 889.4268\n",
      "Epoch 44/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 622.2983 - val_loss: 300.1665\n",
      "Epoch 45/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 249.6248 - val_loss: 120.0016\n",
      "Epoch 46/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 150222.0625 - val_loss: 1612.9713\n",
      "Epoch 47/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1163.0072 - val_loss: 439.1894\n",
      "Epoch 48/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 401.5485 - val_loss: 193.8028\n",
      "Epoch 49/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 370300.1250 - val_loss: 9351.5674\n",
      "Epoch 50/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 4680.3936 - val_loss: 1843.9192\n",
      "Epoch 51/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1218.4012 - val_loss: 390.1460\n",
      "Epoch 52/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 475.6420 - val_loss: 204.9190\n",
      "Epoch 53/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 118233.6953 - val_loss: 903.4519\n",
      "Epoch 54/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 716.2607 - val_loss: 1627.3333\n",
      "Epoch 55/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 304.7529 - val_loss: 160.5677\n",
      "Epoch 56/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 122.4978 - val_loss: 55.7881\n",
      "Epoch 57/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 89328.2422 - val_loss: 737.5862\n",
      "Epoch 58/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 643.3212 - val_loss: 294.3465\n",
      "Epoch 59/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 329604.0000 - val_loss: 20838.5605\n",
      "Epoch 60/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 6207.6025 - val_loss: 1533.1794\n",
      "Epoch 61/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1101.8722 - val_loss: 420.4456\n",
      "Epoch 62/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 503.0473 - val_loss: 245.0207\n",
      "Epoch 63/63\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 182762.8594 - val_loss: 6911.7139\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49bad2ede273483d9b1c3f57daeabaed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='2.665 MB of 2.665 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>loss</td><td>▁▁▁▁▁▂▁▁▁▁▁▄▁▂▁▃▁▂▁▁▆▁▂▁▁▁█▁▁▁▁▁▁▃▁▁▁▅▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▃▁▁▁▁▁▄▁▁▁▁▂▁▁▁▁▁█▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.90132</td></tr><tr><td>epoch</td><td>62</td></tr><tr><td>loss</td><td>182762.85938</td></tr><tr><td>val_loss</td><td>6911.71387</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">smooth-sweep-22</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/fn778zd3\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/fn778zd3</a><br/>Synced 6 W&B file(s), 1 media file(s), 5 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_055721-fn778zd3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mdrdcvgm with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.47652867489961814\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.08638326346185606\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 186\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 239\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 228\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 65\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_060103-mdrdcvgm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/mdrdcvgm\" target=\"_blank\">daily-sweep-23</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1146/1146 [==============================] - ETA: 0s - loss: 3259.3757INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_060103-mdrdcvgm/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_060103-mdrdcvgm/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 4s 3ms/step - loss: 3259.3757 - val_loss: 4.6557\n",
      "Epoch 2/100\n",
      "1122/1146 [============================>.] - ETA: 0s - loss: 2.7093INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_060103-mdrdcvgm/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_060103-mdrdcvgm/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 3ms/step - loss: 2.6882 - val_loss: 1.3661\n",
      "Epoch 3/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1.5811 - val_loss: 1.6785\n",
      "Epoch 4/100\n",
      "1143/1146 [============================>.] - ETA: 0s - loss: 1.3016INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_060103-mdrdcvgm/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_060103-mdrdcvgm/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 3ms/step - loss: 1.3015 - val_loss: 1.1613\n",
      "Epoch 5/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1020504320.0000 - val_loss: 2816365.2500\n",
      "Epoch 6/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2771944.5000 - val_loss: 860149.1875\n",
      "Epoch 7/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1336558.6250 - val_loss: 236596.5625\n",
      "Epoch 8/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 600855.1875 - val_loss: 236201.3750\n",
      "Epoch 9/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 469663.2812 - val_loss: 718217.0625\n",
      "Epoch 10/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 158309.8594 - val_loss: 75684.1016\n",
      "Epoch 11/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 201367264.0000 - val_loss: 28957837312.0000\n",
      "Epoch 12/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1219169408.0000 - val_loss: 3765441.7500\n",
      "Epoch 13/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 4567105.5000 - val_loss: 1321786.1250\n",
      "Epoch 14/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2123977.0000 - val_loss: 1260054.1250\n",
      "Epoch 15/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1016874.1875 - val_loss: 957110.7500\n",
      "Epoch 16/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 495588.6875 - val_loss: 177915.8125\n",
      "Epoch 17/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 464385024.0000 - val_loss: 5522668.5000\n",
      "Epoch 18/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 3543297.0000 - val_loss: 1922814.3750\n",
      "Epoch 19/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1142368.0000 - val_loss: 613554.9375\n",
      "Epoch 20/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 604492.7500 - val_loss: 423299.1875\n",
      "Epoch 21/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 385486.9062 - val_loss: 415220.8750\n",
      "Epoch 22/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 202421.6406 - val_loss: 163691.2500\n",
      "Epoch 23/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 129131.0078 - val_loss: 323026.8750\n",
      "Epoch 24/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 459382336.0000 - val_loss: 2092593.2500\n",
      "Epoch 25/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1533726.3750 - val_loss: 782133.3750\n",
      "Epoch 26/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 727400.4375 - val_loss: 450082.0625\n",
      "Epoch 27/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 400541.7812 - val_loss: 208869.3438\n",
      "Epoch 28/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 229035.5938 - val_loss: 113478.0625\n",
      "Epoch 29/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 122253.8203 - val_loss: 63272.4297\n",
      "Epoch 30/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1185871360.0000 - val_loss: 6023708.0000\n",
      "Epoch 31/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 7411433.0000 - val_loss: 2577330.0000\n",
      "Epoch 32/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2619454.0000 - val_loss: 1497904.6250\n",
      "Epoch 33/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1557728.6250 - val_loss: 753835.3750\n",
      "Epoch 34/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 795641.4375 - val_loss: 338875.0625\n",
      "Epoch 35/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 412711.2812 - val_loss: 187979.0781\n",
      "Epoch 36/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 420988.5000 - val_loss: 78849.3047\n",
      "Epoch 37/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 90097.4844 - val_loss: 73436.2266\n",
      "Epoch 38/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 216318.5625 - val_loss: 19544.6758\n",
      "Epoch 39/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 19289.0254 - val_loss: 6927.7007\n",
      "Epoch 40/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 16181.9395 - val_loss: 9336.6582\n",
      "Epoch 41/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 511264672.0000 - val_loss: 4436420.0000\n",
      "Epoch 42/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1605842.6250 - val_loss: 939120.6250\n",
      "Epoch 43/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 925192.4375 - val_loss: 1074324.0000\n",
      "Epoch 44/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 554265.5625 - val_loss: 237573.5312\n",
      "Epoch 45/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 319723.5312 - val_loss: 165313.2969\n",
      "Epoch 46/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 180439.3594 - val_loss: 106341.5781\n",
      "Epoch 47/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 111382.8672 - val_loss: 177148.1250\n",
      "Epoch 48/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 3562646528.0000 - val_loss: 99399544.0000\n",
      "Epoch 49/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 32499010.0000 - val_loss: 14842338.0000\n",
      "Epoch 50/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 12995478.0000 - val_loss: 3350360.0000\n",
      "Epoch 51/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 6157666.5000 - val_loss: 3892294.5000\n",
      "Epoch 52/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 3422072.2500 - val_loss: 1607842.0000\n",
      "Epoch 53/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1762196.3750 - val_loss: 900549.3750\n",
      "Epoch 54/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 968201.6250 - val_loss: 351641.0938\n",
      "Epoch 55/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 890646208.0000 - val_loss: 2703492.2500\n",
      "Epoch 56/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 3782097.5000 - val_loss: 1661042.7500\n",
      "Epoch 57/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1908803.6250 - val_loss: 825984.6875\n",
      "Epoch 58/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1062625.8750 - val_loss: 492905.3438\n",
      "Epoch 59/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 523621664.0000 - val_loss: 4486309.5000\n",
      "Epoch 60/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2869353.7500 - val_loss: 1965997.7500\n",
      "Epoch 61/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1461474.5000 - val_loss: 847561.2500\n",
      "Epoch 62/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 821109.1250 - val_loss: 620967.0000\n",
      "Epoch 63/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 415712.8125 - val_loss: 245478.7500\n",
      "Epoch 64/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 237098.0781 - val_loss: 117326.2109\n",
      "Epoch 65/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 122384.5703 - val_loss: 47269.6484\n",
      "Epoch 66/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 848831552.0000 - val_loss: 6001668.5000\n",
      "Epoch 67/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 4908021.5000 - val_loss: 1734232.2500\n",
      "Epoch 68/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2002356.7500 - val_loss: 632020.3750\n",
      "Epoch 69/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1295187.7500 - val_loss: 545774.4375\n",
      "Epoch 70/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 794908.3750 - val_loss: 893988.8750\n",
      "Epoch 71/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 454468.9688 - val_loss: 224848.2656\n",
      "Epoch 72/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 254457.2188 - val_loss: 422912.6875\n",
      "Epoch 73/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 168432.1719 - val_loss: 81281.3359\n",
      "Epoch 74/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 608947712.0000 - val_loss: 4376887.5000\n",
      "Epoch 75/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2308514.0000 - val_loss: 867162.6250\n",
      "Epoch 76/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1127683.1250 - val_loss: 556760.6875\n",
      "Epoch 77/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1114341.2500 - val_loss: 741853.0000\n",
      "Epoch 78/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 305189.7188 - val_loss: 101590.0703\n",
      "Epoch 79/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 132708.4219 - val_loss: 85507.4922\n",
      "Epoch 80/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 112872.4609 - val_loss: 117593.6484\n",
      "Epoch 81/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1500806144.0000 - val_loss: 14759514.0000\n",
      "Epoch 82/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 13494127.0000 - val_loss: 3956942.2500\n",
      "Epoch 83/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 5395988.0000 - val_loss: 2257337.0000\n",
      "Epoch 84/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2551432.5000 - val_loss: 1029645.5625\n",
      "Epoch 85/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1442514.7500 - val_loss: 838759.4375\n",
      "Epoch 86/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 228091056.0000 - val_loss: 7568076.5000\n",
      "Epoch 87/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 3693668.0000 - val_loss: 1156901.1250\n",
      "Epoch 88/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1078335.1250 - val_loss: 604118.8125\n",
      "Epoch 89/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 628181.3750 - val_loss: 290862.4375\n",
      "Epoch 90/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 355828.5938 - val_loss: 252239.8906\n",
      "Epoch 91/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 175194.4219 - val_loss: 85798.8281\n",
      "Epoch 92/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 88827.6172 - val_loss: 60724.6836\n",
      "Epoch 93/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 69202.5000 - val_loss: 40116.4727\n",
      "Epoch 94/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 729577216.0000 - val_loss: 3819329.7500\n",
      "Epoch 95/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 3904977.0000 - val_loss: 1517848.2500\n",
      "Epoch 96/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1837443.2500 - val_loss: 1374313.5000\n",
      "Epoch 97/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1006768.9375 - val_loss: 503155.6875\n",
      "Epoch 98/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 577142.0625 - val_loss: 268378.3438\n",
      "Epoch 99/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 363997.9375 - val_loss: 231989.0469\n",
      "Epoch 100/100\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 327601.9688 - val_loss: 138790.6094\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▁▁▃▁▁▁▁▁▁▁▁▁▁▁▆▁▁▁▁▁▁▆▁▁▁▁▁▇▁▁▁▁▁▁▁█▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>3</td></tr><tr><td>best_val_loss</td><td>1.16128</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>loss</td><td>327601.96875</td></tr><tr><td>val_loss</td><td>138790.60938</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">daily-sweep-23</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/mdrdcvgm\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/mdrdcvgm</a><br/>Synced 6 W&B file(s), 1 media file(s), 13 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_060103-mdrdcvgm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wxgexrgv with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4685677516522509\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 65\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.062167063579884656\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 167\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 255\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 76\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 93\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 176\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_060519-wxgexrgv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/wxgexrgv\" target=\"_blank\">fancy-sweep-24</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/65\n",
      "4574/4581 [============================>.] - ETA: 0s - loss: 44.4097INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_060519-wxgexrgv/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_060519-wxgexrgv/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4581/4581 [==============================] - 6s 1ms/step - loss: 44.3508 - val_loss: 0.9068\n",
      "Epoch 2/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 8974220.0000 - val_loss: 127569.9766\n",
      "Epoch 3/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 42463.5273 - val_loss: 19596.1680\n",
      "Epoch 4/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 7604005.0000 - val_loss: 16974.5996\n",
      "Epoch 5/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 13489.9160 - val_loss: 2171.8994\n",
      "Epoch 6/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 15779675.0000 - val_loss: 55299.9336\n",
      "Epoch 7/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 43046.4297 - val_loss: 6776.1592\n",
      "Epoch 8/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 32417362.0000 - val_loss: 183049.8438\n",
      "Epoch 9/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 14843575.0000 - val_loss: 234627.7031\n",
      "Epoch 10/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 100947.1875 - val_loss: 19807.5195\n",
      "Epoch 11/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 14457650.0000 - val_loss: 100880.2812\n",
      "Epoch 12/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 5643814.0000 - val_loss: 210669.5312\n",
      "Epoch 13/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 81633.8672 - val_loss: 15041.0547\n",
      "Epoch 14/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 5399927.0000 - val_loss: 23819.9004\n",
      "Epoch 15/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 10168623.0000 - val_loss: 731822.4375\n",
      "Epoch 16/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 182047.6562 - val_loss: 39996.7148\n",
      "Epoch 17/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 95648488.0000 - val_loss: 1804300.7500\n",
      "Epoch 18/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 738874.6250 - val_loss: 79775.3906\n",
      "Epoch 19/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 36063688.0000 - val_loss: 181443.4062\n",
      "Epoch 20/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 143923.7969 - val_loss: 50223.2266\n",
      "Epoch 21/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 29429620.0000 - val_loss: 129998.5781\n",
      "Epoch 22/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 31596352.0000 - val_loss: 439771.9688\n",
      "Epoch 23/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 310159.1875 - val_loss: 111724.3672\n",
      "Epoch 24/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 7465844.5000 - val_loss: 76726.6797\n",
      "Epoch 25/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 60329.1719 - val_loss: 19182.3281\n",
      "Epoch 26/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 38851628.0000 - val_loss: 174582.2500\n",
      "Epoch 27/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 28184708.0000 - val_loss: 1196392.8750\n",
      "Epoch 28/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 439018.6562 - val_loss: 124624.9688\n",
      "Epoch 29/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 3712584.2500 - val_loss: 44050.3281\n",
      "Epoch 30/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 24059.4062 - val_loss: 5204.8066\n",
      "Epoch 31/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 11384895.0000 - val_loss: 67730.6641\n",
      "Epoch 32/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 25822210.0000 - val_loss: 1492679.8750\n",
      "Epoch 33/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 445893.1250 - val_loss: 73094.3984\n",
      "Epoch 34/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 13620776.0000 - val_loss: 186184.2031\n",
      "Epoch 35/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 106819.6172 - val_loss: 20383.7676\n",
      "Epoch 36/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 13317490.0000 - val_loss: 158177.7812\n",
      "Epoch 37/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 93279.5859 - val_loss: 12742.2607\n",
      "Epoch 38/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 8121209.0000 - val_loss: 60288.7109\n",
      "Epoch 39/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 61636.0078 - val_loss: 4685.9087\n",
      "Epoch 40/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 23763972.0000 - val_loss: 145261.6406\n",
      "Epoch 41/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 80360.1562 - val_loss: 11963.8711\n",
      "Epoch 42/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 24852100.0000 - val_loss: 318879.8438\n",
      "Epoch 43/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 205739.0312 - val_loss: 35171.7070\n",
      "Epoch 44/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 11718890.0000 - val_loss: 191738.2656\n",
      "Epoch 45/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 131942.4062 - val_loss: 19130.8633\n",
      "Epoch 46/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 10893232.0000 - val_loss: 332902.1875\n",
      "Epoch 47/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 165769.1562 - val_loss: 32931.8945\n",
      "Epoch 48/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 33804676.0000 - val_loss: 392816.5312\n",
      "Epoch 49/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 236805.7969 - val_loss: 67566.6406\n",
      "Epoch 50/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 7494840.5000 - val_loss: 320609.4062\n",
      "Epoch 51/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 136496.6562 - val_loss: 25712.3477\n",
      "Epoch 52/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 12772181.0000 - val_loss: 224573.7031\n",
      "Epoch 53/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 130094.4844 - val_loss: 25487.8633\n",
      "Epoch 54/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 14622164.0000 - val_loss: 149429.0625\n",
      "Epoch 55/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 94763.0625 - val_loss: 18129.0312\n",
      "Epoch 56/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 19452514.0000 - val_loss: 109826.8906\n",
      "Epoch 57/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 96533.7969 - val_loss: 29402.0312\n",
      "Epoch 58/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 17163888.0000 - val_loss: 95303.7656\n",
      "Epoch 59/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 82553.3594 - val_loss: 18120.6543\n",
      "Epoch 60/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 29578374.0000 - val_loss: 863227.6875\n",
      "Epoch 61/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 442015.7500 - val_loss: 72594.0312\n",
      "Epoch 62/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 11471931.0000 - val_loss: 160409.2500\n",
      "Epoch 63/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 74099.6172 - val_loss: 98513.2500\n",
      "Epoch 64/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 25907236.0000 - val_loss: 128846.6562\n",
      "Epoch 65/65\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 48610692.0000 - val_loss: 988289.9375\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▂▂▁▁▂▁▁▁▂█▄▁▃▁▁▃▁▁▃▁▁▁▂▃▃▁▁▂▃▂▁▁▁▂▂▃▁▁▅</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▂▁▂▁▄█▂▁▃▁▁▆▁▁▇▁▁▁▁▂▂▁▁▂▃▂▁▁▁▁▁▄▁▁▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.90682</td></tr><tr><td>epoch</td><td>64</td></tr><tr><td>loss</td><td>48610692.0</td></tr><tr><td>val_loss</td><td>988289.9375</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">fancy-sweep-24</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/wxgexrgv\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/wxgexrgv</a><br/>Synced 6 W&B file(s), 1 media file(s), 5 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_060519-wxgexrgv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3th26axi with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5331258289950607\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 79\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.015767628796907664\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 147\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 176\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 167\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 171\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 65\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "162dc7050c7f45438d24eca06e0e8015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01666869721669476, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_061108-3th26axi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/3th26axi\" target=\"_blank\">scarlet-sweep-25</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/79\n",
      "2268/2291 [============================>.] - ETA: 0s - loss: 1.0383INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_061108-3th26axi/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_061108-3th26axi/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1.0383 - val_loss: 0.8901\n",
      "Epoch 2/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1027.3561 - val_loss: 3.0644\n",
      "Epoch 3/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3.0835 - val_loss: 1.5128\n",
      "Epoch 4/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 4194.7510 - val_loss: 57.3140\n",
      "Epoch 5/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 22.3287 - val_loss: 7.2033\n",
      "Epoch 6/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 6.4051 - val_loss: 2.7712\n",
      "Epoch 7/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2.6372 - val_loss: 1.2390\n",
      "Epoch 8/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1709.7443 - val_loss: 19.7188\n",
      "Epoch 9/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 13.4798 - val_loss: 6.0000\n",
      "Epoch 10/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 4.2653 - val_loss: 2.1529\n",
      "Epoch 11/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1191.0566 - val_loss: 59.2388\n",
      "Epoch 12/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 20.1332 - val_loss: 4.9509\n",
      "Epoch 13/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 4.3475 - val_loss: 2.4194\n",
      "Epoch 14/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.8399 - val_loss: 1.1515\n",
      "Epoch 15/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.2052 - val_loss: 1.1259\n",
      "Epoch 16/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1137.5759 - val_loss: 18.7122\n",
      "Epoch 17/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 9.1876 - val_loss: 2.0567\n",
      "Epoch 18/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2.6595 - val_loss: 1.4073\n",
      "Epoch 19/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.3616 - val_loss: 0.9270\n",
      "Epoch 20/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.1682 - val_loss: 0.8982\n",
      "Epoch 21/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1659.6844 - val_loss: 9.5779\n",
      "Epoch 22/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 8.4153 - val_loss: 2.9791\n",
      "Epoch 23/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2.7006 - val_loss: 1.2891\n",
      "Epoch 24/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1481.1665 - val_loss: 14.0292\n",
      "Epoch 25/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 10.5910 - val_loss: 2.9447\n",
      "Epoch 26/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2.8521 - val_loss: 1.2504\n",
      "Epoch 27/79\n",
      "2250/2291 [============================>.] - ETA: 0s - loss: 1.4827INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_061108-3th26axi/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_061108-3th26axi/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1.4760 - val_loss: 0.8474\n",
      "Epoch 28/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1185.3187 - val_loss: 34.9124\n",
      "Epoch 29/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 9.8945 - val_loss: 3.5421\n",
      "Epoch 30/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2.8581 - val_loss: 1.1664\n",
      "Epoch 31/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.9184 - val_loss: 1.0364\n",
      "Epoch 32/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.2091 - val_loss: 1.1361\n",
      "Epoch 33/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3580.5757 - val_loss: 11.3129\n",
      "Epoch 34/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 13.1596 - val_loss: 6.2306\n",
      "Epoch 35/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 4.7651 - val_loss: 2.0765\n",
      "Epoch 36/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3818.9683 - val_loss: 41.6105\n",
      "Epoch 37/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 27.0707 - val_loss: 7.7055\n",
      "Epoch 38/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 7.6046 - val_loss: 2.4544\n",
      "Epoch 39/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2.8289 - val_loss: 1.4918\n",
      "Epoch 40/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1088.7112 - val_loss: 1682.2487\n",
      "Epoch 41/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 60.7529 - val_loss: 4.9741\n",
      "Epoch 42/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 4.7950 - val_loss: 2.4619\n",
      "Epoch 43/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2.0330 - val_loss: 1.2149\n",
      "Epoch 44/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 8878.3135 - val_loss: 68.1759\n",
      "Epoch 45/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 44.6327 - val_loss: 12.4514\n",
      "Epoch 46/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 14.8871 - val_loss: 7.7953\n",
      "Epoch 47/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 5.0024 - val_loss: 6.3202\n",
      "Epoch 48/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2.5297 - val_loss: 1.3672\n",
      "Epoch 49/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2765.1353 - val_loss: 16.1229\n",
      "Epoch 50/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 12.5811 - val_loss: 3.8804\n",
      "Epoch 51/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 5.5998 - val_loss: 3.4057\n",
      "Epoch 52/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3.9435 - val_loss: 1.4880\n",
      "Epoch 53/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.8610 - val_loss: 1.0660\n",
      "Epoch 54/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2736.7698 - val_loss: 17.6085\n",
      "Epoch 55/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 17.8951 - val_loss: 6.2195\n",
      "Epoch 56/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 6.0910 - val_loss: 2.5100\n",
      "Epoch 57/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2.4782 - val_loss: 1.1507\n",
      "Epoch 58/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.4078 - val_loss: 1.1225\n",
      "Epoch 59/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2467.5188 - val_loss: 14.9793\n",
      "Epoch 60/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 11.3344 - val_loss: 4.9906\n",
      "Epoch 61/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3.8085 - val_loss: 1.7647\n",
      "Epoch 62/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.9331 - val_loss: 1.1491\n",
      "Epoch 63/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2275.9578 - val_loss: 77.3593\n",
      "Epoch 64/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 33.6482 - val_loss: 10.4717\n",
      "Epoch 65/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 7.9112 - val_loss: 2.4554\n",
      "Epoch 66/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2.8595 - val_loss: 1.4830\n",
      "Epoch 67/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 4195.2256 - val_loss: 22.6191\n",
      "Epoch 68/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 18.6958 - val_loss: 6.1201\n",
      "Epoch 69/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 5.8838 - val_loss: 2.4796\n",
      "Epoch 70/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2.9857 - val_loss: 1.1317\n",
      "Epoch 71/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1798.6072 - val_loss: 18.0072\n",
      "Epoch 72/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 15.6041 - val_loss: 4.2091\n",
      "Epoch 73/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 4.4528 - val_loss: 2.8445\n",
      "Epoch 74/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.9580 - val_loss: 1.3664\n",
      "Epoch 75/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.7131 - val_loss: 1.3167\n",
      "Epoch 76/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2774.7522 - val_loss: 13.6069\n",
      "Epoch 77/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 10.9161 - val_loss: 4.5456\n",
      "Epoch 78/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 4.2765 - val_loss: 2.7644\n",
      "Epoch 79/79\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1987.1592 - val_loss: 15.0511\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▁▁▁▃▁▁▁▁▄▁▁▁▁▁▇▁▁▁▁▁▁▁▆▁▁▁▁▅▁▅▁█▁▄▁▁▁▄</td></tr><tr><td>val_loss</td><td>▁▁▂▁▁▆▁▁▁▁▂▁▁▁▁▁▂▁▂▁▁▁▂▂▂▁▁▁▁▂▁█▁▃▁▃▁▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>26</td></tr><tr><td>best_val_loss</td><td>0.84738</td></tr><tr><td>epoch</td><td>78</td></tr><tr><td>loss</td><td>1987.15918</td></tr><tr><td>val_loss</td><td>15.05106</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">scarlet-sweep-25</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/3th26axi\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/3th26axi</a><br/>Synced 6 W&B file(s), 1 media file(s), 9 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_061108-3th26axi/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rh5nuoap with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3326940158117588\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 72\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.06739888327067742\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 254\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 243\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 235\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 135\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 236\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_061524-rh5nuoap</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/rh5nuoap\" target=\"_blank\">splendid-sweep-26</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/72\n",
      "1139/1146 [============================>.] - ETA: 0s - loss: 3269.9802INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_061524-rh5nuoap/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_061524-rh5nuoap/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 4s 3ms/step - loss: 3252.7048 - val_loss: 2.8301\n",
      "Epoch 2/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 2.9976 - val_loss: 2.8378\n",
      "Epoch 3/72\n",
      "1128/1146 [============================>.] - ETA: 0s - loss: 1.7034INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_061524-rh5nuoap/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_061524-rh5nuoap/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 4s 3ms/step - loss: 1.7117 - val_loss: 1.3665\n",
      "Epoch 4/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 978026880.0000 - val_loss: 3753147.7500\n",
      "Epoch 5/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 3273049.5000 - val_loss: 9909761.0000\n",
      "Epoch 6/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 1370701.7500 - val_loss: 736663.5625\n",
      "Epoch 7/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 773180.1875 - val_loss: 938033.9375\n",
      "Epoch 8/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 2568587776.0000 - val_loss: 70123352.0000\n",
      "Epoch 9/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 13676998.0000 - val_loss: 6643240.0000\n",
      "Epoch 10/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 5877895.5000 - val_loss: 7238116.5000\n",
      "Epoch 11/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 3136046.5000 - val_loss: 1784996.6250\n",
      "Epoch 12/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 1777668.1250 - val_loss: 1022604.5000\n",
      "Epoch 13/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 1163189.7500 - val_loss: 599089.7500\n",
      "Epoch 14/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 783440384.0000 - val_loss: 26294280192.0000\n",
      "Epoch 15/72\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 305107008.0000 - val_loss: 2201971.2500\n",
      "Epoch 16/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 3036233.7500 - val_loss: 1791231.0000\n",
      "Epoch 17/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 1658644.0000 - val_loss: 1744407.5000\n",
      "Epoch 18/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 1105967.6250 - val_loss: 673240.8750\n",
      "Epoch 19/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 652077.3750 - val_loss: 430878.5625\n",
      "Epoch 20/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 2899428864.0000 - val_loss: 131918888.0000\n",
      "Epoch 21/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 28148182.0000 - val_loss: 22180156.0000\n",
      "Epoch 22/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 9461185.0000 - val_loss: 7505065.0000\n",
      "Epoch 23/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 5279484.5000 - val_loss: 2756672.0000\n",
      "Epoch 24/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 2991378.2500 - val_loss: 1807639.7500\n",
      "Epoch 25/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 1785549.8750 - val_loss: 956091.9375\n",
      "Epoch 26/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 1033937.5000 - val_loss: 484278.5625\n",
      "Epoch 27/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 2702710272.0000 - val_loss: 52597140.0000\n",
      "Epoch 28/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 15418343.0000 - val_loss: 7621160.5000\n",
      "Epoch 29/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 9308496.0000 - val_loss: 7091463.5000\n",
      "Epoch 30/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 4763976.0000 - val_loss: 5524001.0000\n",
      "Epoch 31/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 2896715.2500 - val_loss: 2166918.7500\n",
      "Epoch 32/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 1667296.1250 - val_loss: 651193.8125\n",
      "Epoch 33/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 886148.3750 - val_loss: 508276.9062\n",
      "Epoch 34/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 546078.1250 - val_loss: 656361.0625\n",
      "Epoch 35/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 1024450240.0000 - val_loss: 17337142.0000\n",
      "Epoch 36/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 3788487.5000 - val_loss: 3909868.7500\n",
      "Epoch 37/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 2063191.8750 - val_loss: 1138761.2500\n",
      "Epoch 38/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 1131215.7500 - val_loss: 617158.6250\n",
      "Epoch 39/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 698145.5000 - val_loss: 471970.5938\n",
      "Epoch 40/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 470136.3438 - val_loss: 284933.9375\n",
      "Epoch 41/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 278373.3438 - val_loss: 298711.7812\n",
      "Epoch 42/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 2941694976.0000 - val_loss: 51167880.0000\n",
      "Epoch 43/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 12071134.0000 - val_loss: 6283211.0000\n",
      "Epoch 44/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 6178872.0000 - val_loss: 3809542.5000\n",
      "Epoch 45/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 4764530.5000 - val_loss: 6312705.0000\n",
      "Epoch 46/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 2696244.5000 - val_loss: 2865281.0000\n",
      "Epoch 47/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 73100984.0000 - val_loss: 1156485.2500\n",
      "Epoch 48/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 1009410.8750 - val_loss: 658473.0000\n",
      "Epoch 49/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 442559.7812 - val_loss: 299576.6875\n",
      "Epoch 50/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 266933.4375 - val_loss: 137940.9062\n",
      "Epoch 51/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 173535.6875 - val_loss: 96373.9141\n",
      "Epoch 52/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 2112005504.0000 - val_loss: 21638128.0000\n",
      "Epoch 53/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 11052363.0000 - val_loss: 5398178.0000\n",
      "Epoch 54/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 4873790.5000 - val_loss: 3553699.0000\n",
      "Epoch 55/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 2993225.2500 - val_loss: 1117207.7500\n",
      "Epoch 56/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 1531229.3750 - val_loss: 978774.7500\n",
      "Epoch 57/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 861432.2500 - val_loss: 331273.3438\n",
      "Epoch 58/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 499465.2812 - val_loss: 277688.9062\n",
      "Epoch 59/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 357653.4062 - val_loss: 186773.7500\n",
      "Epoch 60/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 1134327808.0000 - val_loss: 92711200.0000\n",
      "Epoch 61/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 11690992.0000 - val_loss: 4609603.0000\n",
      "Epoch 62/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 4411160.0000 - val_loss: 4567178.5000\n",
      "Epoch 63/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 2727529.0000 - val_loss: 1507354.5000\n",
      "Epoch 64/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 1630779.5000 - val_loss: 746814.3125\n",
      "Epoch 65/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 923068.2500 - val_loss: 529847.6250\n",
      "Epoch 66/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 565726.5625 - val_loss: 473725.4375\n",
      "Epoch 67/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 2344331776.0000 - val_loss: 28273314.0000\n",
      "Epoch 68/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 17714790.0000 - val_loss: 7850205.0000\n",
      "Epoch 69/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 8892709.0000 - val_loss: 6652856.0000\n",
      "Epoch 70/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 4199124.0000 - val_loss: 3609892.2500\n",
      "Epoch 71/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 2495115.5000 - val_loss: 1589603.6250\n",
      "Epoch 72/72\n",
      "1146/1146 [==============================] - 3s 3ms/step - loss: 1109521408.0000 - val_loss: 108027112.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▃▁▇▁▁▁▂▁▁▁▁▁▁▁▁▁▁▃▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄</td></tr><tr><td>val_loss</td><td>▁▁▁▁▆▁▁▁▁▁▁▂▁▁▁▁▁▁▁▂▁▁▁▄▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>2</td></tr><tr><td>best_val_loss</td><td>1.36651</td></tr><tr><td>epoch</td><td>71</td></tr><tr><td>loss</td><td>1109521408.0</td></tr><tr><td>val_loss</td><td>108027112.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">splendid-sweep-26</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/rh5nuoap\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/rh5nuoap</a><br/>Synced 6 W&B file(s), 1 media file(s), 9 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_061524-rh5nuoap/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tx1k8g4i with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.0440928231270973\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 41\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.03757441018799416\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 106\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 89\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 86\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 119\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 126\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_061915-tx1k8g4i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/tx1k8g4i\" target=\"_blank\">confused-sweep-27</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/41\n",
      "1130/1146 [============================>.] - ETA: 0s - loss: 7.4835INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_061915-tx1k8g4i/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_061915-tx1k8g4i/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 2ms/step - loss: 7.3950 - val_loss: 1.0435\n",
      "Epoch 2/41\n",
      "1133/1146 [============================>.] - ETA: 0s - loss: 0.7638INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_061915-tx1k8g4i/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_061915-tx1k8g4i/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.7643 - val_loss: 0.8220\n",
      "Epoch 3/41\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.7538 - val_loss: 0.8728\n",
      "Epoch 4/41\n",
      "1130/1146 [============================>.] - ETA: 0s - loss: 0.7670INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_061915-tx1k8g4i/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_061915-tx1k8g4i/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.7665 - val_loss: 0.8069\n",
      "Epoch 5/41\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.7971 - val_loss: 0.8740\n",
      "Epoch 6/41\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 0.8244 - val_loss: 1.9361\n",
      "Epoch 7/41\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 1430381.5000 - val_loss: 5810.7397\n",
      "Epoch 8/41\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 3135.1389 - val_loss: 1150.8907\n",
      "Epoch 9/41\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 1502.3395 - val_loss: 510.4584\n",
      "Epoch 10/41\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 746.0995 - val_loss: 1461.9984\n",
      "Epoch 11/41\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 439.5105 - val_loss: 592.9475\n",
      "Epoch 12/41\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 319.3202 - val_loss: 211.5605\n",
      "Epoch 13/41\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 488117.3750 - val_loss: 3083.6460\n",
      "Epoch 14/41\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1825.2808 - val_loss: 1464.6118\n",
      "Epoch 15/41\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 835.3141 - val_loss: 537.8903\n",
      "Epoch 16/41\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 483.6273 - val_loss: 308.5813\n",
      "Epoch 17/41\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 286.6900 - val_loss: 185.0535\n",
      "Epoch 18/41\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 175.8679 - val_loss: 151.7156\n",
      "Epoch 19/41\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 552547.8750 - val_loss: 7019.2856\n",
      "Epoch 20/41\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 3190.4111 - val_loss: 13448.9785\n",
      "Epoch 21/41\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 1720.7391 - val_loss: 901.6879\n",
      "Epoch 22/41\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 703.6621 - val_loss: 512.8468\n",
      "Epoch 23/41\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 468.6528 - val_loss: 353.4910\n",
      "Epoch 24/41\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 863561.8750 - val_loss: 19809.6348\n",
      "Epoch 25/41\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 8237.6113 - val_loss: 4129.7334\n",
      "Epoch 26/41\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2699.0527 - val_loss: 4239.2080\n",
      "Epoch 27/41\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 1631.1052 - val_loss: 1082.1118\n",
      "Epoch 28/41\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 806.3065 - val_loss: 780.3261\n",
      "Epoch 29/41\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 558.2322 - val_loss: 226.3500\n",
      "Epoch 30/41\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 529265.7500 - val_loss: 2751.9678\n",
      "Epoch 31/41\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1984.8467 - val_loss: 1356.1312\n",
      "Epoch 32/41\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 1112.4148 - val_loss: 782.4836\n",
      "Epoch 33/41\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 778.5394 - val_loss: 818.3900\n",
      "Epoch 34/41\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 492.3544 - val_loss: 297.2741\n",
      "Epoch 35/41\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 289.7891 - val_loss: 204.6224\n",
      "Epoch 36/41\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 177.7717 - val_loss: 273.2061\n",
      "Epoch 37/41\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1063492.3750 - val_loss: 30806.0137\n",
      "Epoch 38/41\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8972.8076 - val_loss: 3493.2239\n",
      "Epoch 39/41\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 2838.6648 - val_loss: 1872.0930\n",
      "Epoch 40/41\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1515.3505 - val_loss: 1449.5190\n",
      "Epoch 41/41\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 896.6776 - val_loss: 760.2521\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>loss</td><td>▁▁▁▁▁▁█▁▁▁▁▁▃▁▁▁▁▁▄▁▁▁▁▅▁▁▁▁▁▄▁▁▁▁▁▁▆▁▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▂▁▁▁▁▁▂▁▁▁▁▁▃▄▁▁▁▆▂▂▁▁▁▂▁▁▁▁▁▁█▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>3</td></tr><tr><td>best_val_loss</td><td>0.8069</td></tr><tr><td>epoch</td><td>40</td></tr><tr><td>loss</td><td>896.67755</td></tr><tr><td>val_loss</td><td>760.25214</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">confused-sweep-27</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/tx1k8g4i\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/tx1k8g4i</a><br/>Synced 6 W&B file(s), 1 media file(s), 13 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_061915-tx1k8g4i/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4anxljm0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5351904926638938\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 45\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.05866384491406445\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 252\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 65\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 192\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 238\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 175\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_062052-4anxljm0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/4anxljm0\" target=\"_blank\">quiet-sweep-28</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n",
      "4538/4581 [============================>.] - ETA: 0s - loss: 58.2302INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_062052-4anxljm0/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_062052-4anxljm0/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4581/4581 [==============================] - 6s 1ms/step - loss: 57.7019 - val_loss: 0.8707\n",
      "Epoch 2/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 21779728.0000 - val_loss: 368055.0312\n",
      "Epoch 3/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 5370867.0000 - val_loss: 63188.2383\n",
      "Epoch 4/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 35536.5000 - val_loss: 3149.9412\n",
      "Epoch 5/45\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 85988560.0000 - val_loss: 476356.9062\n",
      "Epoch 6/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 309797.2188 - val_loss: 42225.9531\n",
      "Epoch 7/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 14954252.0000 - val_loss: 95450.3750\n",
      "Epoch 8/45\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 46913.0234 - val_loss: 5794.4019\n",
      "Epoch 9/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 35852720.0000 - val_loss: 205951.3125\n",
      "Epoch 10/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 128180.7109 - val_loss: 29244.8086\n",
      "Epoch 11/45\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 18246958.0000 - val_loss: 166445.4531\n",
      "Epoch 12/45\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 121595.0156 - val_loss: 16242.0615\n",
      "Epoch 13/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 32089326.0000 - val_loss: 111383.4922\n",
      "Epoch 14/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 77188.8672 - val_loss: 19194.3359\n",
      "Epoch 15/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 24369114.0000 - val_loss: 254696.0156\n",
      "Epoch 16/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 144083.4531 - val_loss: 56234.8867\n",
      "Epoch 17/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 9536216.0000 - val_loss: 76310.1797\n",
      "Epoch 18/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 46299.2031 - val_loss: 10891.2051\n",
      "Epoch 19/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 80445976.0000 - val_loss: 324282.0000\n",
      "Epoch 20/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 8623979.0000 - val_loss: 50763.5117\n",
      "Epoch 21/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 56233.4258 - val_loss: 13744.0840\n",
      "Epoch 22/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 22428352.0000 - val_loss: 145385.0625\n",
      "Epoch 23/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 107613.8516 - val_loss: 15458.2109\n",
      "Epoch 24/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 72819920.0000 - val_loss: 419248.9062\n",
      "Epoch 25/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 335647.7500 - val_loss: 81244.1953\n",
      "Epoch 26/45\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 66988.4922 - val_loss: 13104.2363\n",
      "Epoch 27/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 14237672.0000 - val_loss: 45342.2539\n",
      "Epoch 28/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 36415400.0000 - val_loss: 1411488.3750\n",
      "Epoch 29/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 612316.5625 - val_loss: 80895.8984\n",
      "Epoch 30/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 14900658.0000 - val_loss: 121306.9688\n",
      "Epoch 31/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 91751.7344 - val_loss: 21554.6660\n",
      "Epoch 32/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 17443952.0000 - val_loss: 135229.8438\n",
      "Epoch 33/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 48664024.0000 - val_loss: 737397.0000\n",
      "Epoch 34/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 432627.4062 - val_loss: 93997.6953\n",
      "Epoch 35/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 17396852.0000 - val_loss: 267082.8125\n",
      "Epoch 36/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 162437.3750 - val_loss: 43743.5312\n",
      "Epoch 37/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 37909716.0000 - val_loss: 856955.1875\n",
      "Epoch 38/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 452718.9688 - val_loss: 57727.1992\n",
      "Epoch 39/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 62437716.0000 - val_loss: 230707.4062\n",
      "Epoch 40/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 246070.9531 - val_loss: 54794.1953\n",
      "Epoch 41/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 65664488.0000 - val_loss: 361195.0000\n",
      "Epoch 42/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 345671.5938 - val_loss: 68383.6172\n",
      "Epoch 43/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 31201666.0000 - val_loss: 244552.7344\n",
      "Epoch 44/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 161323.1875 - val_loss: 38197.4180\n",
      "Epoch 45/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 31686460.0000 - val_loss: 184503.7500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d94accacf85f4e1b94400b43ac4c606d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.170 MB of 3.198 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.991221…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▃▁▁█▁▂▁▁▂▁▄▁▃▁▂█▂▁▃▁▇▁▁▄▁▂▁▂▅▁▂▄▁▆▁▆▁▄▄</td></tr><tr><td>val_loss</td><td>▁▃▁▁▃▁▁▁▁▂▁▂▁▂▁▁▃▁▁▂▁▃▁▁█▁▂▁▂▅▁▂▅▁▂▁▃▁▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.8707</td></tr><tr><td>epoch</td><td>44</td></tr><tr><td>loss</td><td>31686460.0</td></tr><tr><td>val_loss</td><td>184503.75</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">quiet-sweep-28</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/4anxljm0\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/4anxljm0</a><br/>Synced 6 W&B file(s), 1 media file(s), 5 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_062052-4anxljm0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xqq8zwu1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5661606632757246\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 74\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0931845757339709\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 111\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 153\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 145\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 230\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 209\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_062510-xqq8zwu1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/xqq8zwu1\" target=\"_blank\">dark-sweep-29</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/74\n",
      "4543/4581 [============================>.] - ETA: 0s - loss: 795.0778INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_062510-xqq8zwu1/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_062510-xqq8zwu1/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4581/4581 [==============================] - 7s 1ms/step - loss: 788.6334 - val_loss: 1.5454\n",
      "Epoch 2/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 355817152.0000 - val_loss: 356573344.0000\n",
      "Epoch 3/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 5348041.5000 - val_loss: 229703.1875\n",
      "Epoch 4/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 2044147.7500 - val_loss: 18319.5684\n",
      "Epoch 5/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1902510720.0000 - val_loss: 1275770.2500\n",
      "Epoch 6/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1235842176.0000 - val_loss: 14954915.0000\n",
      "Epoch 7/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 5402169.5000 - val_loss: 2291170.0000\n",
      "Epoch 8/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1523774.3750 - val_loss: 67436.3203\n",
      "Epoch 9/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 573563712.0000 - val_loss: 5483517.0000\n",
      "Epoch 10/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 2245126.2500 - val_loss: 734652.3125\n",
      "Epoch 11/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1144000128.0000 - val_loss: 5547226.5000\n",
      "Epoch 12/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 2628517.5000 - val_loss: 444883.4688\n",
      "Epoch 13/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 298756608.0000 - val_loss: 2291576.5000\n",
      "Epoch 14/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 321852896.0000 - val_loss: 4927409.5000\n",
      "Epoch 15/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 3421661.2500 - val_loss: 456773.1562\n",
      "Epoch 16/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 560205568.0000 - val_loss: 1425774.0000\n",
      "Epoch 17/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1066988800.0000 - val_loss: 10705182.0000\n",
      "Epoch 18/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 562483776.0000 - val_loss: 64658944.0000\n",
      "Epoch 19/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 14467878.0000 - val_loss: 3379945.5000\n",
      "Epoch 20/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1478302.5000 - val_loss: 182064.2344\n",
      "Epoch 21/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 844099520.0000 - val_loss: 5911798.0000\n",
      "Epoch 22/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 4193459.0000 - val_loss: 1018745.5625\n",
      "Epoch 23/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 335008800.0000 - val_loss: 6050397.0000\n",
      "Epoch 24/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 3080010.0000 - val_loss: 609305.6250\n",
      "Epoch 25/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 286866304.0000 - val_loss: 1420177.1250\n",
      "Epoch 26/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1238789.3750 - val_loss: 172983.4844\n",
      "Epoch 27/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 871772352.0000 - val_loss: 3568241.7500\n",
      "Epoch 28/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 504873024.0000 - val_loss: 6380143.0000\n",
      "Epoch 29/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 5338888.5000 - val_loss: 1580983.8750\n",
      "Epoch 30/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 662415872.0000 - val_loss: 11584868.0000\n",
      "Epoch 31/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 8704035.0000 - val_loss: 2453618.0000\n",
      "Epoch 32/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1678855.6250 - val_loss: 248597.0625\n",
      "Epoch 33/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 808279872.0000 - val_loss: 6711597.0000\n",
      "Epoch 34/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 3844787.0000 - val_loss: 732783.0000\n",
      "Epoch 35/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1390396032.0000 - val_loss: 21766862.0000\n",
      "Epoch 36/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 14111895.0000 - val_loss: 1880212.5000\n",
      "Epoch 37/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1730791936.0000 - val_loss: 18551766.0000\n",
      "Epoch 38/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 13886952.0000 - val_loss: 2076917.0000\n",
      "Epoch 39/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 632435520.0000 - val_loss: 4106045.7500\n",
      "Epoch 40/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 3137762.7500 - val_loss: 479612.3438\n",
      "Epoch 41/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 923553536.0000 - val_loss: 6118612.5000\n",
      "Epoch 42/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1219757568.0000 - val_loss: 18234792.0000\n",
      "Epoch 43/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 11133867.0000 - val_loss: 2655837.5000\n",
      "Epoch 44/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1424133888.0000 - val_loss: 8780280.0000\n",
      "Epoch 45/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 5517252.0000 - val_loss: 2287283.2500\n",
      "Epoch 46/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 971781056.0000 - val_loss: 7733466.0000\n",
      "Epoch 47/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 6893687.0000 - val_loss: 1493847.7500\n",
      "Epoch 48/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 283304192.0000 - val_loss: 2357461.0000\n",
      "Epoch 49/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1708526.1250 - val_loss: 307971.2188\n",
      "Epoch 50/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1747024256.0000 - val_loss: 14032624.0000\n",
      "Epoch 51/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 8918676.0000 - val_loss: 1960121.0000\n",
      "Epoch 52/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 967993664.0000 - val_loss: 9836253.0000\n",
      "Epoch 53/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 7041042.0000 - val_loss: 1478077.8750\n",
      "Epoch 54/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 393654912.0000 - val_loss: 8665119.0000\n",
      "Epoch 55/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 4902614.0000 - val_loss: 1160716.3750\n",
      "Epoch 56/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 571015488.0000 - val_loss: 7740643.5000\n",
      "Epoch 57/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 5358652.0000 - val_loss: 1017622.8125\n",
      "Epoch 58/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 410084160.0000 - val_loss: 13995401.0000\n",
      "Epoch 59/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 6332124.5000 - val_loss: 1127233.0000\n",
      "Epoch 60/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 790819200.0000 - val_loss: 7180424.0000\n",
      "Epoch 61/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 9655062.0000 - val_loss: 1256823.6250\n",
      "Epoch 62/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 776632.3125 - val_loss: 81938.6250\n",
      "Epoch 63/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 890039424.0000 - val_loss: 4333065.5000\n",
      "Epoch 64/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 3610008.7500 - val_loss: 635065.0625\n",
      "Epoch 65/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 796438656.0000 - val_loss: 24495104.0000\n",
      "Epoch 66/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 11131867.0000 - val_loss: 1744303.7500\n",
      "Epoch 67/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1057976192.0000 - val_loss: 520091168.0000\n",
      "Epoch 68/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 28305900.0000 - val_loss: 3386475.7500\n",
      "Epoch 69/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1408380672.0000 - val_loss: 8951706.0000\n",
      "Epoch 70/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 10474301.0000 - val_loss: 11748092.0000\n",
      "Epoch 71/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 311980128.0000 - val_loss: 24493694.0000\n",
      "Epoch 72/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 8281296.0000 - val_loss: 1446601.0000\n",
      "Epoch 73/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 859498240.0000 - val_loss: 29854772.0000\n",
      "Epoch 74/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 14607312.0000 - val_loss: 2528841.7500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▃▁▇▁▁▁▃▁▆▁▅▃▂▅▁▄▁▁▁▁▁▇█▁▁▁▁▁▁▁▁▅▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>1.5454</td></tr><tr><td>epoch</td><td>73</td></tr><tr><td>loss</td><td>14607312.0</td></tr><tr><td>val_loss</td><td>2528841.75</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">dark-sweep-29</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/xqq8zwu1\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/xqq8zwu1</a><br/>Synced 6 W&B file(s), 1 media file(s), 5 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_062510-xqq8zwu1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 87p5jjw2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.10740354936585206\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 69\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.06390101770910654\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 204\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 183\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 245\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 237\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_063229-87p5jjw2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/87p5jjw2\" target=\"_blank\">lucky-sweep-30</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/69\n",
      "1129/1146 [============================>.] - ETA: 0s - loss: 802.5165INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_063229-87p5jjw2/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_063229-87p5jjw2/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 4s 3ms/step - loss: 791.2807 - val_loss: 0.9772\n",
      "Epoch 2/69\n",
      "1138/1146 [============================>.] - ETA: 0s - loss: 0.9997INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_063229-87p5jjw2/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_063229-87p5jjw2/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.9996 - val_loss: 0.9478\n",
      "Epoch 3/69\n",
      "1142/1146 [============================>.] - ETA: 0s - loss: 0.8800INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_063229-87p5jjw2/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_063229-87p5jjw2/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.8798 - val_loss: 0.8864\n",
      "Epoch 4/69\n",
      "1130/1146 [============================>.] - ETA: 0s - loss: 0.8357INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_063229-87p5jjw2/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_063229-87p5jjw2/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.8353 - val_loss: 0.8625\n",
      "Epoch 5/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 153635.9844 - val_loss: 1425582208.0000\n",
      "Epoch 6/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 406242240.0000 - val_loss: 610697.8750\n",
      "Epoch 7/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 1147231.3750 - val_loss: 412242.0625\n",
      "Epoch 8/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 518672.6875 - val_loss: 266242.5312\n",
      "Epoch 9/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 283768.2812 - val_loss: 269537.9062\n",
      "Epoch 10/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 148329.1875 - val_loss: 99370.6953\n",
      "Epoch 11/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 75383.5547 - val_loss: 36716.1016\n",
      "Epoch 12/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 68699.3359 - val_loss: 17930.6992\n",
      "Epoch 13/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 698127104.0000 - val_loss: 9776031.0000\n",
      "Epoch 14/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 3532990.0000 - val_loss: 1969582.6250\n",
      "Epoch 15/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 1389441.1250 - val_loss: 1503239.6250\n",
      "Epoch 16/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 792187.8750 - val_loss: 1047576.4375\n",
      "Epoch 17/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 687889.2500 - val_loss: 194056.0469\n",
      "Epoch 18/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 206635792.0000 - val_loss: 1357706.1250\n",
      "Epoch 19/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 965835.9375 - val_loss: 477807.7500\n",
      "Epoch 20/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 469065.9688 - val_loss: 479933.8438\n",
      "Epoch 21/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 256942.8906 - val_loss: 177135.5781\n",
      "Epoch 22/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 147637.9688 - val_loss: 109757.0547\n",
      "Epoch 23/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 85134.7969 - val_loss: 92574.4453\n",
      "Epoch 24/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 251656528.0000 - val_loss: 2714437.2500\n",
      "Epoch 25/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 1128332.7500 - val_loss: 591975.1250\n",
      "Epoch 26/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 550388.0625 - val_loss: 268972.0000\n",
      "Epoch 27/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 304290.5938 - val_loss: 221840.3125\n",
      "Epoch 28/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 177238.8750 - val_loss: 131623.8125\n",
      "Epoch 29/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 138931.8438 - val_loss: 75349.9609\n",
      "Epoch 30/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 1229978496.0000 - val_loss: 11934247.0000\n",
      "Epoch 31/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 4983709.5000 - val_loss: 2827950.0000\n",
      "Epoch 32/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 2521372.7500 - val_loss: 3472939.5000\n",
      "Epoch 33/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 1405193.7500 - val_loss: 816760.2500\n",
      "Epoch 34/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 720349.0625 - val_loss: 457906.0625\n",
      "Epoch 35/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 467267.4375 - val_loss: 225267.4531\n",
      "Epoch 36/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 290321.1250 - val_loss: 234279.6719\n",
      "Epoch 37/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 930007936.0000 - val_loss: 5460209.0000\n",
      "Epoch 38/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 3597628.5000 - val_loss: 2316984.5000\n",
      "Epoch 39/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 2214792.2500 - val_loss: 1246871.6250\n",
      "Epoch 40/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 1312882.0000 - val_loss: 972628.4375\n",
      "Epoch 41/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 820871.5000 - val_loss: 721983.5000\n",
      "Epoch 42/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 437391.0625 - val_loss: 317136.0312\n",
      "Epoch 43/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 283799.7500 - val_loss: 273493.4688\n",
      "Epoch 44/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 193305.2969 - val_loss: 75264.0234\n",
      "Epoch 45/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 444748736.0000 - val_loss: 10386526208.0000\n",
      "Epoch 46/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 381235872.0000 - val_loss: 5547875.0000\n",
      "Epoch 47/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 4452609.0000 - val_loss: 5234872.0000\n",
      "Epoch 48/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 2271301.7500 - val_loss: 1552429.1250\n",
      "Epoch 49/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 1124984.2500 - val_loss: 605950.5625\n",
      "Epoch 50/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 597010.8750 - val_loss: 863865.6250\n",
      "Epoch 51/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 390634.0000 - val_loss: 164447.9062\n",
      "Epoch 52/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 851075264.0000 - val_loss: 21847424.0000\n",
      "Epoch 53/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 9600715.0000 - val_loss: 15334439.0000\n",
      "Epoch 54/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 3621946.5000 - val_loss: 2374196.5000\n",
      "Epoch 55/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 1838044.3750 - val_loss: 2139692.5000\n",
      "Epoch 56/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 1064058.6250 - val_loss: 1149592.8750\n",
      "Epoch 57/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 573512896.0000 - val_loss: 17279666.0000\n",
      "Epoch 58/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 7274138.5000 - val_loss: 1880566.3750\n",
      "Epoch 59/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2191225.5000 - val_loss: 1746786.0000\n",
      "Epoch 60/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 1345030.5000 - val_loss: 806619.3750\n",
      "Epoch 61/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 646330.5000 - val_loss: 432825.2500\n",
      "Epoch 62/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 566492.7500 - val_loss: 186631.0781\n",
      "Epoch 63/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 246244.7031 - val_loss: 186349.7188\n",
      "Epoch 64/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 660852288.0000 - val_loss: 11155396.0000\n",
      "Epoch 65/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 3759806.2500 - val_loss: 2915680.5000\n",
      "Epoch 66/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 2112433.5000 - val_loss: 9508067.0000\n",
      "Epoch 67/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 1455584.8750 - val_loss: 855950.6250\n",
      "Epoch 68/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 694370.0000 - val_loss: 7958376.0000\n",
      "Epoch 69/69\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 216300816.0000 - val_loss: 1620447.5000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▁▃▁▁▁▅▁▁▂▁▁▁▁▁▁█▁▁▁▆▁▁▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▂</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▅▂▁▂▁▁▁▁▁▁▆▃▁▁▃▂▁▁▁▄▂▁▁█▂▂▂▁▁▁▂▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>3</td></tr><tr><td>best_val_loss</td><td>0.86247</td></tr><tr><td>epoch</td><td>68</td></tr><tr><td>loss</td><td>216300816.0</td></tr><tr><td>val_loss</td><td>1620447.5</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">lucky-sweep-30</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/87p5jjw2\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/87p5jjw2</a><br/>Synced 6 W&B file(s), 1 media file(s), 17 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_063229-87p5jjw2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gmbiqmje with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5872788371597887\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 33\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.09224258536532624\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 186\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 87\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 248\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 135\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 179\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_063544-gmbiqmje</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/gmbiqmje\" target=\"_blank\">breezy-sweep-31</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/33\n",
      "2259/2291 [============================>.] - ETA: 0s - loss: 14496.2832INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_063544-gmbiqmje/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_063544-gmbiqmje/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 14299.6240 - val_loss: 8.6925\n",
      "Epoch 2/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 41841048.0000 - val_loss: 21196584960.0000\n",
      "Epoch 3/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 266938384.0000 - val_loss: 1262971.7500\n",
      "Epoch 4/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 579415.3125 - val_loss: 246599.0312\n",
      "Epoch 5/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1590938240.0000 - val_loss: 19258592.0000\n",
      "Epoch 6/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 12090607.0000 - val_loss: 4048043.7500\n",
      "Epoch 7/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2777601.2500 - val_loss: 795813.8125\n",
      "Epoch 8/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 504296512.0000 - val_loss: 10786606.0000\n",
      "Epoch 9/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 4976371.0000 - val_loss: 1047763.6875\n",
      "Epoch 10/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1090574208.0000 - val_loss: 1046148736.0000\n",
      "Epoch 11/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 31617792.0000 - val_loss: 3594411.0000\n",
      "Epoch 12/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3552652.5000 - val_loss: 2107434.5000\n",
      "Epoch 13/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 13254288.0000 - val_loss: 285126.0625\n",
      "Epoch 14/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 313519.5938 - val_loss: 181559.8438\n",
      "Epoch 15/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 251396.3125 - val_loss: 39966.8945\n",
      "Epoch 16/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 56287.7344 - val_loss: 17292.8730\n",
      "Epoch 17/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1431836160.0000 - val_loss: 11126813.0000\n",
      "Epoch 18/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 6401540.0000 - val_loss: 2238556.0000\n",
      "Epoch 19/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1886652.7500 - val_loss: 703144.9375\n",
      "Epoch 20/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 610415424.0000 - val_loss: 3339853.7500\n",
      "Epoch 21/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3384185.7500 - val_loss: 2527071.0000\n",
      "Epoch 22/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 385241856.0000 - val_loss: 8058317.5000\n",
      "Epoch 23/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 4229143.0000 - val_loss: 1347223.6250\n",
      "Epoch 24/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1164311.1250 - val_loss: 382786.6562\n",
      "Epoch 25/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 386073.4688 - val_loss: 124864.6641\n",
      "Epoch 26/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 774264448.0000 - val_loss: 5116839.0000\n",
      "Epoch 27/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 4461361.5000 - val_loss: 1407120.8750\n",
      "Epoch 28/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1142184448.0000 - val_loss: 12458876.0000\n",
      "Epoch 29/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 10808433.0000 - val_loss: 3423844.7500\n",
      "Epoch 30/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3180685.5000 - val_loss: 1202218.7500\n",
      "Epoch 31/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1141450.0000 - val_loss: 389889.5938\n",
      "Epoch 32/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 960838592.0000 - val_loss: 12906304.0000\n",
      "Epoch 33/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 7090064.0000 - val_loss: 2727365.2500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▂▁█▁▁▃▁▆▁▁▁▁▁▁▇▁▁▄▁▃▁▁▁▄▁▆▁▁▁▅▁</td></tr><tr><td>val_loss</td><td>▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>8.69247</td></tr><tr><td>epoch</td><td>32</td></tr><tr><td>loss</td><td>7090064.0</td></tr><tr><td>val_loss</td><td>2727365.25</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">breezy-sweep-31</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/gmbiqmje\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/gmbiqmje</a><br/>Synced 6 W&B file(s), 1 media file(s), 5 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_063544-gmbiqmje/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2vnbzx1w with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.41042522005121457\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 67\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001725683763915542\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 244\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 71\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 89\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 202\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 162\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_063747-2vnbzx1w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/2vnbzx1w\" target=\"_blank\">wise-sweep-32</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/67\n",
      "4547/4581 [============================>.] - ETA: 0s - loss: 0.8458INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_063747-2vnbzx1w/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_063747-2vnbzx1w/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4581/4581 [==============================] - 6s 1ms/step - loss: 0.8455 - val_loss: 0.8373\n",
      "Epoch 2/67\n",
      "4537/4581 [============================>.] - ETA: 0s - loss: 0.7775INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_063747-2vnbzx1w/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_063747-2vnbzx1w/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4581/4581 [==============================] - 6s 1ms/step - loss: 0.7774 - val_loss: 0.7549\n",
      "Epoch 3/67\n",
      "4565/4581 [============================>.] - ETA: 0s - loss: 0.7501INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_063747-2vnbzx1w/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_063747-2vnbzx1w/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4581/4581 [==============================] - 6s 1ms/step - loss: 0.7502 - val_loss: 0.7007\n",
      "Epoch 4/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.7353 - val_loss: 0.7242\n",
      "Epoch 5/67\n",
      "4568/4581 [============================>.] - ETA: 0s - loss: 0.7266INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_063747-2vnbzx1w/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_063747-2vnbzx1w/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4581/4581 [==============================] - 6s 1ms/step - loss: 0.7265 - val_loss: 0.6856\n",
      "Epoch 6/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.7208 - val_loss: 0.7135\n",
      "Epoch 7/67\n",
      "4576/4581 [============================>.] - ETA: 0s - loss: 0.7134INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_063747-2vnbzx1w/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_063747-2vnbzx1w/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4581/4581 [==============================] - 6s 1ms/step - loss: 0.7134 - val_loss: 0.6823\n",
      "Epoch 8/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.7065 - val_loss: 0.6831\n",
      "Epoch 9/67\n",
      "4544/4581 [============================>.] - ETA: 0s - loss: 0.7042INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_063747-2vnbzx1w/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_063747-2vnbzx1w/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4581/4581 [==============================] - 6s 1ms/step - loss: 0.7040 - val_loss: 0.6761\n",
      "Epoch 10/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.7016 - val_loss: 0.6905\n",
      "Epoch 11/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6983 - val_loss: 0.6787\n",
      "Epoch 12/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6965 - val_loss: 0.6799\n",
      "Epoch 13/67\n",
      "4564/4581 [============================>.] - ETA: 0s - loss: 0.6957INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_063747-2vnbzx1w/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_063747-2vnbzx1w/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4581/4581 [==============================] - 6s 1ms/step - loss: 0.6959 - val_loss: 0.6683\n",
      "Epoch 14/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6949 - val_loss: 0.6880\n",
      "Epoch 15/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6908 - val_loss: 0.6752\n",
      "Epoch 16/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6910 - val_loss: 0.6876\n",
      "Epoch 17/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6893 - val_loss: 0.6757\n",
      "Epoch 18/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6883 - val_loss: 0.6857\n",
      "Epoch 19/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6882 - val_loss: 0.6775\n",
      "Epoch 20/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6871 - val_loss: 0.6975\n",
      "Epoch 21/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6832 - val_loss: 0.6771\n",
      "Epoch 22/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6826 - val_loss: 0.6865\n",
      "Epoch 23/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6812 - val_loss: 0.6825\n",
      "Epoch 24/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6846 - val_loss: 0.6987\n",
      "Epoch 25/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6810 - val_loss: 0.6796\n",
      "Epoch 26/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6831 - val_loss: 0.6857\n",
      "Epoch 27/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6777 - val_loss: 0.6737\n",
      "Epoch 28/67\n",
      "4578/4581 [============================>.] - ETA: 0s - loss: 0.6835INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_063747-2vnbzx1w/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_063747-2vnbzx1w/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4581/4581 [==============================] - 6s 1ms/step - loss: 0.6834 - val_loss: 0.6477\n",
      "Epoch 29/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6813 - val_loss: 0.6999\n",
      "Epoch 30/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6787 - val_loss: 0.6684\n",
      "Epoch 31/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6798 - val_loss: 0.6754\n",
      "Epoch 32/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6784 - val_loss: 0.6947\n",
      "Epoch 33/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6770 - val_loss: 0.6942\n",
      "Epoch 34/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6790 - val_loss: 0.6801\n",
      "Epoch 35/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6786 - val_loss: 0.6876\n",
      "Epoch 36/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6801 - val_loss: 0.7296\n",
      "Epoch 37/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6807 - val_loss: 0.6501\n",
      "Epoch 38/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6803 - val_loss: 0.7874\n",
      "Epoch 39/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6786 - val_loss: 0.6905\n",
      "Epoch 40/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6750 - val_loss: 0.6907\n",
      "Epoch 41/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6775 - val_loss: 0.7132\n",
      "Epoch 42/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6757 - val_loss: 0.6776\n",
      "Epoch 43/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6742 - val_loss: 0.6577\n",
      "Epoch 44/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6759 - val_loss: 0.6610\n",
      "Epoch 45/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6725 - val_loss: 0.6726\n",
      "Epoch 46/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6756 - val_loss: 0.6844\n",
      "Epoch 47/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6750 - val_loss: 0.6885\n",
      "Epoch 48/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6771 - val_loss: 0.6493\n",
      "Epoch 49/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6729 - val_loss: 0.6577\n",
      "Epoch 50/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6748 - val_loss: 0.6740\n",
      "Epoch 51/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6710 - val_loss: 0.6895\n",
      "Epoch 52/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6747 - val_loss: 0.6898\n",
      "Epoch 53/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6711 - val_loss: 0.6845\n",
      "Epoch 54/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6711 - val_loss: 0.6959\n",
      "Epoch 55/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6711 - val_loss: 0.6585\n",
      "Epoch 56/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6723 - val_loss: 0.6787\n",
      "Epoch 57/67\n",
      "4577/4581 [============================>.] - ETA: 0s - loss: 0.6713INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_063747-2vnbzx1w/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_063747-2vnbzx1w/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4581/4581 [==============================] - 6s 1ms/step - loss: 0.6714 - val_loss: 0.6476\n",
      "Epoch 58/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6728 - val_loss: 0.6641\n",
      "Epoch 59/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6736 - val_loss: 0.6650\n",
      "Epoch 60/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6716 - val_loss: 0.6877\n",
      "Epoch 61/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6722 - val_loss: 0.6613\n",
      "Epoch 62/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6715 - val_loss: 0.6690\n",
      "Epoch 63/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6688 - val_loss: 0.7265\n",
      "Epoch 64/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6710 - val_loss: 0.6515\n",
      "Epoch 65/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6697 - val_loss: 0.6801\n",
      "Epoch 66/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6709 - val_loss: 0.6509\n",
      "Epoch 67/67\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.6726 - val_loss: 0.6719\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "151556519450499ea53cd3f3789e6460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='11.405 MB of 11.405 MB uploaded (0.016 MB deduped)\\r'), FloatProgress(value=1.0, m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▅▄▃▃▂▂▂▂▂▂▂▂▁▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▅▄▃▂▂▂▂▂▂▂▂▂▂▃▂▁▃▂▃▂▄▆▃▃▁▂▂▁▂▃▂▁▂▂▂▂▄▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>56</td></tr><tr><td>best_val_loss</td><td>0.64762</td></tr><tr><td>epoch</td><td>66</td></tr><tr><td>loss</td><td>0.67264</td></tr><tr><td>val_loss</td><td>0.67194</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">wise-sweep-32</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/2vnbzx1w\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/2vnbzx1w</a><br/>Synced 6 W&B file(s), 1 media file(s), 37 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_063747-2vnbzx1w/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bx477zft with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.24807970995362072\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.06125697879658966\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 217\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 254\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 81\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 92\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 241\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_064346-bx477zft</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/bx477zft\" target=\"_blank\">fresh-sweep-33</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/99\n",
      "2265/2291 [============================>.] - ETA: 0s - loss: 159.5118INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_064346-bx477zft/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_064346-bx477zft/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 5s 2ms/step - loss: 157.7740 - val_loss: 1.2831\n",
      "Epoch 2/99\n",
      "2289/2291 [============================>.] - ETA: 0s - loss: 0.8833INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_064346-bx477zft/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_064346-bx477zft/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 0.8831 - val_loss: 0.8631\n",
      "Epoch 3/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 0.8347 - val_loss: 0.9599\n",
      "Epoch 4/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 729557568.0000 - val_loss: 5614412.0000\n",
      "Epoch 5/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 4843453.0000 - val_loss: 1367906.0000\n",
      "Epoch 6/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1166411.2500 - val_loss: 426549.4375\n",
      "Epoch 7/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 352604.5312 - val_loss: 130058.1172\n",
      "Epoch 8/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 247874384.0000 - val_loss: 14794544.0000\n",
      "Epoch 9/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 2174382.7500 - val_loss: 1386843.5000\n",
      "Epoch 10/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 567099.3125 - val_loss: 227205.0781\n",
      "Epoch 11/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 46398688.0000 - val_loss: 261173.8750\n",
      "Epoch 12/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 189134.8594 - val_loss: 62346.7812\n",
      "Epoch 13/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 63679.9297 - val_loss: 28086.2500\n",
      "Epoch 14/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 51073548.0000 - val_loss: 1209293.5000\n",
      "Epoch 15/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 490583.3125 - val_loss: 166610.4844\n",
      "Epoch 16/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 162821.5938 - val_loss: 56431.7930\n",
      "Epoch 17/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 150978128.0000 - val_loss: 2724590.0000\n",
      "Epoch 18/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1340405.0000 - val_loss: 366001.0625\n",
      "Epoch 19/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 376575.0938 - val_loss: 203707.5781\n",
      "Epoch 20/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 131187.9531 - val_loss: 41469.3438\n",
      "Epoch 21/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 59013752.0000 - val_loss: 259661.0469\n",
      "Epoch 22/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 301180.6875 - val_loss: 85941.2266\n",
      "Epoch 23/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 97654.4062 - val_loss: 34477.1914\n",
      "Epoch 24/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 33280.1367 - val_loss: 8693.6768\n",
      "Epoch 25/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 132468240.0000 - val_loss: 1130101.1250\n",
      "Epoch 26/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 911658.5625 - val_loss: 264119.0625\n",
      "Epoch 27/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 221286.0625 - val_loss: 114935.2344\n",
      "Epoch 28/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 103702.9688 - val_loss: 35814.3477\n",
      "Epoch 29/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 177595344.0000 - val_loss: 1407006.0000\n",
      "Epoch 30/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 790010.4375 - val_loss: 197499.2656\n",
      "Epoch 31/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 252291.6250 - val_loss: 152846.1562\n",
      "Epoch 32/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 271688768.0000 - val_loss: 1000455.3125\n",
      "Epoch 33/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1095515.5000 - val_loss: 435897.4375\n",
      "Epoch 34/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 383460.9062 - val_loss: 127218.6016\n",
      "Epoch 35/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 246908992.0000 - val_loss: 3161133.5000\n",
      "Epoch 36/99\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 1680369.8750 - val_loss: 647755.2500\n",
      "Epoch 37/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 511124.4688 - val_loss: 362358.3125\n",
      "Epoch 38/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 160557.0469 - val_loss: 89878.3125\n",
      "Epoch 39/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 153069280.0000 - val_loss: 1219635.1250\n",
      "Epoch 40/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 925900.0625 - val_loss: 347509.5312\n",
      "Epoch 41/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 338676.3438 - val_loss: 620734.0625\n",
      "Epoch 42/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 157430.8594 - val_loss: 43774.4805\n",
      "Epoch 43/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 120200464.0000 - val_loss: 1298502.8750\n",
      "Epoch 44/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1025392.4375 - val_loss: 297658.5938\n",
      "Epoch 45/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 342560.0000 - val_loss: 172627.4688\n",
      "Epoch 46/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 148238.7188 - val_loss: 49490.0703\n",
      "Epoch 47/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 76422048.0000 - val_loss: 558664.5000\n",
      "Epoch 48/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 551393.5625 - val_loss: 127299.0156\n",
      "Epoch 49/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 159458.4062 - val_loss: 53175.7539\n",
      "Epoch 50/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 131137928.0000 - val_loss: 38722860.0000\n",
      "Epoch 51/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 3244039.5000 - val_loss: 904988.4375\n",
      "Epoch 52/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 484350.5000 - val_loss: 233809.6719\n",
      "Epoch 53/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 198356.8281 - val_loss: 81405.4062\n",
      "Epoch 54/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 77607016.0000 - val_loss: 2369351.5000\n",
      "Epoch 55/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 999061.5000 - val_loss: 448281.9688\n",
      "Epoch 56/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 309889.7500 - val_loss: 199715.8438\n",
      "Epoch 57/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 66144020.0000 - val_loss: 33181406.0000\n",
      "Epoch 58/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1682715.2500 - val_loss: 370361.4688\n",
      "Epoch 59/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 298535.9688 - val_loss: 147379.1406\n",
      "Epoch 60/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 134214.0469 - val_loss: 99537.4453\n",
      "Epoch 61/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 205597808.0000 - val_loss: 7616103.5000\n",
      "Epoch 62/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 2191502.7500 - val_loss: 858959.5625\n",
      "Epoch 63/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 637990.1250 - val_loss: 331389.9375\n",
      "Epoch 64/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 247513.7656 - val_loss: 84702.7734\n",
      "Epoch 65/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 155749008.0000 - val_loss: 2038235.3750\n",
      "Epoch 66/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1157035.8750 - val_loss: 408968.1562\n",
      "Epoch 67/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 389913.6562 - val_loss: 151763.6562\n",
      "Epoch 68/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 162075.2031 - val_loss: 67079.5391\n",
      "Epoch 69/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 300659392.0000 - val_loss: 2442644.2500\n",
      "Epoch 70/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1502199.6250 - val_loss: 553187.6875\n",
      "Epoch 71/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 517246.0000 - val_loss: 1461655.1250\n",
      "Epoch 72/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 98716632.0000 - val_loss: 1172315.0000\n",
      "Epoch 73/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 810959.6875 - val_loss: 390404.2500\n",
      "Epoch 74/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 284888.4375 - val_loss: 131502.5625\n",
      "Epoch 75/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 125761768.0000 - val_loss: 15951270.0000\n",
      "Epoch 76/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 2429973.7500 - val_loss: 506731.3750\n",
      "Epoch 77/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 504890.8750 - val_loss: 299347.5000\n",
      "Epoch 78/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 229670.1406 - val_loss: 99036.6094\n",
      "Epoch 79/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 77138552.0000 - val_loss: 1993880.7500\n",
      "Epoch 80/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 755161.1250 - val_loss: 305696.5312\n",
      "Epoch 81/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 290721.4062 - val_loss: 173441.8281\n",
      "Epoch 82/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 127220.0859 - val_loss: 40731.7695\n",
      "Epoch 83/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 64371736.0000 - val_loss: 1159482.1250\n",
      "Epoch 84/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 763605.6250 - val_loss: 296542.6875\n",
      "Epoch 85/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 271412.7188 - val_loss: 145853.1406\n",
      "Epoch 86/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 126212.5781 - val_loss: 51027.1523\n",
      "Epoch 87/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 87547296.0000 - val_loss: 785179.2500\n",
      "Epoch 88/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 720167.1250 - val_loss: 301436.8750\n",
      "Epoch 89/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 12472470.0000 - val_loss: 218493.5938\n",
      "Epoch 90/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 134291.7031 - val_loss: 83805.5547\n",
      "Epoch 91/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 51225.3320 - val_loss: 21162.3457\n",
      "Epoch 92/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 22472.1211 - val_loss: 4680.8330\n",
      "Epoch 93/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 68159432.0000 - val_loss: 688433.7500\n",
      "Epoch 94/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 566500.4375 - val_loss: 227908.8125\n",
      "Epoch 95/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 195212.4688 - val_loss: 126377.3281\n",
      "Epoch 96/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 100039.5156 - val_loss: 362677.5625\n",
      "Epoch 97/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 164210128.0000 - val_loss: 3841680.0000\n",
      "Epoch 98/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1365648.6250 - val_loss: 548082.5000\n",
      "Epoch 99/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 453247.5312 - val_loss: 184616.3594\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▁█▂▁▁▁▃▁▁▁▁▁▁▁▁▄▁▁▁▁▁▁▇▁▁▁▁▁▁▁▁▃▁▁▁▃▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▅▁▁▁▂▁▁▁▁▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>1</td></tr><tr><td>best_val_loss</td><td>0.86306</td></tr><tr><td>epoch</td><td>98</td></tr><tr><td>loss</td><td>453247.53125</td></tr><tr><td>val_loss</td><td>184616.35938</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">fresh-sweep-33</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/bx477zft\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/bx477zft</a><br/>Synced 6 W&B file(s), 1 media file(s), 9 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_064346-bx477zft/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: u7b59bmj with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2110360446677748\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 74\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.06478427144180464\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 211\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 154\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 245\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 226\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_064956-u7b59bmj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/u7b59bmj\" target=\"_blank\">morning-sweep-34</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/74\n",
      "4556/4581 [============================>.] - ETA: 0s - loss: 289.1961INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_064956-u7b59bmj/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_064956-u7b59bmj/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4581/4581 [==============================] - 7s 1ms/step - loss: 287.6741 - val_loss: 1.2811\n",
      "Epoch 2/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 210287888.0000 - val_loss: 1670250.3750\n",
      "Epoch 3/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 621806.5000 - val_loss: 75466.0156\n",
      "Epoch 4/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 65271520.0000 - val_loss: 288769.1562\n",
      "Epoch 5/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 75980672.0000 - val_loss: 548185.6875\n",
      "Epoch 6/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 297709.5000 - val_loss: 71663.3047\n",
      "Epoch 7/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 66928312.0000 - val_loss: 197297.8125\n",
      "Epoch 8/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 156610.5469 - val_loss: 30767.7773\n",
      "Epoch 9/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 166005344.0000 - val_loss: 513630.3125\n",
      "Epoch 10/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 186752016.0000 - val_loss: 5518110.0000\n",
      "Epoch 11/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1985779.6250 - val_loss: 509377.6562\n",
      "Epoch 12/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 103317192.0000 - val_loss: 581790.7500\n",
      "Epoch 13/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 51516564.0000 - val_loss: 914790.0000\n",
      "Epoch 14/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 467385.0625 - val_loss: 117172.8125\n",
      "Epoch 15/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 66007692.0000 - val_loss: 1069238.3750\n",
      "Epoch 16/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 532308.4375 - val_loss: 143644.6406\n",
      "Epoch 17/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 48286588.0000 - val_loss: 237045.5000\n",
      "Epoch 18/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 155047.8438 - val_loss: 30775.1348\n",
      "Epoch 19/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 99904592.0000 - val_loss: 500276.4062\n",
      "Epoch 20/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 75123048.0000 - val_loss: 752356.5000\n",
      "Epoch 21/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 359803.3125 - val_loss: 69515.9297\n",
      "Epoch 22/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 84900120.0000 - val_loss: 462799.9375\n",
      "Epoch 23/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 212050928.0000 - val_loss: 3579759.2500\n",
      "Epoch 24/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 2251601.0000 - val_loss: 460240.4688\n",
      "Epoch 25/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 33373874.0000 - val_loss: 174955.2344\n",
      "Epoch 26/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 43132048.0000 - val_loss: 1686567.5000\n",
      "Epoch 27/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 540358.3750 - val_loss: 112484.4375\n",
      "Epoch 28/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 54638684.0000 - val_loss: 5636184.0000\n",
      "Epoch 29/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1063753.0000 - val_loss: 184911.8906\n",
      "Epoch 30/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 85336720.0000 - val_loss: 11645235.0000\n",
      "Epoch 31/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1839252.3750 - val_loss: 366457.1875\n",
      "Epoch 32/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 111097520.0000 - val_loss: 1250567.8750\n",
      "Epoch 33/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 652077.8125 - val_loss: 171493.4844\n",
      "Epoch 34/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 194043456.0000 - val_loss: 1209043.1250\n",
      "Epoch 35/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 901099.7500 - val_loss: 161421.4844\n",
      "Epoch 36/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 276544096.0000 - val_loss: 2396474.0000\n",
      "Epoch 37/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1694835.5000 - val_loss: 435462.1562\n",
      "Epoch 38/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 149963888.0000 - val_loss: 992812.3125\n",
      "Epoch 39/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 570980.3125 - val_loss: 383416.8750\n",
      "Epoch 40/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 253731536.0000 - val_loss: 2854162.5000\n",
      "Epoch 41/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1499746.5000 - val_loss: 381502.5938\n",
      "Epoch 42/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 66941904.0000 - val_loss: 1213367.0000\n",
      "Epoch 43/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 648285.8125 - val_loss: 593499.5000\n",
      "Epoch 44/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 124508392.0000 - val_loss: 1033546.6250\n",
      "Epoch 45/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 589599.5000 - val_loss: 240780.9531\n",
      "Epoch 46/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 93091472.0000 - val_loss: 531354.0625\n",
      "Epoch 47/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 231973904.0000 - val_loss: 7341456.5000\n",
      "Epoch 48/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 2178757.5000 - val_loss: 457551.1250\n",
      "Epoch 49/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 152063984.0000 - val_loss: 1064803.2500\n",
      "Epoch 50/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 768593.8125 - val_loss: 335029.2500\n",
      "Epoch 51/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 227341520.0000 - val_loss: 2415898.0000\n",
      "Epoch 52/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 36478648.0000 - val_loss: 14844003.0000\n",
      "Epoch 53/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1137653.6250 - val_loss: 225199.8594\n",
      "Epoch 54/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 92993456.0000 - val_loss: 725964.6875\n",
      "Epoch 55/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 57148524.0000 - val_loss: 1043259.0625\n",
      "Epoch 56/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 688825.6875 - val_loss: 241342.7656\n",
      "Epoch 57/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 112498208.0000 - val_loss: 2180384.7500\n",
      "Epoch 58/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 994539.7500 - val_loss: 346016.0625\n",
      "Epoch 59/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 277644.9375 - val_loss: 40722.8125\n",
      "Epoch 60/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 98932208.0000 - val_loss: 944111.3750\n",
      "Epoch 61/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 187129712.0000 - val_loss: 2094448.0000\n",
      "Epoch 62/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1462811.5000 - val_loss: 539767.4375\n",
      "Epoch 63/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 147299872.0000 - val_loss: 818218.8750\n",
      "Epoch 64/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 80658744.0000 - val_loss: 3709608.5000\n",
      "Epoch 65/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1414794.8750 - val_loss: 309856.8750\n",
      "Epoch 66/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 118260072.0000 - val_loss: 2197946.5000\n",
      "Epoch 67/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 222437856.0000 - val_loss: 5527136.5000\n",
      "Epoch 68/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 2438256.0000 - val_loss: 443763.3125\n",
      "Epoch 69/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 89532712.0000 - val_loss: 2180831744.0000\n",
      "Epoch 70/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 9048510.0000 - val_loss: 478998.0938\n",
      "Epoch 71/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 94987888.0000 - val_loss: 2638854.7500\n",
      "Epoch 72/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1234215.6250 - val_loss: 325295.5000\n",
      "Epoch 73/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 70797424.0000 - val_loss: 450283.3750\n",
      "Epoch 74/74\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 310822.3750 - val_loss: 63210.6289\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▆▃▁▁▆▄▁▃▂▄▁▆▂▁▁▃▄▆█▅▇▃▄▁▇▅▇▁▂▄▁▄▁▃▄▁▁▁▁</td></tr><tr><td>val_loss</td><td>▁▂▁▁▁▄▁▁▂▁▁▁▃▁▁▁█▂▂▂▂▃▂▂▁▅▂▂▁▂▂▁▂▁▃▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>1.28108</td></tr><tr><td>epoch</td><td>73</td></tr><tr><td>loss</td><td>310822.375</td></tr><tr><td>val_loss</td><td>63210.62891</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">morning-sweep-34</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/u7b59bmj\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/u7b59bmj</a><br/>Synced 6 W&B file(s), 1 media file(s), 5 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_064956-u7b59bmj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tcog37ng with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.31176505998917237\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 45\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.06406280621864208\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 245\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 92\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 198\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 76\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 238\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_065717-tcog37ng</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/tcog37ng\" target=\"_blank\">quiet-sweep-35</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n",
      "4543/4581 [============================>.] - ETA: 0s - loss: 14474045.0000INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_065717-tcog37ng/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_065717-tcog37ng/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4581/4581 [==============================] - 6s 1ms/step - loss: 14357026.0000 - val_loss: 59209.3242\n",
      "Epoch 2/45\n",
      "4581/4581 [==============================] - ETA: 0s - loss: 35402.2031INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_065717-tcog37ng/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_065717-tcog37ng/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4581/4581 [==============================] - 6s 1ms/step - loss: 35402.2031 - val_loss: 8209.5596\n",
      "Epoch 3/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 61448736.0000 - val_loss: 836091.3125\n",
      "Epoch 4/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 444077.6250 - val_loss: 49642.6836\n",
      "Epoch 5/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 19303664.0000 - val_loss: 306953.5625\n",
      "Epoch 6/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 151403.1250 - val_loss: 28668.9102\n",
      "Epoch 7/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 19879654.0000 - val_loss: 650728.5625\n",
      "Epoch 8/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 215049.2188 - val_loss: 37992.3594\n",
      "Epoch 9/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 25682326.0000 - val_loss: 171712.8906\n",
      "Epoch 10/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 95114.6016 - val_loss: 16731.6660\n",
      "Epoch 11/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 28854694.0000 - val_loss: 193053.5781\n",
      "Epoch 12/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 24318996.0000 - val_loss: 246167.1250\n",
      "Epoch 13/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 195370.2031 - val_loss: 67876.3281\n",
      "Epoch 14/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 87301104.0000 - val_loss: 16633018.0000\n",
      "Epoch 15/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1120306.8750 - val_loss: 133243.5469\n",
      "Epoch 16/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 22474676.0000 - val_loss: 575853.5625\n",
      "Epoch 17/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 218387.7656 - val_loss: 41893.2266\n",
      "Epoch 18/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 49300648.0000 - val_loss: 394146.4062\n",
      "Epoch 19/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 231701.1562 - val_loss: 41356.2930\n",
      "Epoch 20/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 34538168.0000 - val_loss: 152637.7031\n",
      "Epoch 21/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 28257772.0000 - val_loss: 886496.3125\n",
      "Epoch 22/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 463682.5312 - val_loss: 82510.7734\n",
      "Epoch 23/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 41982876.0000 - val_loss: 796987.0625\n",
      "Epoch 24/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 473865.4375 - val_loss: 112992.1172\n",
      "Epoch 25/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 27680906.0000 - val_loss: 675382.0000\n",
      "Epoch 26/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 351274.3125 - val_loss: 99549.1016\n",
      "Epoch 27/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 48862920.0000 - val_loss: 537237.8125\n",
      "Epoch 28/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 325085.3438 - val_loss: 60309.9570\n",
      "Epoch 29/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 51734832.0000 - val_loss: 276219.0312\n",
      "Epoch 30/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 18592650.0000 - val_loss: 685064.3750\n",
      "Epoch 31/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 243477.1250 - val_loss: 73206.6094\n",
      "Epoch 32/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 34681884.0000 - val_loss: 1364257.1250\n",
      "Epoch 33/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 481864.6250 - val_loss: 72634.3594\n",
      "Epoch 34/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 49932300.0000 - val_loss: 567716.6875\n",
      "Epoch 35/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 394408.0938 - val_loss: 137638.1250\n",
      "Epoch 36/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 50424352.0000 - val_loss: 736625.5000\n",
      "Epoch 37/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 130631232.0000 - val_loss: 1716347.3750\n",
      "Epoch 38/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 28012800.0000 - val_loss: 1977337.7500\n",
      "Epoch 39/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 639276.4375 - val_loss: 117775.2031\n",
      "Epoch 40/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 50605600.0000 - val_loss: 882272.0625\n",
      "Epoch 41/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 343981.3438 - val_loss: 85057.4688\n",
      "Epoch 42/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 86210576.0000 - val_loss: 877521.6875\n",
      "Epoch 43/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 666081.4375 - val_loss: 151894.6250\n",
      "Epoch 44/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 57530564.0000 - val_loss: 237331.5156\n",
      "Epoch 45/45\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 34396576.0000 - val_loss: 1164927.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2ba67b0eb3947a0b2fe3360db3dd8c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='2.349 MB of 3.415 MB uploaded (0.016 MB deduped)\\r'), FloatProgress(value=0.687868…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▂▁▄▁▂▁▂▁▁▃▂▁▆▁▂▁▁▃▃▁▃▁▂▁▁▄▂▁▃▁▄▁█▂▁▄▁▆▁▃</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▂▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>1</td></tr><tr><td>best_val_loss</td><td>8209.55957</td></tr><tr><td>epoch</td><td>44</td></tr><tr><td>loss</td><td>34396576.0</td></tr><tr><td>val_loss</td><td>1164927.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">quiet-sweep-35</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/tcog37ng\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/tcog37ng</a><br/>Synced 6 W&B file(s), 1 media file(s), 9 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_065717-tcog37ng/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: sqe7f541 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5401597513579024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 58\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.09985700045513544\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 234\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 186\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 68\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 188\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 86\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_070129-sqe7f541</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/sqe7f541\" target=\"_blank\">apricot-sweep-36</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/58\n",
      "2260/2291 [============================>.] - ETA: 0s - loss: 3719.2664INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_070129-sqe7f541/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_070129-sqe7f541/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 3670.4265 - val_loss: 8.2858\n",
      "Epoch 2/58\n",
      "2269/2291 [============================>.] - ETA: 0s - loss: 2.6128INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_070129-sqe7f541/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_070129-sqe7f541/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 2.6098 - val_loss: 1.7037\n",
      "Epoch 3/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 264713440.0000 - val_loss: 810305.4375\n",
      "Epoch 4/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 617246.1250 - val_loss: 144703.0156\n",
      "Epoch 5/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 122429.5781 - val_loss: 44279.9961\n",
      "Epoch 6/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 38709.7617 - val_loss: 8091.7607\n",
      "Epoch 7/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1069286720.0000 - val_loss: 2517914.0000\n",
      "Epoch 8/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2319022.2500 - val_loss: 748971.7500\n",
      "Epoch 9/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 721490.0000 - val_loss: 576575.0625\n",
      "Epoch 10/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 279989.2812 - val_loss: 148463.4062\n",
      "Epoch 11/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 304663968.0000 - val_loss: 1793061.3750\n",
      "Epoch 12/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1270774.3750 - val_loss: 348815.6562\n",
      "Epoch 13/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 352139.6875 - val_loss: 107092.3516\n",
      "Epoch 14/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 682789824.0000 - val_loss: 8001627.0000\n",
      "Epoch 15/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 5002638.0000 - val_loss: 1679572.0000\n",
      "Epoch 16/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1373423.1250 - val_loss: 443243.6875\n",
      "Epoch 17/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 459668.2500 - val_loss: 103366.4766\n",
      "Epoch 18/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 542568320.0000 - val_loss: 4456990.5000\n",
      "Epoch 19/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 4497934.0000 - val_loss: 1262026.8750\n",
      "Epoch 20/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1429619.8750 - val_loss: 855394.0625\n",
      "Epoch 21/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 965715136.0000 - val_loss: 7613886.5000\n",
      "Epoch 22/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 4782612.5000 - val_loss: 1868488.5000\n",
      "Epoch 23/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1498771.8750 - val_loss: 529219.5625\n",
      "Epoch 24/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 462271776.0000 - val_loss: 7364149.0000\n",
      "Epoch 25/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 4925374.0000 - val_loss: 2162340.2500\n",
      "Epoch 26/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1360256.8750 - val_loss: 479189.6875\n",
      "Epoch 27/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 416916.3750 - val_loss: 141883.3906\n",
      "Epoch 28/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2714154752.0000 - val_loss: 171136720.0000\n",
      "Epoch 29/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 37860940.0000 - val_loss: 10727293.0000\n",
      "Epoch 30/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 8255890.5000 - val_loss: 2774849.0000\n",
      "Epoch 31/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2452504.0000 - val_loss: 758554.1875\n",
      "Epoch 32/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1292580.0000 - val_loss: 430017.5000\n",
      "Epoch 33/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 508449408.0000 - val_loss: 3849223.2500\n",
      "Epoch 34/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1941366.5000 - val_loss: 741074.9375\n",
      "Epoch 35/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 610386.2500 - val_loss: 167106.7188\n",
      "Epoch 36/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 364256416.0000 - val_loss: 7329435.5000\n",
      "Epoch 37/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 4662434.0000 - val_loss: 1484169.3750\n",
      "Epoch 38/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1383995.7500 - val_loss: 581400.0625\n",
      "Epoch 39/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 619818.7500 - val_loss: 216950.2188\n",
      "Epoch 40/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 653733184.0000 - val_loss: 2677061.5000\n",
      "Epoch 41/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2516735.7500 - val_loss: 876288.2500\n",
      "Epoch 42/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 909069.1875 - val_loss: 480849.9062\n",
      "Epoch 43/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 982023872.0000 - val_loss: 31157798.0000\n",
      "Epoch 44/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 14412909.0000 - val_loss: 3260774.0000\n",
      "Epoch 45/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3299069.0000 - val_loss: 815144.9375\n",
      "Epoch 46/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 640685824.0000 - val_loss: 3795060.5000\n",
      "Epoch 47/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3611841.5000 - val_loss: 1411776.5000\n",
      "Epoch 48/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1117027.6250 - val_loss: 788019.3750\n",
      "Epoch 49/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 331004.0938 - val_loss: 80333.6094\n",
      "Epoch 50/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1331878016.0000 - val_loss: 1629184896.0000\n",
      "Epoch 51/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 55942016.0000 - val_loss: 6004737.0000\n",
      "Epoch 52/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1436638592.0000 - val_loss: 191435568.0000\n",
      "Epoch 53/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 41606924.0000 - val_loss: 7476669.0000\n",
      "Epoch 54/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 5396746.5000 - val_loss: 1009863.6250\n",
      "Epoch 55/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2204328.5000 - val_loss: 5879756.0000\n",
      "Epoch 56/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1329748992.0000 - val_loss: 13636684.0000\n",
      "Epoch 57/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 9976405.0000 - val_loss: 3059898.5000\n",
      "Epoch 58/58\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3443888.5000 - val_loss: 1036676.4375\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▂▁▁▁▁▂▁▃▁▁▂▁▃▁▂▁▁█▁▁▂▁▂▁▁▃▁▄▁▃▁▁▄▅▁▁▄▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>1</td></tr><tr><td>best_val_loss</td><td>1.7037</td></tr><tr><td>epoch</td><td>57</td></tr><tr><td>loss</td><td>3443888.5</td></tr><tr><td>val_loss</td><td>1036676.4375</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">apricot-sweep-36</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/sqe7f541\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/sqe7f541</a><br/>Synced 6 W&B file(s), 1 media file(s), 9 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_070129-sqe7f541/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ajwdzsgr with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2700558617338092\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 43\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.05212524308892931\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 178\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 192\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 102\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 238\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 167\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_070439-ajwdzsgr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/ajwdzsgr\" target=\"_blank\">sweet-sweep-37</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/43\n",
      "1505/1527 [============================>.] - ETA: 0s - loss: 51.7319INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_070439-ajwdzsgr/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_070439-ajwdzsgr/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 4s 2ms/step - loss: 51.0069 - val_loss: 0.7679\n",
      "Epoch 2/43\n",
      "1523/1527 [============================>.] - ETA: 0s - loss: 0.8104INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_070439-ajwdzsgr/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_070439-ajwdzsgr/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.8101 - val_loss: 0.7590\n",
      "Epoch 3/43\n",
      "1526/1527 [============================>.] - ETA: 0s - loss: 0.7803INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_070439-ajwdzsgr/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_070439-ajwdzsgr/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.7802 - val_loss: 0.7528\n",
      "Epoch 4/43\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.7917 - val_loss: 0.7761\n",
      "Epoch 5/43\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.8293 - val_loss: 0.8190\n",
      "Epoch 6/43\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 18418660.0000 - val_loss: 38962.3594\n",
      "Epoch 7/43\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 46062.0664 - val_loss: 18205.6641\n",
      "Epoch 8/43\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 17590.4316 - val_loss: 5301.2144\n",
      "Epoch 9/43\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 8821.6455 - val_loss: 3217.4585\n",
      "Epoch 10/43\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 4945.7583 - val_loss: 2928.3606\n",
      "Epoch 11/43\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 51283908.0000 - val_loss: 271962.7812\n",
      "Epoch 12/43\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 176681.6875 - val_loss: 75345.6328\n",
      "Epoch 13/43\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 95611.7344 - val_loss: 122405.7656\n",
      "Epoch 14/43\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 45710.7930 - val_loss: 23286.9531\n",
      "Epoch 15/43\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 20600.2285 - val_loss: 10755.8535\n",
      "Epoch 16/43\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 62741984.0000 - val_loss: 462812.4375\n",
      "Epoch 17/43\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 219461.3906 - val_loss: 72996.0312\n",
      "Epoch 18/43\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 106543.1016 - val_loss: 38957.8828\n",
      "Epoch 19/43\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 46778.1211 - val_loss: 19149.8379\n",
      "Epoch 20/43\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 66522696.0000 - val_loss: 223697.1562\n",
      "Epoch 21/43\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 223828.9219 - val_loss: 71422.0312\n",
      "Epoch 22/43\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 93930.2578 - val_loss: 43241.7539\n",
      "Epoch 23/43\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 28987236.0000 - val_loss: 489254.4688\n",
      "Epoch 24/43\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 252742.2031 - val_loss: 112126.4219\n",
      "Epoch 25/43\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 99201.1641 - val_loss: 52664.0000\n",
      "Epoch 26/43\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 41192416.0000 - val_loss: 5019974.0000\n",
      "Epoch 27/43\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 893328.0000 - val_loss: 134940.4844\n",
      "Epoch 28/43\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 179570.0781 - val_loss: 69199.8359\n",
      "Epoch 29/43\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 90382.1719 - val_loss: 32989.5859\n",
      "Epoch 30/43\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 47248.0508 - val_loss: 14257.1016\n",
      "Epoch 31/43\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 64929852.0000 - val_loss: 251893.1875\n",
      "Epoch 32/43\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 290879.7500 - val_loss: 126732.4766\n",
      "Epoch 33/43\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 160081.1719 - val_loss: 64217.0625\n",
      "Epoch 34/43\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 80731.9531 - val_loss: 31312.6270\n",
      "Epoch 35/43\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 55418.8984 - val_loss: 22978.0566\n",
      "Epoch 36/43\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 60020632.0000 - val_loss: 67467872.0000\n",
      "Epoch 37/43\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 2064981.8750 - val_loss: 120048.9062\n",
      "Epoch 38/43\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 183803.1719 - val_loss: 75175.4219\n",
      "Epoch 39/43\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 93909.1250 - val_loss: 46484.3281\n",
      "Epoch 40/43\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 53625.7617 - val_loss: 22204.4082\n",
      "Epoch 41/43\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 180736240.0000 - val_loss: 1086160.3750\n",
      "Epoch 42/43\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1199937.3750 - val_loss: 632118.8125\n",
      "Epoch 43/43\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 528418.8125 - val_loss: 289116.3438\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>loss</td><td>▁▁▁▁▁▂▁▁▁▁▃▁▁▁▃▁▁▁▄▁▁▂▁▁▃▁▁▁▄▁▁▁▁▃▁▁▁▁█▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁█▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>2</td></tr><tr><td>best_val_loss</td><td>0.75282</td></tr><tr><td>epoch</td><td>42</td></tr><tr><td>loss</td><td>528418.8125</td></tr><tr><td>val_loss</td><td>289116.34375</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">sweet-sweep-37</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/ajwdzsgr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/ajwdzsgr</a><br/>Synced 6 W&B file(s), 1 media file(s), 13 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_070439-ajwdzsgr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bce93xqi with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.0034121937758504026\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 78\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.09125729497104204\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 207\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 252\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 104\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 141\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 106\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_070652-bce93xqi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/bce93xqi\" target=\"_blank\">hardy-sweep-38</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/78\n",
      "1138/1146 [============================>.] - ETA: 0s - loss: 11398.9785INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_070652-bce93xqi/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_070652-bce93xqi/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 3ms/step - loss: 11328.8008 - val_loss: 7.8950\n",
      "Epoch 2/78\n",
      "1141/1146 [============================>.] - ETA: 0s - loss: 7.6440INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_070652-bce93xqi/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_070652-bce93xqi/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 3ms/step - loss: 7.6247 - val_loss: 1.8946\n",
      "Epoch 3/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 660384192.0000 - val_loss: 29572526080.0000\n",
      "Epoch 4/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 377159168.0000 - val_loss: 1671324.5000\n",
      "Epoch 5/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1884846.7500 - val_loss: 2870296.7500\n",
      "Epoch 6/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 985104.6875 - val_loss: 1305932.0000\n",
      "Epoch 7/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2420196.5000 - val_loss: 596846.6250\n",
      "Epoch 8/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 131391.9688 - val_loss: 45228.6992\n",
      "Epoch 9/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 96193.0781 - val_loss: 453288.1875\n",
      "Epoch 10/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 4616863744.0000 - val_loss: 7460086.0000\n",
      "Epoch 11/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 6598405.0000 - val_loss: 3177245.7500\n",
      "Epoch 12/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2966876.2500 - val_loss: 2153322.5000\n",
      "Epoch 13/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1433189.0000 - val_loss: 6030528.0000\n",
      "Epoch 14/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1002322.5625 - val_loss: 400924.2500\n",
      "Epoch 15/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 3252926.7500 - val_loss: 119865.7344\n",
      "Epoch 16/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 159108.7188 - val_loss: 73878.9922\n",
      "Epoch 17/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2568406784.0000 - val_loss: 10353466.0000\n",
      "Epoch 18/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 5870446.0000 - val_loss: 11379472.0000\n",
      "Epoch 19/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2761783.0000 - val_loss: 2630757.2500\n",
      "Epoch 20/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1326062.6250 - val_loss: 1359214.3750\n",
      "Epoch 21/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 770336.9375 - val_loss: 854171.7500\n",
      "Epoch 22/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2215561216.0000 - val_loss: 17583330.0000\n",
      "Epoch 23/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 11196475.0000 - val_loss: 6013102.5000\n",
      "Epoch 24/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 5308561.5000 - val_loss: 5367110.0000\n",
      "Epoch 25/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2719821.7500 - val_loss: 1800781.8750\n",
      "Epoch 26/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1601081.8750 - val_loss: 1897215.1250\n",
      "Epoch 27/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 816052.9375 - val_loss: 1195283.7500\n",
      "Epoch 28/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 746690.5625 - val_loss: 177055.8281\n",
      "Epoch 29/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2333718016.0000 - val_loss: 24750682.0000\n",
      "Epoch 30/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8034517.5000 - val_loss: 3851688.2500\n",
      "Epoch 31/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 4867122.0000 - val_loss: 3277692.7500\n",
      "Epoch 32/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 3096490.2500 - val_loss: 2617476.0000\n",
      "Epoch 33/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2330249.0000 - val_loss: 1129934.5000\n",
      "Epoch 34/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 3533921280.0000 - val_loss: 43799164.0000\n",
      "Epoch 35/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 18815074.0000 - val_loss: 19618324.0000\n",
      "Epoch 36/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8829212.0000 - val_loss: 8194900.0000\n",
      "Epoch 37/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 5135128.0000 - val_loss: 1822960.5000\n",
      "Epoch 38/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2230472.7500 - val_loss: 1570337.7500\n",
      "Epoch 39/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 5051118.0000 - val_loss: 576118.6250\n",
      "Epoch 40/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 6749546496.0000 - val_loss: 90270000.0000\n",
      "Epoch 41/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 51969540.0000 - val_loss: 29499992.0000\n",
      "Epoch 42/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 21988010.0000 - val_loss: 19822198.0000\n",
      "Epoch 43/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 11544745.0000 - val_loss: 11508666.0000\n",
      "Epoch 44/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 6749198.0000 - val_loss: 4759754.0000\n",
      "Epoch 45/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 4040824320.0000 - val_loss: 38460384.0000\n",
      "Epoch 46/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 29795174.0000 - val_loss: 37831892.0000\n",
      "Epoch 47/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 14053075.0000 - val_loss: 12348381.0000\n",
      "Epoch 48/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 6720694.5000 - val_loss: 4472878.0000\n",
      "Epoch 49/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 3746105.0000 - val_loss: 5282442.0000\n",
      "Epoch 50/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 5821608.0000 - val_loss: 8367373.5000\n",
      "Epoch 51/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1347256.2500 - val_loss: 2645023.0000\n",
      "Epoch 52/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 5259159040.0000 - val_loss: 20012832.0000\n",
      "Epoch 53/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 23720596.0000 - val_loss: 9171770.0000\n",
      "Epoch 54/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8055901.0000 - val_loss: 6855392.0000\n",
      "Epoch 55/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 7884484.0000 - val_loss: 12512066.0000\n",
      "Epoch 56/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 4841016832.0000 - val_loss: 90582520.0000\n",
      "Epoch 57/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 31736420.0000 - val_loss: 17576210.0000\n",
      "Epoch 58/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 15036501.0000 - val_loss: 11777389.0000\n",
      "Epoch 59/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 10063259.0000 - val_loss: 6952646.0000\n",
      "Epoch 60/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 3822859008.0000 - val_loss: 36097936.0000\n",
      "Epoch 61/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 18824130.0000 - val_loss: 16395765.0000\n",
      "Epoch 62/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 9808515.0000 - val_loss: 35990304.0000\n",
      "Epoch 63/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8362608.5000 - val_loss: 21364102.0000\n",
      "Epoch 64/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 4671259648.0000 - val_loss: 106487640.0000\n",
      "Epoch 65/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 36498948.0000 - val_loss: 44298984.0000\n",
      "Epoch 66/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 16190742.0000 - val_loss: 30782232.0000\n",
      "Epoch 67/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 7765755.0000 - val_loss: 5337254.5000\n",
      "Epoch 68/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 5207468.0000 - val_loss: 7495137.0000\n",
      "Epoch 69/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2264538112.0000 - val_loss: 20462396.0000\n",
      "Epoch 70/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 12221334.0000 - val_loss: 7668455.0000\n",
      "Epoch 71/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 6200698.5000 - val_loss: 3489352.2500\n",
      "Epoch 72/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 4776255.5000 - val_loss: 2799973.7500\n",
      "Epoch 73/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8622357.0000 - val_loss: 1153567.0000\n",
      "Epoch 74/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 3361135616.0000 - val_loss: 62777164.0000\n",
      "Epoch 75/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 21471190.0000 - val_loss: 15363629.0000\n",
      "Epoch 76/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 12687689.0000 - val_loss: 14519985.0000\n",
      "Epoch 77/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 5510956.0000 - val_loss: 3875349.0000\n",
      "Epoch 78/78\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 4631805.0000 - val_loss: 3605941.7500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▁▁▁▆▁▁▁▁▁▃▁▁▁▁▁▅▁▁█▁▁▁▁▁▆▁▆▁▅▁▆▁▁▁▁▄▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▂▁▂▁▁▁▁▁▄▂▁▇▂▁▃▁▂▂▁▇▂▃▃█▃▁▂▁▅▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>1</td></tr><tr><td>best_val_loss</td><td>1.89456</td></tr><tr><td>epoch</td><td>77</td></tr><tr><td>loss</td><td>4631805.0</td></tr><tr><td>val_loss</td><td>3605941.75</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">hardy-sweep-38</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/bce93xqi\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/bce93xqi</a><br/>Synced 6 W&B file(s), 1 media file(s), 9 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_070652-bce93xqi/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: whgyl6fk with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5792621728827462\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 74\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.03448595616719846\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 143\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 251\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 194\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 74\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 105\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_071007-whgyl6fk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/whgyl6fk\" target=\"_blank\">divine-sweep-39</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/74\n",
      "4549/4581 [============================>.] - ETA: 0s - loss: 2.6565INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_071007-whgyl6fk/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_071007-whgyl6fk/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4581/4581 [==============================] - 6s 1ms/step - loss: 2.6468 - val_loss: 1.0296\n",
      "Epoch 2/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 451550.1562 - val_loss: 1558.8004\n",
      "Epoch 3/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 729.2151 - val_loss: 100.5266\n",
      "Epoch 4/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 222284.7969 - val_loss: 1070.8823\n",
      "Epoch 5/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 188897.3750 - val_loss: 2532.3306\n",
      "Epoch 6/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1627.4238 - val_loss: 354.8303\n",
      "Epoch 7/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 360333.9688 - val_loss: 7651.3691\n",
      "Epoch 8/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 3253.3489 - val_loss: 480.7070\n",
      "Epoch 9/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 722653.6875 - val_loss: 10112.2080\n",
      "Epoch 10/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 8624.5049 - val_loss: 1297.3842\n",
      "Epoch 11/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 314737.3438 - val_loss: 3164.8843\n",
      "Epoch 12/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2311.6213 - val_loss: 514.3643\n",
      "Epoch 13/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 656809.0625 - val_loss: 10722.6807\n",
      "Epoch 14/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 6825.1738 - val_loss: 846.1034\n",
      "Epoch 15/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 260761.2188 - val_loss: 2542.4233\n",
      "Epoch 16/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1562.7632 - val_loss: 634.0756\n",
      "Epoch 17/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 866424.3750 - val_loss: 5595.7075\n",
      "Epoch 18/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 3617.5725 - val_loss: 1315.4194\n",
      "Epoch 19/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 344160.0312 - val_loss: 4751.1797\n",
      "Epoch 20/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 3286.7556 - val_loss: 453.5027\n",
      "Epoch 21/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 151188.7031 - val_loss: 4590.8936\n",
      "Epoch 22/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2397.6812 - val_loss: 378.5251\n",
      "Epoch 23/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 192318.6719 - val_loss: 2418.6860\n",
      "Epoch 24/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1349.4207 - val_loss: 965.7172\n",
      "Epoch 25/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 117372.4062 - val_loss: 1503.5441\n",
      "Epoch 26/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 929.5898 - val_loss: 268.6071\n",
      "Epoch 27/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 353401.4062 - val_loss: 2871.5952\n",
      "Epoch 28/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1937.6334 - val_loss: 257.1626\n",
      "Epoch 29/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 277367.4062 - val_loss: 3674.8186\n",
      "Epoch 30/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2396.9111 - val_loss: 437.5032\n",
      "Epoch 31/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 192936.5469 - val_loss: 13114.7314\n",
      "Epoch 32/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 3749.0830 - val_loss: 430.6596\n",
      "Epoch 33/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 190187.0938 - val_loss: 2498.4102\n",
      "Epoch 34/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2092.0132 - val_loss: 630.3550\n",
      "Epoch 35/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 320316.0312 - val_loss: 1417.0123\n",
      "Epoch 36/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1047.3536 - val_loss: 283.5579\n",
      "Epoch 37/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 194197.7344 - val_loss: 935.1129\n",
      "Epoch 38/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 639.3144 - val_loss: 258.5423\n",
      "Epoch 39/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 167059.2969 - val_loss: 830.2208\n",
      "Epoch 40/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 613.9884 - val_loss: 178.9687\n",
      "Epoch 41/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 248132.2969 - val_loss: 3854.4150\n",
      "Epoch 42/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2374.1265 - val_loss: 371.1049\n",
      "Epoch 43/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 120343.8359 - val_loss: 8587.0820\n",
      "Epoch 44/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2513.7563 - val_loss: 325.7343\n",
      "Epoch 45/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 570742.8750 - val_loss: 10228.0049\n",
      "Epoch 46/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 8318.8604 - val_loss: 1753.4956\n",
      "Epoch 47/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 224605.7188 - val_loss: 5564.0024\n",
      "Epoch 48/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2876.6597 - val_loss: 314.2606\n",
      "Epoch 49/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 231835.1250 - val_loss: 2724.8813\n",
      "Epoch 50/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1452.5745 - val_loss: 717.6377\n",
      "Epoch 51/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 338807.6250 - val_loss: 2780.8291\n",
      "Epoch 52/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2184.9585 - val_loss: 389.0781\n",
      "Epoch 53/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 160021.5312 - val_loss: 1684.5884\n",
      "Epoch 54/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1089.2880 - val_loss: 368.9020\n",
      "Epoch 55/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 176487.3281 - val_loss: 804.4401\n",
      "Epoch 56/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 558.1788 - val_loss: 94.2031\n",
      "Epoch 57/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 145669.1250 - val_loss: 814.1985\n",
      "Epoch 58/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 675.5612 - val_loss: 124.1794\n",
      "Epoch 59/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 185914.7500 - val_loss: 1608.1416\n",
      "Epoch 60/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 626.6329 - val_loss: 108.0629\n",
      "Epoch 61/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 152774.5625 - val_loss: 1159.0182\n",
      "Epoch 62/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 672.2218 - val_loss: 778.8552\n",
      "Epoch 63/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 119720.4766 - val_loss: 3106.8013\n",
      "Epoch 64/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1697.7729 - val_loss: 253.5240\n",
      "Epoch 65/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 92436.4688 - val_loss: 2285.8140\n",
      "Epoch 66/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1141.8474 - val_loss: 239.0946\n",
      "Epoch 67/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 321657.1562 - val_loss: 1600.0135\n",
      "Epoch 68/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 545256.1875 - val_loss: 123774.7500\n",
      "Epoch 69/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 14239.3857 - val_loss: 2173.2974\n",
      "Epoch 70/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 632215.1875 - val_loss: 13430.3721\n",
      "Epoch 71/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 5670.3247 - val_loss: 1729.6642\n",
      "Epoch 72/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 183972.8438 - val_loss: 1363.0807\n",
      "Epoch 73/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 955.8635 - val_loss: 189.9518\n",
      "Epoch 74/74\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 326272.2188 - val_loss: 2680.6895\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "876c064afb8d40bda771d14174418359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='2.862 MB of 2.862 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▅▃▁▁▁▁▁▃█▄▂▃▂▄▃▁▁▁▁▁▁▁▁▆▃▃▄▂▂▂▃▁▁▁▁▅▆▂▄</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁█▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>1.02956</td></tr><tr><td>epoch</td><td>73</td></tr><tr><td>loss</td><td>326272.21875</td></tr><tr><td>val_loss</td><td>2680.68945</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">divine-sweep-39</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/whgyl6fk\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/whgyl6fk</a><br/>Synced 6 W&B file(s), 1 media file(s), 5 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_071007-whgyl6fk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0vj2ad1w with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.30969014214573504\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 53\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0896116504820449\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 76\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 152\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 176\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 235\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_071652-0vj2ad1w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/0vj2ad1w\" target=\"_blank\">whole-sweep-40</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/53\n",
      "1503/1527 [============================>.] - ETA: 0s - loss: 2925.5684INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_071652-0vj2ad1w/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_071652-0vj2ad1w/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 4s 2ms/step - loss: 2880.1279 - val_loss: 2.4221\n",
      "Epoch 2/53\n",
      "1509/1527 [============================>.] - ETA: 0s - loss: 2.1611INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_071652-0vj2ad1w/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_071652-0vj2ad1w/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 3s 2ms/step - loss: 2.1521 - val_loss: 1.0735\n",
      "Epoch 3/53\n",
      "1512/1527 [============================>.] - ETA: 0s - loss: 1.4643INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_071652-0vj2ad1w/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_071652-0vj2ad1w/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1.4634 - val_loss: 0.9029\n",
      "Epoch 4/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1278983808.0000 - val_loss: 2603521.5000\n",
      "Epoch 5/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 3474239.0000 - val_loss: 1829759.3750\n",
      "Epoch 6/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1681832.5000 - val_loss: 347441.9688\n",
      "Epoch 7/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 657338.1250 - val_loss: 161823.5469\n",
      "Epoch 8/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 233392.1562 - val_loss: 64786.1797\n",
      "Epoch 9/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 132294.0625 - val_loss: 10509891.0000\n",
      "Epoch 10/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 308609664.0000 - val_loss: 529356.4375\n",
      "Epoch 11/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 751946.2500 - val_loss: 256498.1719\n",
      "Epoch 12/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 304224.5938 - val_loss: 164129.8594\n",
      "Epoch 13/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 133956.1719 - val_loss: 45901.5625\n",
      "Epoch 14/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 64860.1836 - val_loss: 47439.7773\n",
      "Epoch 15/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 4973208576.0000 - val_loss: 43195704.0000\n",
      "Epoch 16/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 27131998.0000 - val_loss: 8707834.0000\n",
      "Epoch 17/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 10563566.0000 - val_loss: 4257165.0000\n",
      "Epoch 18/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 4634642.0000 - val_loss: 1732277.1250\n",
      "Epoch 19/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 2302061.2500 - val_loss: 1262954.2500\n",
      "Epoch 20/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1216407.8750 - val_loss: 525871.8125\n",
      "Epoch 21/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 578072512.0000 - val_loss: 3897792.2500\n",
      "Epoch 22/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 2838419.2500 - val_loss: 1292024.8750\n",
      "Epoch 23/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1406160.8750 - val_loss: 1103331.3750\n",
      "Epoch 24/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 697350.6875 - val_loss: 460569.2188\n",
      "Epoch 25/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 344410.5938 - val_loss: 295656.8125\n",
      "Epoch 26/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 812447872.0000 - val_loss: 3435340.7500\n",
      "Epoch 27/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 3346253.0000 - val_loss: 1235941.6250\n",
      "Epoch 28/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1271023.5000 - val_loss: 518238.7500\n",
      "Epoch 29/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 674006.3125 - val_loss: 478867.3750\n",
      "Epoch 30/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 387995.5000 - val_loss: 154296.6875\n",
      "Epoch 31/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 4747772416.0000 - val_loss: 45015856.0000\n",
      "Epoch 32/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 43320228.0000 - val_loss: 11740974.0000\n",
      "Epoch 33/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 19133246.0000 - val_loss: 5420150.0000\n",
      "Epoch 34/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 8179718.5000 - val_loss: 4159824.7500\n",
      "Epoch 35/53\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 3238695.5000 - val_loss: 1304956.6250\n",
      "Epoch 36/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1534719.7500 - val_loss: 500968.4688\n",
      "Epoch 37/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1166694144.0000 - val_loss: 38573008.0000\n",
      "Epoch 38/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 10812574.0000 - val_loss: 3949988.7500\n",
      "Epoch 39/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 3963777.7500 - val_loss: 1677554.1250\n",
      "Epoch 40/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1923320.2500 - val_loss: 1126419.5000\n",
      "Epoch 41/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1007193.9375 - val_loss: 452207.2500\n",
      "Epoch 42/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 526702.7500 - val_loss: 164474.1406\n",
      "Epoch 43/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 658927488.0000 - val_loss: 6480712704.0000\n",
      "Epoch 44/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 77000984.0000 - val_loss: 3978471.0000\n",
      "Epoch 45/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 3578357.0000 - val_loss: 1601169.5000\n",
      "Epoch 46/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1653275.5000 - val_loss: 1018155.2500\n",
      "Epoch 47/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 916303.0625 - val_loss: 403834.3750\n",
      "Epoch 48/53\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 547317.5625 - val_loss: 209834.4688\n",
      "Epoch 49/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 544518464.0000 - val_loss: 3458557.2500\n",
      "Epoch 50/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 3045001.5000 - val_loss: 1465160.5000\n",
      "Epoch 51/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1478487.3750 - val_loss: 643841.4375\n",
      "Epoch 52/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 774791.1875 - val_loss: 624616.0000\n",
      "Epoch 53/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 423637.2812 - val_loss: 171842.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▂▁▁▁▂▁▁▁█▁▁▁▃▁▁▁▁▂▁▁▁▂▁▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>2</td></tr><tr><td>best_val_loss</td><td>0.90291</td></tr><tr><td>epoch</td><td>52</td></tr><tr><td>loss</td><td>423637.28125</td></tr><tr><td>val_loss</td><td>171842.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">whole-sweep-40</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/0vj2ad1w\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/0vj2ad1w</a><br/>Synced 6 W&B file(s), 1 media file(s), 13 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_071652-0vj2ad1w/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: po6qqkv0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.23590527677156423\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.010745288424054512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 163\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 71\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 113\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 244\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 213\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_071932-po6qqkv0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/po6qqkv0\" target=\"_blank\">fast-sweep-41</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/94\n",
      "2287/2291 [============================>.] - ETA: 0s - loss: 0.9253INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_071932-po6qqkv0/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_071932-po6qqkv0/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 0.9251 - val_loss: 0.7776\n",
      "Epoch 2/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1050.2433 - val_loss: 55.6315\n",
      "Epoch 3/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 7.7110 - val_loss: 3.1790\n",
      "Epoch 4/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2.0679 - val_loss: 1.2217\n",
      "Epoch 5/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.1969 - val_loss: 0.9606\n",
      "Epoch 6/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.9757 - val_loss: 0.8001\n",
      "Epoch 7/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 680.2243 - val_loss: 7.8638\n",
      "Epoch 8/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3.0118 - val_loss: 1.2100\n",
      "Epoch 9/94\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 1.5149 - val_loss: 0.9763\n",
      "Epoch 10/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.1114 - val_loss: 0.8011\n",
      "Epoch 11/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 597.6814 - val_loss: 7.3458\n",
      "Epoch 12/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3.9320 - val_loss: 2.8347\n",
      "Epoch 13/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.8827 - val_loss: 3.1709\n",
      "Epoch 14/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.0840 - val_loss: 0.8314\n",
      "Epoch 15/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 291.6613 - val_loss: 2.0001\n",
      "Epoch 16/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2.2214 - val_loss: 1.0443\n",
      "Epoch 17/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.2321 - val_loss: 0.8344\n",
      "Epoch 18/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.8551 - val_loss: 0.9067\n",
      "Epoch 19/94\n",
      "2282/2291 [============================>.] - ETA: 0s - loss: 0.8318INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_071932-po6qqkv0/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_071932-po6qqkv0/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 0.8312 - val_loss: 0.7281\n",
      "Epoch 20/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.8227 - val_loss: 1.0498\n",
      "Epoch 21/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 168.4509 - val_loss: 3.5695\n",
      "Epoch 22/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.8190 - val_loss: 1.2410\n",
      "Epoch 23/94\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 1.0360 - val_loss: 0.8404\n",
      "Epoch 24/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 468.0287 - val_loss: 8.2048\n",
      "Epoch 25/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3.8472 - val_loss: 1.6919\n",
      "Epoch 26/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.7195 - val_loss: 1.2245\n",
      "Epoch 27/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.1020 - val_loss: 0.9253\n",
      "Epoch 28/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 260.7220 - val_loss: 5.5137\n",
      "Epoch 29/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3.2935 - val_loss: 1.5560\n",
      "Epoch 30/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.6560 - val_loss: 1.0363\n",
      "Epoch 31/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.0701 - val_loss: 0.8153\n",
      "Epoch 32/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 193.1608 - val_loss: 12.1957\n",
      "Epoch 33/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3.8119 - val_loss: 3.1665\n",
      "Epoch 34/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.4610 - val_loss: 1.0268\n",
      "Epoch 35/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.0104 - val_loss: 0.7931\n",
      "Epoch 36/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.8480 - val_loss: 1.0491\n",
      "Epoch 37/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 355.0318 - val_loss: 4.4724\n",
      "Epoch 38/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2.0907 - val_loss: 1.2474\n",
      "Epoch 39/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.1016 - val_loss: 0.7800\n",
      "Epoch 40/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.8480 - val_loss: 0.7515\n",
      "Epoch 41/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.8168 - val_loss: 0.7417\n",
      "Epoch 42/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 614.8573 - val_loss: 7.7329\n",
      "Epoch 43/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3.4956 - val_loss: 1.9109\n",
      "Epoch 44/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.6692 - val_loss: 1.1365\n",
      "Epoch 45/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.0620 - val_loss: 0.8502\n",
      "Epoch 46/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.8688 - val_loss: 0.9663\n",
      "Epoch 47/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 374.8904 - val_loss: 3.7924\n",
      "Epoch 48/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2.3740 - val_loss: 1.4962\n",
      "Epoch 49/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.2442 - val_loss: 0.8297\n",
      "Epoch 50/94\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 0.9079 - val_loss: 0.8540\n",
      "Epoch 51/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.8177 - val_loss: 1.3349\n",
      "Epoch 52/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.8333 - val_loss: 0.8063\n",
      "Epoch 53/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 364.1109 - val_loss: 3.0119\n",
      "Epoch 54/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2.0612 - val_loss: 1.2817\n",
      "Epoch 55/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.1260 - val_loss: 0.9381\n",
      "Epoch 56/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.8959 - val_loss: 0.7978\n",
      "Epoch 57/94\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 571.1700 - val_loss: 5.4805\n",
      "Epoch 58/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3.5320 - val_loss: 1.2632\n",
      "Epoch 59/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.5440 - val_loss: 1.0967\n",
      "Epoch 60/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.0139 - val_loss: 0.8498\n",
      "Epoch 61/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 505.2731 - val_loss: 3.1138\n",
      "Epoch 62/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2.7607 - val_loss: 1.4004\n",
      "Epoch 63/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.4604 - val_loss: 1.1493\n",
      "Epoch 64/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.9685 - val_loss: 1.0382\n",
      "Epoch 65/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 127.0517 - val_loss: 2.9472\n",
      "Epoch 66/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.9171 - val_loss: 1.1207\n",
      "Epoch 67/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.0598 - val_loss: 1.2390\n",
      "Epoch 68/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.8440 - val_loss: 0.9021\n",
      "Epoch 69/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.8228 - val_loss: 0.8178\n",
      "Epoch 70/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 633.0012 - val_loss: 3.5588\n",
      "Epoch 71/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2.8410 - val_loss: 1.5590\n",
      "Epoch 72/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.4467 - val_loss: 1.0541\n",
      "Epoch 73/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.0233 - val_loss: 0.9458\n",
      "Epoch 74/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 488.6626 - val_loss: 17.1953\n",
      "Epoch 75/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 5.5116 - val_loss: 1.9347\n",
      "Epoch 76/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.8539 - val_loss: 1.1878\n",
      "Epoch 77/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.1457 - val_loss: 1.0005\n",
      "Epoch 78/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.8793 - val_loss: 0.7563\n",
      "Epoch 79/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 625.7939 - val_loss: 5.1974\n",
      "Epoch 80/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3.5277 - val_loss: 1.4420\n",
      "Epoch 81/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.5327 - val_loss: 0.9900\n",
      "Epoch 82/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 603.4641 - val_loss: 11.2629\n",
      "Epoch 83/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 7.3477 - val_loss: 3.6165\n",
      "Epoch 84/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2.5832 - val_loss: 1.2866\n",
      "Epoch 85/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.1765 - val_loss: 0.8738\n",
      "Epoch 86/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 565.0533 - val_loss: 16.1295\n",
      "Epoch 87/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 7.8213 - val_loss: 3.6543\n",
      "Epoch 88/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2.3981 - val_loss: 1.3764\n",
      "Epoch 89/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.3903 - val_loss: 1.0208\n",
      "Epoch 90/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 337.5879 - val_loss: 11.0574\n",
      "Epoch 91/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 4.2689 - val_loss: 1.9149\n",
      "Epoch 92/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.8428 - val_loss: 1.0113\n",
      "Epoch 93/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1.1539 - val_loss: 1.1394\n",
      "Epoch 94/94\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 102.3386 - val_loss: 11.9521\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00fc312c7502410a95e04f56a12847d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='4.174 MB of 4.174 MB uploaded (0.016 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▁▁▁▁▄▁▁▁▆▁▁▃▁▁▁▁▁▁▁▁▅▁▁▁▁▂▁█▁▆▁██▁▇▁▁▂</td></tr><tr><td>val_loss</td><td>▁▂▁▁▁▂▂▁▁▁▄▁▁▆▁▁▁▁▁▁▁▁▂▁▁▁▁▂▁▂▁█▁▃▅▁█▁▁▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>18</td></tr><tr><td>best_val_loss</td><td>0.72809</td></tr><tr><td>epoch</td><td>93</td></tr><tr><td>loss</td><td>102.33865</td></tr><tr><td>val_loss</td><td>11.95208</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">fast-sweep-41</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/po6qqkv0\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/po6qqkv0</a><br/>Synced 6 W&B file(s), 1 media file(s), 9 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_071932-po6qqkv0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ri8bz0rm with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.15468454318581695\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 36\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.04808049264444447\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 157\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 163\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 72\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 204\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 209\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_072502-ri8bz0rm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/ri8bz0rm\" target=\"_blank\">hardy-sweep-42</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/36\n",
      "1137/1146 [============================>.] - ETA: 0s - loss: 1243.7968INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_072502-ri8bz0rm/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_072502-ri8bz0rm/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 3ms/step - loss: 1235.0776 - val_loss: 2.5432\n",
      "Epoch 2/36\n",
      "1138/1146 [============================>.] - ETA: 0s - loss: 1.5962INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_072502-ri8bz0rm/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_072502-ri8bz0rm/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 3ms/step - loss: 1.5949 - val_loss: 1.0221\n",
      "Epoch 3/36\n",
      "1119/1146 [============================>.] - ETA: 0s - loss: 1.2355INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_072502-ri8bz0rm/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_072502-ri8bz0rm/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 2ms/step - loss: 1.2283 - val_loss: 0.8849\n",
      "Epoch 4/36\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.9679 - val_loss: 1.0127\n",
      "Epoch 5/36\n",
      "1143/1146 [============================>.] - ETA: 0s - loss: 0.9078INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_072502-ri8bz0rm/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_072502-ri8bz0rm/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.9074 - val_loss: 0.8370\n",
      "Epoch 6/36\n",
      "1127/1146 [============================>.] - ETA: 0s - loss: 0.8467INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_072502-ri8bz0rm/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_072502-ri8bz0rm/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.8454 - val_loss: 0.7886\n",
      "Epoch 7/36\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 24130572.0000 - val_loss: 118771.5781\n",
      "Epoch 8/36\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 80824.5547 - val_loss: 31044.3809\n",
      "Epoch 9/36\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 36865.9688 - val_loss: 19098.2344\n",
      "Epoch 10/36\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 18007.1445 - val_loss: 29673.5703\n",
      "Epoch 11/36\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 7295.9321 - val_loss: 4681.9194\n",
      "Epoch 12/36\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 4495.2568 - val_loss: 4268.2725\n",
      "Epoch 13/36\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2606.7563 - val_loss: 1600.1250\n",
      "Epoch 14/36\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 24915296.0000 - val_loss: 2566376448.0000\n",
      "Epoch 15/36\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 32344624.0000 - val_loss: 150895.6250\n",
      "Epoch 16/36\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 137518.3125 - val_loss: 167850.1094\n",
      "Epoch 17/36\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 80392.4922 - val_loss: 34416.0234\n",
      "Epoch 18/36\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 42679.4062 - val_loss: 21211.7285\n",
      "Epoch 19/36\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 25136.1484 - val_loss: 14110.9551\n",
      "Epoch 20/36\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 34140608.0000 - val_loss: 294043.5000\n",
      "Epoch 21/36\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 202815.3594 - val_loss: 136088.3438\n",
      "Epoch 22/36\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 85518.0312 - val_loss: 54237.8867\n",
      "Epoch 23/36\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 52079.4141 - val_loss: 39340.9375\n",
      "Epoch 24/36\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 31251.6855 - val_loss: 25810.3945\n",
      "Epoch 25/36\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 20699.5371 - val_loss: 109485.3906\n",
      "Epoch 26/36\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 58053060.0000 - val_loss: 1515450.0000\n",
      "Epoch 27/36\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 284065.1562 - val_loss: 367279.3750\n",
      "Epoch 28/36\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 147070.6250 - val_loss: 199198.9688\n",
      "Epoch 29/36\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 80970.7422 - val_loss: 91487.8828\n",
      "Epoch 30/36\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 43806.8750 - val_loss: 19683.9082\n",
      "Epoch 31/36\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 47035232.0000 - val_loss: 483118.3438\n",
      "Epoch 32/36\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 343426.2812 - val_loss: 502342.6875\n",
      "Epoch 33/36\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 140917.9219 - val_loss: 147899.6562\n",
      "Epoch 34/36\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 81882.3281 - val_loss: 118359.5156\n",
      "Epoch 35/36\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 42918.9219 - val_loss: 33549.2500\n",
      "Epoch 36/36\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 26175.0547 - val_loss: 15610.4209\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba56efe239dd494f99fd279663672399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='8.130 MB of 8.130 MB uploaded (0.016 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▁▁▁▁▄▁▁▁▁▁▁▄▅▁▁▁▁▅▁▁▁▁▁█▁▁▁▁▇▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>5</td></tr><tr><td>best_val_loss</td><td>0.78861</td></tr><tr><td>epoch</td><td>35</td></tr><tr><td>loss</td><td>26175.05469</td></tr><tr><td>val_loss</td><td>15610.4209</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">hardy-sweep-42</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/ri8bz0rm\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/ri8bz0rm</a><br/>Synced 6 W&B file(s), 1 media file(s), 21 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_072502-ri8bz0rm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dubw1zcj with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.21657287569923547\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.05380103656005223\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 187\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 181\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 249\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 249\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_072639-dubw1zcj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/dubw1zcj\" target=\"_blank\">prime-sweep-43</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1136/1146 [============================>.] - ETA: 0s - loss: 203.5909INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_072639-dubw1zcj/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_072639-dubw1zcj/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 5s 4ms/step - loss: 201.9883 - val_loss: 1.1101\n",
      "Epoch 2/50\n",
      "1133/1146 [============================>.] - ETA: 0s - loss: 0.8874INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_072639-dubw1zcj/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_072639-dubw1zcj/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.8870 - val_loss: 0.8158\n",
      "Epoch 3/50\n",
      "1121/1146 [============================>.] - ETA: 0s - loss: 0.8084INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_072639-dubw1zcj/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_072639-dubw1zcj/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.8066 - val_loss: 0.7857\n",
      "Epoch 4/50\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.7837 - val_loss: 0.7905\n",
      "Epoch 5/50\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.7674 - val_loss: 1.4734\n",
      "Epoch 6/50\n",
      "1132/1146 [============================>.] - ETA: 0s - loss: 0.7716INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_072639-dubw1zcj/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_072639-dubw1zcj/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.7711 - val_loss: 0.7399\n",
      "Epoch 7/50\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.7720 - val_loss: 0.8225\n",
      "Epoch 8/50\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 36115048.0000 - val_loss: 313696.0625\n",
      "Epoch 9/50\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 101449.3750 - val_loss: 56757.2539\n",
      "Epoch 10/50\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 30207.5039 - val_loss: 41842.3047\n",
      "Epoch 11/50\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 16502.0703 - val_loss: 10311.2744\n",
      "Epoch 12/50\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 7900.2173 - val_loss: 4744.5200\n",
      "Epoch 13/50\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 5218.0156 - val_loss: 2249.5828\n",
      "Epoch 14/50\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 3317.6658 - val_loss: 2626.4146\n",
      "Epoch 15/50\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 123940568.0000 - val_loss: 724521.7500\n",
      "Epoch 16/50\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 357784.7500 - val_loss: 142849.3281\n",
      "Epoch 17/50\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 166445.2656 - val_loss: 99192.1016\n",
      "Epoch 18/50\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 73143.2500 - val_loss: 58407.4922\n",
      "Epoch 19/50\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 51822.4453 - val_loss: 36452.9375\n",
      "Epoch 20/50\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 137813104.0000 - val_loss: 686520.2500\n",
      "Epoch 21/50\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 510132.3125 - val_loss: 496412.6875\n",
      "Epoch 22/50\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 283528.2500 - val_loss: 135526.2344\n",
      "Epoch 23/50\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 165629.7344 - val_loss: 88632.2891\n",
      "Epoch 24/50\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 86414.6250 - val_loss: 90685.0469\n",
      "Epoch 25/50\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 50766.2344 - val_loss: 61258.7539\n",
      "Epoch 26/50\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 28161.7441 - val_loss: 12697.2061\n",
      "Epoch 27/50\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 164892240.0000 - val_loss: 1519582.7500\n",
      "Epoch 28/50\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 831795.6875 - val_loss: 306281.1250\n",
      "Epoch 29/50\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 412554.0312 - val_loss: 167038.6719\n",
      "Epoch 30/50\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 242535.9844 - val_loss: 194084.7188\n",
      "Epoch 31/50\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 191548.6562 - val_loss: 70058.5469\n",
      "Epoch 32/50\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 223515456.0000 - val_loss: 1636264.7500\n",
      "Epoch 33/50\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 1457309.6250 - val_loss: 687810.1250\n",
      "Epoch 34/50\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 705279.2500 - val_loss: 1672026.7500\n",
      "Epoch 35/50\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 412577.9688 - val_loss: 175936.6406\n",
      "Epoch 36/50\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 178211.3594 - val_loss: 71778.2734\n",
      "Epoch 37/50\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 126506.1953 - val_loss: 157689.1719\n",
      "Epoch 38/50\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 77539.6875 - val_loss: 112646.8047\n",
      "Epoch 39/50\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 289332064.0000 - val_loss: 1485234.0000\n",
      "Epoch 40/50\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 1666782.6250 - val_loss: 2906582.5000\n",
      "Epoch 41/50\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 715739.0000 - val_loss: 436723.8750\n",
      "Epoch 42/50\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 444208.7500 - val_loss: 418469.8125\n",
      "Epoch 43/50\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 262260.2500 - val_loss: 240207.2344\n",
      "Epoch 44/50\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 168092.6875 - val_loss: 79672.0078\n",
      "Epoch 45/50\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 99531.5938 - val_loss: 53098.8516\n",
      "Epoch 46/50\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 142431568.0000 - val_loss: 842599.9375\n",
      "Epoch 47/50\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 804912.4375 - val_loss: 821550.1250\n",
      "Epoch 48/50\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 422853.5000 - val_loss: 352084.6250\n",
      "Epoch 49/50\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 260619.1406 - val_loss: 124748.8672\n",
      "Epoch 50/50\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 179649.9219 - val_loss: 69296.0625\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▁▁▁▆▁▁▁▁▁█▁▁▁▁▄▁▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▂▁▁▁▁▁▂▁▁▁▃▂▁▁▁▇▂▂▁█▄█▁▂▁▇▃▃▂▁▅▄▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>5</td></tr><tr><td>best_val_loss</td><td>0.73987</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>loss</td><td>179649.92188</td></tr><tr><td>val_loss</td><td>69296.0625</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">prime-sweep-43</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/dubw1zcj\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/dubw1zcj</a><br/>Synced 6 W&B file(s), 1 media file(s), 17 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_072639-dubw1zcj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 863gs2yc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.005047924782384361\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 33\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.06590238019461697\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 226\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 181\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 191\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 197\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 88\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_072913-863gs2yc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/863gs2yc\" target=\"_blank\">fluent-sweep-44</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/33\n",
      "2269/2291 [============================>.] - ETA: 0s - loss: 1873.1046INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_072913-863gs2yc/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_072913-863gs2yc/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 5s 2ms/step - loss: 1855.8516 - val_loss: 1.4371\n",
      "Epoch 2/33\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 130570952.0000 - val_loss: 868692.3125\n",
      "Epoch 3/33\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 481642.2812 - val_loss: 167864.7344\n",
      "Epoch 4/33\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 221581824.0000 - val_loss: 8573564.0000\n",
      "Epoch 5/33\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1949901.3750 - val_loss: 974424.8125\n",
      "Epoch 6/33\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 651728.4375 - val_loss: 153876.9531\n",
      "Epoch 7/33\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 207348928.0000 - val_loss: 4630477.5000\n",
      "Epoch 8/33\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 1949946.1250 - val_loss: 998686.2500\n",
      "Epoch 9/33\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 444454.5312 - val_loss: 522557.5312\n",
      "Epoch 10/33\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 130446856.0000 - val_loss: 5337995776.0000\n",
      "Epoch 11/33\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 37074240.0000 - val_loss: 467103.3750\n",
      "Epoch 12/33\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 484465.8125 - val_loss: 256054.0156\n",
      "Epoch 13/33\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 137170208.0000 - val_loss: 2721473.7500\n",
      "Epoch 14/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 655896.0625 - val_loss: 453488.7812\n",
      "Epoch 15/33\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 234989.5938 - val_loss: 102490.2734\n",
      "Epoch 16/33\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 103631280.0000 - val_loss: 1088325.3750\n",
      "Epoch 17/33\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 697468.0625 - val_loss: 1767154.7500\n",
      "Epoch 18/33\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 195574.1562 - val_loss: 90280.1875\n",
      "Epoch 19/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 520870880.0000 - val_loss: 3883964.5000\n",
      "Epoch 20/33\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 2450329.7500 - val_loss: 794009.3750\n",
      "Epoch 21/33\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 761969.8750 - val_loss: 481413.6250\n",
      "Epoch 22/33\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 151505232.0000 - val_loss: 3849999.0000\n",
      "Epoch 23/33\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1255623.3750 - val_loss: 409095.0000\n",
      "Epoch 24/33\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 434255.1875 - val_loss: 666837.0000\n",
      "Epoch 25/33\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 126829056.0000 - val_loss: 3921884.7500\n",
      "Epoch 26/33\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 1445958.6250 - val_loss: 567490.8125\n",
      "Epoch 27/33\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 385269.0625 - val_loss: 424655.1562\n",
      "Epoch 28/33\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 676811584.0000 - val_loss: 2549602.0000\n",
      "Epoch 29/33\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 2343704.7500 - val_loss: 2596099.5000\n",
      "Epoch 30/33\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 2081888.2500 - val_loss: 357307.9375\n",
      "Epoch 31/33\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 280183168.0000 - val_loss: 7440457.5000\n",
      "Epoch 32/33\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 3310055.5000 - val_loss: 1485580.3750\n",
      "Epoch 33/33\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 972525.0625 - val_loss: 457959.7812\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▂▁▃▁▁▃▁▁▂▁▁▂▁▁▂▁▁▆▁▁▃▁▁▂▁▁█▁▁▄▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>1.43706</td></tr><tr><td>epoch</td><td>32</td></tr><tr><td>loss</td><td>972525.0625</td></tr><tr><td>val_loss</td><td>457959.78125</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">fluent-sweep-44</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/863gs2yc\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/863gs2yc</a><br/>Synced 6 W&B file(s), 1 media file(s), 5 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_072913-863gs2yc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: b7915zqm with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5027489451979701\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 70\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.016128828543729812\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 249\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 87\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 244\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 163\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 230\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_073122-b7915zqm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/b7915zqm\" target=\"_blank\">worldly-sweep-45</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1126/1146 [============================>.] - ETA: 0s - loss: 1.1753INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_073122-b7915zqm/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_073122-b7915zqm/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 4s 3ms/step - loss: 1.1700 - val_loss: 1.0126\n",
      "Epoch 2/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.8404 - val_loss: 1.0481\n",
      "Epoch 3/70\n",
      "1124/1146 [============================>.] - ETA: 0s - loss: 0.8625INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_073122-b7915zqm/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_073122-b7915zqm/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.8621 - val_loss: 0.8899\n",
      "Epoch 4/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 4876.0596 - val_loss: 29960.9082\n",
      "Epoch 5/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 395.4587 - val_loss: 19.4647\n",
      "Epoch 6/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 13.5965 - val_loss: 11.1900\n",
      "Epoch 7/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 7.6488 - val_loss: 7.7357\n",
      "Epoch 8/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 5.6805 - val_loss: 27.9751\n",
      "Epoch 9/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 3.1637 - val_loss: 2.2658\n",
      "Epoch 10/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 42810.6836 - val_loss: 585.2111\n",
      "Epoch 11/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 284.6942 - val_loss: 225.7440\n",
      "Epoch 12/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 109.4679 - val_loss: 69.7190\n",
      "Epoch 13/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 64.3358 - val_loss: 62.7289\n",
      "Epoch 14/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 38.5371 - val_loss: 28.3027\n",
      "Epoch 15/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 22.9110 - val_loss: 10.2048\n",
      "Epoch 16/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 15.3342 - val_loss: 9.7783\n",
      "Epoch 17/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 10.3813 - val_loss: 5.2478\n",
      "Epoch 18/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 6.8605 - val_loss: 5.1125\n",
      "Epoch 19/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 3.7675 - val_loss: 4.1341\n",
      "Epoch 20/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 44056.6758 - val_loss: 285.5797\n",
      "Epoch 21/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 155.9810 - val_loss: 121.7629\n",
      "Epoch 22/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 83.2063 - val_loss: 71.2307\n",
      "Epoch 23/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 51.1095 - val_loss: 28.1274\n",
      "Epoch 24/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 35979.0781 - val_loss: 511.8896\n",
      "Epoch 25/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 232.8454 - val_loss: 121.3200\n",
      "Epoch 26/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 96.6779 - val_loss: 84.0161\n",
      "Epoch 27/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 58.0028 - val_loss: 45.3446\n",
      "Epoch 28/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 36.5809 - val_loss: 33.6585\n",
      "Epoch 29/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 24.7028 - val_loss: 16.9817\n",
      "Epoch 30/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 20.9814 - val_loss: 11.8848\n",
      "Epoch 31/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 51867.2344 - val_loss: 528.7802\n",
      "Epoch 32/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 361.8805 - val_loss: 540.8135\n",
      "Epoch 33/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 186.0153 - val_loss: 80.0232\n",
      "Epoch 34/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 103.2792 - val_loss: 53.4955\n",
      "Epoch 35/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 61.4156 - val_loss: 46.0793\n",
      "Epoch 36/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 42226.6562 - val_loss: 3153.0439\n",
      "Epoch 37/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 583.2203 - val_loss: 136.3707\n",
      "Epoch 38/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 169.0344 - val_loss: 120.5824\n",
      "Epoch 39/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 99.1690 - val_loss: 46.1837\n",
      "Epoch 40/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 53.8189 - val_loss: 32.5887\n",
      "Epoch 41/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 35.2575 - val_loss: 19.8729\n",
      "Epoch 42/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 22.4280 - val_loss: 9.9899\n",
      "Epoch 43/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 14.8808 - val_loss: 13.7722\n",
      "Epoch 44/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 10.0269 - val_loss: 3.8368\n",
      "Epoch 45/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 95239.3828 - val_loss: 1610.6791\n",
      "Epoch 46/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 591.9767 - val_loss: 404.7715\n",
      "Epoch 47/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 274.2273 - val_loss: 138.0778\n",
      "Epoch 48/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 150.0386 - val_loss: 128.3716\n",
      "Epoch 49/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 88.1872 - val_loss: 45.7035\n",
      "Epoch 50/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 51.3679 - val_loss: 34.7044\n",
      "Epoch 51/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 31.4163 - val_loss: 37.9003\n",
      "Epoch 52/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 50749.1289 - val_loss: 322.1187\n",
      "Epoch 53/70\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 178.5648 - val_loss: 148.0189\n",
      "Epoch 54/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 108.2656 - val_loss: 70.0825\n",
      "Epoch 55/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 69.2883 - val_loss: 40.5656\n",
      "Epoch 56/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 42.5275 - val_loss: 14.7960\n",
      "Epoch 57/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 23.2346 - val_loss: 12.6809\n",
      "Epoch 58/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 22.0472 - val_loss: 8.6995\n",
      "Epoch 59/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 7.2408 - val_loss: 6.0177\n",
      "Epoch 60/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 181822.7344 - val_loss: 4836.5269\n",
      "Epoch 61/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 972.0049 - val_loss: 289.3730\n",
      "Epoch 62/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 418.3379 - val_loss: 274.7964\n",
      "Epoch 63/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 281.9573 - val_loss: 147.4233\n",
      "Epoch 64/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 168.0747 - val_loss: 121.4613\n",
      "Epoch 65/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 100.9235 - val_loss: 83.9666\n",
      "Epoch 66/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 61.3461 - val_loss: 37.7043\n",
      "Epoch 67/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 39.8286 - val_loss: 26.3808\n",
      "Epoch 68/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 33586.6328 - val_loss: 829.1250\n",
      "Epoch 69/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 327.6820 - val_loss: 265.1938\n",
      "Epoch 70/70\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 137.7933 - val_loss: 83.3401\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▄▁▄▁▁▁▅▁▁▄▁▁▁▁█▁▁▁▅▁▁▁▁▁▁▁▁▃▁</td></tr><tr><td>val_loss</td><td>▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>2</td></tr><tr><td>best_val_loss</td><td>0.88986</td></tr><tr><td>epoch</td><td>69</td></tr><tr><td>loss</td><td>137.79326</td></tr><tr><td>val_loss</td><td>83.34009</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">worldly-sweep-45</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/b7915zqm\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/b7915zqm</a><br/>Synced 6 W&B file(s), 1 media file(s), 9 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_073122-b7915zqm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pefcv3iz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.25040541903851843\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 36\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.08150913692808802\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 147\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 211\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 135\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 254\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_073431-pefcv3iz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/pefcv3iz\" target=\"_blank\">kind-sweep-46</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/36\n",
      "1495/1527 [============================>.] - ETA: 0s - loss: 2570.8088INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_073431-pefcv3iz/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_073431-pefcv3iz/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 4s 2ms/step - loss: 2517.4233 - val_loss: 2.7391\n",
      "Epoch 2/36\n",
      "1524/1527 [============================>.] - ETA: 0s - loss: 1.8931INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_073431-pefcv3iz/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_073431-pefcv3iz/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1.8922 - val_loss: 1.1551\n",
      "Epoch 3/36\n",
      "1495/1527 [============================>.] - ETA: 0s - loss: 1.2345INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_073431-pefcv3iz/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_073431-pefcv3iz/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 4s 2ms/step - loss: 1.2291 - val_loss: 0.9414\n",
      "Epoch 4/36\n",
      "1523/1527 [============================>.] - ETA: 0s - loss: 0.9986INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_073431-pefcv3iz/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_073431-pefcv3iz/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.9990 - val_loss: 0.8776\n",
      "Epoch 5/36\n",
      "1520/1527 [============================>.] - ETA: 0s - loss: 0.9088INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_073431-pefcv3iz/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_073431-pefcv3iz/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.9081 - val_loss: 0.8092\n",
      "Epoch 6/36\n",
      "1513/1527 [============================>.] - ETA: 0s - loss: 0.8334INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_073431-pefcv3iz/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_073431-pefcv3iz/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.8335 - val_loss: 0.7819\n",
      "Epoch 7/36\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 2135133696.0000 - val_loss: 22814216.0000\n",
      "Epoch 8/36\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 9238774.0000 - val_loss: 2794141.5000\n",
      "Epoch 9/36\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1789697.7500 - val_loss: 706614.8750\n",
      "Epoch 10/36\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 874573.0625 - val_loss: 540280.1875\n",
      "Epoch 11/36\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 493826.5625 - val_loss: 347116.7812\n",
      "Epoch 12/36\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 998750592.0000 - val_loss: 3026090.5000\n",
      "Epoch 13/36\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 3254361.0000 - val_loss: 1802895.7500\n",
      "Epoch 14/36\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1301240.5000 - val_loss: 555774.3750\n",
      "Epoch 15/36\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 573194.0000 - val_loss: 499578.4688\n",
      "Epoch 16/36\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 647842816.0000 - val_loss: 5357699.5000\n",
      "Epoch 17/36\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 3246533.2500 - val_loss: 794288.1875\n",
      "Epoch 18/36\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1482883.5000 - val_loss: 523153.3750\n",
      "Epoch 19/36\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 683708.0625 - val_loss: 443929.0000\n",
      "Epoch 20/36\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 541662.8125 - val_loss: 302142.5000\n",
      "Epoch 21/36\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 123958.0156 - val_loss: 50206.6445\n",
      "Epoch 22/36\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1634882560.0000 - val_loss: 5430964.0000\n",
      "Epoch 23/36\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 5847827.5000 - val_loss: 2465854.0000\n",
      "Epoch 24/36\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 2887782.7500 - val_loss: 1424520.5000\n",
      "Epoch 25/36\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1678939.1250 - val_loss: 816802.1250\n",
      "Epoch 26/36\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 996462464.0000 - val_loss: 15527112.0000\n",
      "Epoch 27/36\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 7926200.5000 - val_loss: 2464663.2500\n",
      "Epoch 28/36\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 2924424.0000 - val_loss: 1111900.1250\n",
      "Epoch 29/36\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1314850.6250 - val_loss: 2860673.7500\n",
      "Epoch 30/36\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1575886336.0000 - val_loss: 23354978.0000\n",
      "Epoch 31/36\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 13872766.0000 - val_loss: 5264925.5000\n",
      "Epoch 32/36\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 4637788.5000 - val_loss: 2205846.5000\n",
      "Epoch 33/36\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 2433680.7500 - val_loss: 819671.0625\n",
      "Epoch 34/36\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1257053.5000 - val_loss: 786901.6250\n",
      "Epoch 35/36\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 535414.8750 - val_loss: 216972.5625\n",
      "Epoch 36/36\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 536716960.0000 - val_loss: 14247568.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6853ff22832479baa5282def7e343f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='9.726 MB of 9.726 MB uploaded (0.016 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▁▁▁▁█▁▁▁▁▄▁▁▁▃▁▁▁▁▁▆▁▁▁▄▁▁▁▆▁▁▁▁▁▃</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁█▂▁▁▁▂▂▁▁▃▁▁▁▁▁▃▂▁▁▆▂▁▂█▃▂▁▁▁▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>5</td></tr><tr><td>best_val_loss</td><td>0.78191</td></tr><tr><td>epoch</td><td>35</td></tr><tr><td>loss</td><td>536716960.0</td></tr><tr><td>val_loss</td><td>14247568.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">kind-sweep-46</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/pefcv3iz\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/pefcv3iz</a><br/>Synced 6 W&B file(s), 1 media file(s), 25 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_073431-pefcv3iz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vp4z0o9b with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5275721039103399\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 87\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0601393446643601\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 101\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 197\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 164\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 137\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 242\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_073629-vp4z0o9b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/vp4z0o9b\" target=\"_blank\">silver-sweep-47</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/87\n",
      "4546/4581 [============================>.] - ETA: 0s - loss: 145.5561INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_073629-vp4z0o9b/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_073629-vp4z0o9b/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4581/4581 [==============================] - 7s 1ms/step - loss: 144.4752 - val_loss: 0.8289\n",
      "Epoch 2/87\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.9215 - val_loss: 0.9141\n",
      "Epoch 3/87\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 7956762.0000 - val_loss: 15149.7881\n",
      "Epoch 4/87\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 18100342.0000 - val_loss: 67418.1719\n",
      "Epoch 5/87\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 49876.4844 - val_loss: 8233.8271\n",
      "Epoch 6/87\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 16335799.0000 - val_loss: 46541.9297\n",
      "Epoch 7/87\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 48506268.0000 - val_loss: 3741423.2500\n",
      "Epoch 8/87\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 972538.8125 - val_loss: 156914.9219\n",
      "Epoch 9/87\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 34125632.0000 - val_loss: 904368.5625\n",
      "Epoch 10/87\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 19706868.0000 - val_loss: 404254.4062\n",
      "Epoch 11/87\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 24394418.0000 - val_loss: 616318.6875\n",
      "Epoch 12/87\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 315919.5312 - val_loss: 40161.7188\n",
      "Epoch 13/87\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 57786.5312 - val_loss: 4330.2358\n",
      "Epoch 14/87\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 16775898.0000 - val_loss: 79620.5312\n",
      "Epoch 15/87\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 57055.8359 - val_loss: 23951.6094\n",
      "Epoch 16/87\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 25302412.0000 - val_loss: 127223.2109\n",
      "Epoch 17/87\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 39302064.0000 - val_loss: 383790.7812\n",
      "Epoch 18/87\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 358064.0938 - val_loss: 76235.4141\n",
      "Epoch 19/87\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 53457416.0000 - val_loss: 1239457.5000\n",
      "Epoch 20/87\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 742385.8125 - val_loss: 120041.2969\n",
      "Epoch 21/87\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 105955.0156 - val_loss: 17238.3633\n",
      "Epoch 22/87\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 43767796.0000 - val_loss: 114095.1719\n",
      "Epoch 23/87\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 16633494.0000 - val_loss: 303923.2500\n",
      "Epoch 24/87\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 180236.2188 - val_loss: 30306.6211\n",
      "Epoch 25/87\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 44681124.0000 - val_loss: 220130.4688\n",
      "Epoch 26/87\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 150599.5000 - val_loss: 37600.9336\n",
      "Epoch 27/87\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 24554204.0000 - val_loss: 97089.9297\n",
      "Epoch 28/87\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 21321000.0000 - val_loss: 970248.8750\n",
      "Epoch 29/87\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 402369.5312 - val_loss: 92381.9766\n",
      "Epoch 30/87\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 13731885.0000 - val_loss: 101412.4453\n",
      "Epoch 31/87\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 56746524.0000 - val_loss: 1988730.3750\n",
      "Epoch 32/87\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 861664.8750 - val_loss: 249441.6094\n",
      "Epoch 33/87\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 17657640.0000 - val_loss: 505584.6562\n",
      "Epoch 34/87\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 286546.6250 - val_loss: 55847.3672\n",
      "Epoch 35/87\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 32622596.0000 - val_loss: 932104.6250\n",
      "Epoch 36/87\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 316802.6250 - val_loss: 62007.6758\n",
      "Epoch 37/87\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 133643072.0000 - val_loss: 1000745.9375\n",
      "Epoch 38/87\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 747365.0625 - val_loss: 127821.5781\n",
      "Epoch 39/87\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 70600536.0000 - val_loss: 457291.6875\n",
      "Epoch 40/87\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 250195.6562 - val_loss: 84628.3984\n",
      "Epoch 41/87\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 55625876.0000 - val_loss: 312329.9688\n",
      "Epoch 42/87\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 221899.3125 - val_loss: 40545.8125\n",
      "Epoch 43/87\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 24671756.0000 - val_loss: 149780.8750\n",
      "Epoch 44/87\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 131653.4688 - val_loss: 50653.2344\n",
      "Epoch 45/87\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 21890654.0000 - val_loss: 366606.9062\n",
      "Epoch 46/87\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 220797.7656 - val_loss: 56973.1562\n",
      "Epoch 47/87\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 40640620.0000 - val_loss: 991653.6250\n",
      "Epoch 48/87\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 388452.0312 - val_loss: 101088.8516\n",
      "Epoch 49/87\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 24432142.0000 - val_loss: 217725.2812\n",
      "Epoch 50/87\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 31159038.0000 - val_loss: 697654.7500\n",
      "Epoch 51/87\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 370168.8750 - val_loss: 90484.6641\n",
      "Epoch 52/87\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 17898288.0000 - val_loss: 138036.6719\n",
      "Epoch 53/87\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 29702670.0000 - val_loss: 833015.5000\n",
      "Epoch 54/87\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 457083.8750 - val_loss: 89644.8984\n",
      "Epoch 55/87\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 23781932.0000 - val_loss: 299264.0625\n",
      "Epoch 56/87\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 252493.5469 - val_loss: 44903.5508\n",
      "Epoch 57/87\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 59988596.0000 - val_loss: 807911.0000\n",
      "Epoch 58/87\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 518761.9688 - val_loss: 243723.4531\n",
      "Epoch 59/87\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 31030808.0000 - val_loss: 461447.2188\n",
      "Epoch 60/87\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 313079.9688 - val_loss: 58935.4648\n",
      "Epoch 61/87\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 18608434.0000 - val_loss: 399756.4375\n",
      "Epoch 62/87\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 284815.6875 - val_loss: 54223.6992\n",
      "Epoch 63/87\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 40887548.0000 - val_loss: 735559.5000\n",
      "Epoch 64/87\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 392385.8125 - val_loss: 87944.7266\n",
      "Epoch 65/87\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 90598.8906 - val_loss: 22734.4922\n",
      "Epoch 66/87\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 29112136.0000 - val_loss: 144469.7812\n",
      "Epoch 67/87\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 160309.8281 - val_loss: 188735.7500\n",
      "Epoch 68/87\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 32598270.0000 - val_loss: 204417.0938\n",
      "Epoch 69/87\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 137034.5312 - val_loss: 37469.8672\n",
      "Epoch 70/87\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 74157400.0000 - val_loss: 353451.7188\n",
      "Epoch 71/87\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 53815752.0000 - val_loss: 567892.1250\n",
      "Epoch 72/87\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 523635.3438 - val_loss: 101326.9219\n",
      "Epoch 73/87\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 26825850.0000 - val_loss: 654664.4375\n",
      "Epoch 74/87\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 245005.2500 - val_loss: 48379.5703\n",
      "Epoch 75/87\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 64710604.0000 - val_loss: 471463.6562\n",
      "Epoch 76/87\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 282977.1562 - val_loss: 73410.5156\n",
      "Epoch 77/87\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 36867228.0000 - val_loss: 237542.7031\n",
      "Epoch 78/87\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 22021706.0000 - val_loss: 410912.5625\n",
      "Epoch 79/87\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 264029.9688 - val_loss: 27785.1113\n",
      "Epoch 80/87\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 12503810.0000 - val_loss: 263240.4375\n",
      "Epoch 81/87\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 150033.8906 - val_loss: 75174.3047\n",
      "Epoch 82/87\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 95748568.0000 - val_loss: 2279945.5000\n",
      "Epoch 83/87\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 888029.4375 - val_loss: 81663.5156\n",
      "Epoch 84/87\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 34136504.0000 - val_loss: 539756.2500\n",
      "Epoch 85/87\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 380520.3438 - val_loss: 94124.4609\n",
      "Epoch 86/87\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 18081962.0000 - val_loss: 203953.8125\n",
      "Epoch 87/87\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 16960394.0000 - val_loss: 509241.1562\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▂▁▅▃▁▂▃▁▁▂▄▃▁▅▁▁▁▁▁▃▄▃▁▃▁▁▁▁▁▁▁▅▃▆▃▂█▃▂</td></tr><tr><td>val_loss</td><td>▁▁▁█▃▁▁▁▁▁▂▁▁▁▅▁▁▁▁▁▂▃▁▁▃▁▁▁▁▁▁▁▂▂▂▂▁▅▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.82888</td></tr><tr><td>epoch</td><td>86</td></tr><tr><td>loss</td><td>16960394.0</td></tr><tr><td>val_loss</td><td>509241.15625</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">silver-sweep-47</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/vp4z0o9b\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/vp4z0o9b</a><br/>Synced 6 W&B file(s), 1 media file(s), 5 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_073629-vp4z0o9b/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cxbhdb2v with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.042092677552453515\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 52\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.017078192895493605\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 153\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 207\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 69\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 77\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 242\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_074457-cxbhdb2v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/cxbhdb2v\" target=\"_blank\">devout-sweep-48</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/52\n",
      "1523/1527 [============================>.] - ETA: 0s - loss: 0.9883INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_074457-cxbhdb2v/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_074457-cxbhdb2v/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 4s 2ms/step - loss: 0.9881 - val_loss: 0.8508\n",
      "Epoch 2/52\n",
      "1504/1527 [============================>.] - ETA: 0s - loss: 0.8586INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_074457-cxbhdb2v/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_074457-cxbhdb2v/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.8578 - val_loss: 0.7770\n",
      "Epoch 3/52\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 3254.0649 - val_loss: 224.2671\n",
      "Epoch 4/52\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 25.7360 - val_loss: 8.1579\n",
      "Epoch 5/52\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 6.2946 - val_loss: 3.6165\n",
      "Epoch 6/52\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 3.4097 - val_loss: 1.7989\n",
      "Epoch 7/52\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 4726.7710 - val_loss: 62.3471\n",
      "Epoch 8/52\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 27.6143 - val_loss: 13.2593\n",
      "Epoch 9/52\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 8.9192 - val_loss: 4.9247\n",
      "Epoch 10/52\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 4.4606 - val_loss: 2.2092\n",
      "Epoch 11/52\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 2.4664 - val_loss: 1.5545\n",
      "Epoch 12/52\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 1.9028 - val_loss: 1.1081\n",
      "Epoch 13/52\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 5258.4097 - val_loss: 265.9977\n",
      "Epoch 14/52\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 71.0539 - val_loss: 49.5938\n",
      "Epoch 15/52\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 18.3341 - val_loss: 11.3265\n",
      "Epoch 16/52\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 11.5015 - val_loss: 4.9935\n",
      "Epoch 17/52\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 4.7949 - val_loss: 2.8589\n",
      "Epoch 18/52\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 7874.5620 - val_loss: 473.7422\n",
      "Epoch 19/52\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 98.8475 - val_loss: 34.2077\n",
      "Epoch 20/52\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 23.0145 - val_loss: 19.4459\n",
      "Epoch 21/52\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 11.9676 - val_loss: 7.9021\n",
      "Epoch 22/52\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 6.5827 - val_loss: 5.0031\n",
      "Epoch 23/52\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 5.8429 - val_loss: 3.0615\n",
      "Epoch 24/52\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 2743.6802 - val_loss: 18.3639\n",
      "Epoch 25/52\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 14.9234 - val_loss: 6.4321\n",
      "Epoch 26/52\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 6.5865 - val_loss: 5.1130\n",
      "Epoch 27/52\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 3.5693 - val_loss: 1.9950\n",
      "Epoch 28/52\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 2.0797 - val_loss: 1.3257\n",
      "Epoch 29/52\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 1.4275 - val_loss: 1.2091\n",
      "Epoch 30/52\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 4571.6802 - val_loss: 24.3250\n",
      "Epoch 31/52\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 17.4919 - val_loss: 13.6837\n",
      "Epoch 32/52\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 7.6359 - val_loss: 3.8169\n",
      "Epoch 33/52\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 4.2170 - val_loss: 2.4053\n",
      "Epoch 34/52\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 2.7739 - val_loss: 4.3017\n",
      "Epoch 35/52\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 5376.7734 - val_loss: 40.5005\n",
      "Epoch 36/52\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 38.2585 - val_loss: 17.7468\n",
      "Epoch 37/52\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 15.4385 - val_loss: 9.7390\n",
      "Epoch 38/52\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 8.5757 - val_loss: 4.3317\n",
      "Epoch 39/52\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 5.2637 - val_loss: 2.8139\n",
      "Epoch 40/52\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 3.5317 - val_loss: 2.1301\n",
      "Epoch 41/52\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 8028.6953 - val_loss: 86.5450\n",
      "Epoch 42/52\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 42.0378 - val_loss: 34.2746\n",
      "Epoch 43/52\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 19.0276 - val_loss: 15.8231\n",
      "Epoch 44/52\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 10.8986 - val_loss: 7.9328\n",
      "Epoch 45/52\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 7159.0684 - val_loss: 96.5321\n",
      "Epoch 46/52\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 52.3483 - val_loss: 25.3957\n",
      "Epoch 47/52\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 23.3851 - val_loss: 9.8869\n",
      "Epoch 48/52\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 11.7572 - val_loss: 7.0876\n",
      "Epoch 49/52\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 6282.0220 - val_loss: 65.7223\n",
      "Epoch 50/52\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 48.9541 - val_loss: 22.0064\n",
      "Epoch 51/52\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 22.9455 - val_loss: 18.7435\n",
      "Epoch 52/52\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 13.0188 - val_loss: 9.6533\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9d09eb4e36841e28bada0d6ba124e5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.179 MB of 3.179 MB uploaded (0.016 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▄▁▁▅▁▁▁▁▁▁▁█▁▁▁▁▃▁▁▁▁▁▁▁▆▁▁▁▁█▁▁▇▁▁▆▁▁</td></tr><tr><td>val_loss</td><td>▁▁▄▁▁▂▁▁▁▁▂▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▂▁▁▂▁▁▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>1</td></tr><tr><td>best_val_loss</td><td>0.77698</td></tr><tr><td>epoch</td><td>51</td></tr><tr><td>loss</td><td>13.01885</td></tr><tr><td>val_loss</td><td>9.65332</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">devout-sweep-48</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/cxbhdb2v\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/cxbhdb2v</a><br/>Synced 6 W&B file(s), 1 media file(s), 9 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_074457-cxbhdb2v/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2qih842u with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.540451085517444\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 38\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.056633043528705566\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 84\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 116\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 133\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 205\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 85\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_074713-2qih842u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/2qih842u\" target=\"_blank\">copper-sweep-49</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/38\n",
      "1121/1146 [============================>.] - ETA: 0s - loss: 37.7066INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_074713-2qih842u/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_074713-2qih842u/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 2ms/step - loss: 36.9345 - val_loss: 0.9247\n",
      "Epoch 2/38\n",
      "1123/1146 [============================>.] - ETA: 0s - loss: 0.8549INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_074713-2qih842u/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_074713-2qih842u/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.8546 - val_loss: 0.7668\n",
      "Epoch 3/38\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.8124 - val_loss: 0.7715\n",
      "Epoch 4/38\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.8030 - val_loss: 0.8959\n",
      "Epoch 5/38\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 4400584.5000 - val_loss: 21158.5762\n",
      "Epoch 6/38\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 14048.6045 - val_loss: 13383.3809\n",
      "Epoch 7/38\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 7194.7358 - val_loss: 4977.4985\n",
      "Epoch 8/38\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 3911.7246 - val_loss: 1640.4131\n",
      "Epoch 9/38\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1566.6045 - val_loss: 815.6794\n",
      "Epoch 10/38\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 953.0213 - val_loss: 882.0288\n",
      "Epoch 11/38\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 548.7964 - val_loss: 268.4384\n",
      "Epoch 12/38\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 6401933.0000 - val_loss: 24248.8887\n",
      "Epoch 13/38\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 20038.5820 - val_loss: 4744.4370\n",
      "Epoch 14/38\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8491.5928 - val_loss: 4959.5884\n",
      "Epoch 15/38\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 4759.2637 - val_loss: 3591.0225\n",
      "Epoch 16/38\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2955.4070 - val_loss: 1454.4557\n",
      "Epoch 17/38\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1577.1826 - val_loss: 868.7324\n",
      "Epoch 18/38\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 14335.4414 - val_loss: 15330137.0000\n",
      "Epoch 19/38\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8369114.5000 - val_loss: 29900.4043\n",
      "Epoch 20/38\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 28560.1445 - val_loss: 16940.9883\n",
      "Epoch 21/38\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 13870.1221 - val_loss: 7235.4443\n",
      "Epoch 22/38\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 7497.1538 - val_loss: 3708.9333\n",
      "Epoch 23/38\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 3993.7686 - val_loss: 3271.6201\n",
      "Epoch 24/38\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2152.9473 - val_loss: 2029.4760\n",
      "Epoch 25/38\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1249.2480 - val_loss: 658.9543\n",
      "Epoch 26/38\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 7675014.0000 - val_loss: 35061.6836\n",
      "Epoch 27/38\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 37979.1875 - val_loss: 34790.6055\n",
      "Epoch 28/38\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 17323.3984 - val_loss: 7458.2051\n",
      "Epoch 29/38\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 9688.5850 - val_loss: 3308.8555\n",
      "Epoch 30/38\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 5368.3555 - val_loss: 3226.3704\n",
      "Epoch 31/38\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2972.6094 - val_loss: 1247.2092\n",
      "Epoch 32/38\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1439.5813 - val_loss: 776.8663\n",
      "Epoch 33/38\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 853.4382 - val_loss: 416.8081\n",
      "Epoch 34/38\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 459.9392 - val_loss: 242.0554\n",
      "Epoch 35/38\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 4645875.0000 - val_loss: 132473.3906\n",
      "Epoch 36/38\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 55336.7070 - val_loss: 14668.1934\n",
      "Epoch 37/38\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 15739.5762 - val_loss: 5583.6431\n",
      "Epoch 38/38\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 7966.8525 - val_loss: 5578.8398\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▁▁▅▁▁▁▁▁▁▆▁▁▁▁▁▁█▁▁▁▁▁▁▇▁▁▁▁▁▁▁▁▅▁▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>1</td></tr><tr><td>best_val_loss</td><td>0.76685</td></tr><tr><td>epoch</td><td>37</td></tr><tr><td>loss</td><td>7966.85254</td></tr><tr><td>val_loss</td><td>5578.83984</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">copper-sweep-49</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/2qih842u\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/2qih842u</a><br/>Synced 6 W&B file(s), 1 media file(s), 9 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_074713-2qih842u/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bjh6notz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4608814547568595\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 48\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.06332434760719935\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 144\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 166\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 157\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 236\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 144\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_074840-bjh6notz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/bjh6notz\" target=\"_blank\">northern-sweep-50</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/48\n",
      "4540/4581 [============================>.] - ETA: 0s - loss: 108.8911INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_074840-bjh6notz/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_074840-bjh6notz/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4581/4581 [==============================] - 7s 1ms/step - loss: 107.9426 - val_loss: 0.8613\n",
      "Epoch 2/48\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 83471424.0000 - val_loss: 243532.9531\n",
      "Epoch 3/48\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 95927120.0000 - val_loss: 798486.0000\n",
      "Epoch 4/48\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 507261.0000 - val_loss: 32771.4062\n",
      "Epoch 5/48\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 100479576.0000 - val_loss: 959622.5625\n",
      "Epoch 6/48\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 731587.8750 - val_loss: 64221.9688\n",
      "Epoch 7/48\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 75419.0703 - val_loss: 12136.8262\n",
      "Epoch 8/48\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 44532420.0000 - val_loss: 124798.7188\n",
      "Epoch 9/48\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 30253690.0000 - val_loss: 213050.6094\n",
      "Epoch 10/48\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 149330.6094 - val_loss: 36117.8203\n",
      "Epoch 11/48\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 30797798.0000 - val_loss: 155470.8594\n",
      "Epoch 12/48\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 123492.1328 - val_loss: 10556.8291\n",
      "Epoch 13/48\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 34054820.0000 - val_loss: 293631.4375\n",
      "Epoch 14/48\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 173624.4219 - val_loss: 87813.0625\n",
      "Epoch 15/48\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 67951664.0000 - val_loss: 339294.9062\n",
      "Epoch 16/48\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 247982.0625 - val_loss: 238292.7188\n",
      "Epoch 17/48\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 60315644.0000 - val_loss: 682914.5000\n",
      "Epoch 18/48\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 255668.2969 - val_loss: 60642.6562\n",
      "Epoch 19/48\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 87747728.0000 - val_loss: 1354188.5000\n",
      "Epoch 20/48\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 512121.5938 - val_loss: 80499.3438\n",
      "Epoch 21/48\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 32246984.0000 - val_loss: 175207.5000\n",
      "Epoch 22/48\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 120983.9609 - val_loss: 22031.1270\n",
      "Epoch 23/48\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 60865032.0000 - val_loss: 190630.5625\n",
      "Epoch 24/48\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 168722.8281 - val_loss: 31163.6055\n",
      "Epoch 25/48\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 61297964.0000 - val_loss: 311532.8750\n",
      "Epoch 26/48\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 234066.7031 - val_loss: 46356.0898\n",
      "Epoch 27/48\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 47279088.0000 - val_loss: 475523.9062\n",
      "Epoch 28/48\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 298921.5312 - val_loss: 94408.8828\n",
      "Epoch 29/48\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 45398644.0000 - val_loss: 277902.4062\n",
      "Epoch 30/48\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 260628.8594 - val_loss: 64004.6602\n",
      "Epoch 31/48\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 144771840.0000 - val_loss: 616949.1250\n",
      "Epoch 32/48\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 655834.9375 - val_loss: 69492.9062\n",
      "Epoch 33/48\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 135032704.0000 - val_loss: 1862882.3750\n",
      "Epoch 34/48\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 875816.9375 - val_loss: 303766.5312\n",
      "Epoch 35/48\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 39979524.0000 - val_loss: 243342.8594\n",
      "Epoch 36/48\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 70820616.0000 - val_loss: 1222040.8750\n",
      "Epoch 37/48\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 682208.5625 - val_loss: 107522.2031\n",
      "Epoch 38/48\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 21722810.0000 - val_loss: 1406434.1250\n",
      "Epoch 39/48\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 377502.5000 - val_loss: 69458.8984\n",
      "Epoch 40/48\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 35933448.0000 - val_loss: 413303.9688\n",
      "Epoch 41/48\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 20847848.0000 - val_loss: 1681801.1250\n",
      "Epoch 42/48\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 509859.1875 - val_loss: 108663.4688\n",
      "Epoch 43/48\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 67219992.0000 - val_loss: 1173125.3750\n",
      "Epoch 44/48\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 590161.1875 - val_loss: 141019.3281\n",
      "Epoch 45/48\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 25101942.0000 - val_loss: 222213.3281\n",
      "Epoch 46/48\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 191858.7344 - val_loss: 40272.1719\n",
      "Epoch 47/48\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 22231378.0000 - val_loss: 379652.9062\n",
      "Epoch 48/48\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 174250.6719 - val_loss: 43174.1250\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5103e1cd2ded4a2c900d85fc789e371e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.210 MB of 3.238 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.991219…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▅▆▁▆▁▃▂▁▂▃▁▄▁▄▅▁▃▁▄▄▁▃▁▃█▁█▁▃▁▂▁▃▂▄▁▂▁▁</td></tr><tr><td>val_loss</td><td>▁▂▄▁▅▁▁▂▁▂▂▁▂▂▄▆▁▂▁▂▂▁▃▁▂▃▁█▂▂▁▆▁▃▇▅▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.86133</td></tr><tr><td>epoch</td><td>47</td></tr><tr><td>loss</td><td>174250.67188</td></tr><tr><td>val_loss</td><td>43174.125</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">northern-sweep-50</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/bjh6notz\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/bjh6notz</a><br/>Synced 6 W&B file(s), 1 media file(s), 5 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_074840-bjh6notz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: l531pxa9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4277076730587929\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 78\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.06256780491314584\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 140\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 129\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 79\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 94\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_075312-l531pxa9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/l531pxa9\" target=\"_blank\">faithful-sweep-51</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/78\n",
      "1518/1527 [============================>.] - ETA: 0s - loss: 94.6893INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_075312-l531pxa9/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_075312-l531pxa9/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 3s 2ms/step - loss: 94.1525 - val_loss: 0.7895\n",
      "Epoch 2/78\n",
      "1524/1527 [============================>.] - ETA: 0s - loss: 0.8506INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_075312-l531pxa9/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_075312-l531pxa9/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.8505 - val_loss: 0.7425\n",
      "Epoch 3/78\n",
      "1488/1527 [============================>.] - ETA: 0s - loss: 0.8012INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_075312-l531pxa9/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_075312-l531pxa9/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.8005 - val_loss: 0.7399\n",
      "Epoch 4/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 0.7997 - val_loss: 0.8409\n",
      "Epoch 5/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 0.8258 - val_loss: 0.7718\n",
      "Epoch 6/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 0.8460 - val_loss: 0.8119\n",
      "Epoch 7/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 15452046.0000 - val_loss: 35186.3359\n",
      "Epoch 8/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 23136.4668 - val_loss: 8623.4951\n",
      "Epoch 9/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 9938.9463 - val_loss: 4877.0913\n",
      "Epoch 10/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 5171.7046 - val_loss: 2551.7881\n",
      "Epoch 11/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 2907.4412 - val_loss: 1390.6184\n",
      "Epoch 12/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 10018397.0000 - val_loss: 25383.0820\n",
      "Epoch 13/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 16445.9258 - val_loss: 4517.3257\n",
      "Epoch 14/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 8040.4316 - val_loss: 2979.0376\n",
      "Epoch 15/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 3928.5115 - val_loss: 1468.3818\n",
      "Epoch 16/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 7770009.0000 - val_loss: 412903.2500\n",
      "Epoch 17/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 89974.6016 - val_loss: 21225.8145\n",
      "Epoch 18/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 23078.8770 - val_loss: 28855.9043\n",
      "Epoch 19/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 9674.7979 - val_loss: 3585.2178\n",
      "Epoch 20/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 4152.2725 - val_loss: 1376.9196\n",
      "Epoch 21/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 2056.5471 - val_loss: 1925.0194\n",
      "Epoch 22/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 5317952.5000 - val_loss: 58052.4375\n",
      "Epoch 23/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 30545.7930 - val_loss: 13250.0576\n",
      "Epoch 24/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 12565.1104 - val_loss: 7793.4541\n",
      "Epoch 25/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 6054.1499 - val_loss: 4158.9121\n",
      "Epoch 26/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 9893467.0000 - val_loss: 81324.5078\n",
      "Epoch 27/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 44492.8359 - val_loss: 21367.2305\n",
      "Epoch 28/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 18680.5996 - val_loss: 12645.3105\n",
      "Epoch 29/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 8954.0361 - val_loss: 5496.8672\n",
      "Epoch 30/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 4103.6167 - val_loss: 1396.7161\n",
      "Epoch 31/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 48940964.0000 - val_loss: 928766.8125\n",
      "Epoch 32/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 365654.4062 - val_loss: 133110.4219\n",
      "Epoch 33/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 116401.8359 - val_loss: 70103.9531\n",
      "Epoch 34/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 62132.5352 - val_loss: 22088.6328\n",
      "Epoch 35/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 32423.5176 - val_loss: 9632.5859\n",
      "Epoch 36/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 16620.8184 - val_loss: 7469.5347\n",
      "Epoch 37/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 14162057.0000 - val_loss: 87747.9141\n",
      "Epoch 38/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 71422.3672 - val_loss: 26482.6543\n",
      "Epoch 39/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 32889.1875 - val_loss: 15811.3379\n",
      "Epoch 40/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 15732.2158 - val_loss: 5884.5322\n",
      "Epoch 41/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 7053.5869 - val_loss: 2464.3252\n",
      "Epoch 42/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 24808056.0000 - val_loss: 225117.9375\n",
      "Epoch 43/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 228642.2969 - val_loss: 82724.8203\n",
      "Epoch 44/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 90285.4297 - val_loss: 86305.1328\n",
      "Epoch 45/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 38848.9375 - val_loss: 14564.4375\n",
      "Epoch 46/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 17307.7773 - val_loss: 4359.6255\n",
      "Epoch 47/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 13523971.0000 - val_loss: 3097578496.0000\n",
      "Epoch 48/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 13836295.0000 - val_loss: 184319.9375\n",
      "Epoch 49/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 113938.7188 - val_loss: 60370.7617\n",
      "Epoch 50/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 50632.4688 - val_loss: 19343.0117\n",
      "Epoch 51/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 27183.2422 - val_loss: 21375.9199\n",
      "Epoch 52/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 13475.9170 - val_loss: 4922.8115\n",
      "Epoch 53/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 9959175.0000 - val_loss: 98638.2734\n",
      "Epoch 54/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 80068.7734 - val_loss: 28325.9805\n",
      "Epoch 55/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 32589.0801 - val_loss: 16589.9219\n",
      "Epoch 56/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 18563.5156 - val_loss: 5137.6689\n",
      "Epoch 57/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 27820820.0000 - val_loss: 143880.6875\n",
      "Epoch 58/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 153707.0000 - val_loss: 55757.2344\n",
      "Epoch 59/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 73622.0938 - val_loss: 24294.5586\n",
      "Epoch 60/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 33087.4688 - val_loss: 20054.0117\n",
      "Epoch 61/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 23873.6797 - val_loss: 8373.2529\n",
      "Epoch 62/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 10084.5674 - val_loss: 2427.3843\n",
      "Epoch 63/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 23145950.0000 - val_loss: 197131.7188\n",
      "Epoch 64/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 175945.2188 - val_loss: 72468.7031\n",
      "Epoch 65/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 67246.2109 - val_loss: 23137.0469\n",
      "Epoch 66/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 29396.9883 - val_loss: 15624.8291\n",
      "Epoch 67/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 13568.3271 - val_loss: 6352.2773\n",
      "Epoch 68/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 6061.8096 - val_loss: 2118.7241\n",
      "Epoch 69/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 14967413.0000 - val_loss: 94449.5547\n",
      "Epoch 70/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 74054.4375 - val_loss: 28528.0430\n",
      "Epoch 71/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 38114.3555 - val_loss: 18743.1211\n",
      "Epoch 72/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 20122.2441 - val_loss: 15039.6572\n",
      "Epoch 73/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 12766.7900 - val_loss: 46730.4844\n",
      "Epoch 74/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 18132856.0000 - val_loss: 96112.7031\n",
      "Epoch 75/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 85819.6562 - val_loss: 46079.7969\n",
      "Epoch 76/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 41369.0430 - val_loss: 15993.2754\n",
      "Epoch 77/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 19993.3848 - val_loss: 10578.5576\n",
      "Epoch 78/78\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 9401777.0000 - val_loss: 879472.9375\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▁▁▁▁▄▁▃▁▁▃▁▄▁▁▁▁▁▁▁█▁▁▅▁▁▁▁▁▁▁▁▁▁▁▁▆▁▄</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▄▁▁▁▁▂▁▁▂▁▁▁▁▃▂▁▂▁▁▁▁▁▁▁▂▁▁▁▁▂▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>2</td></tr><tr><td>best_val_loss</td><td>0.73986</td></tr><tr><td>epoch</td><td>77</td></tr><tr><td>loss</td><td>9401777.0</td></tr><tr><td>val_loss</td><td>879472.9375</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">faithful-sweep-51</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/l531pxa9\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/l531pxa9</a><br/>Synced 6 W&B file(s), 1 media file(s), 13 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_075312-l531pxa9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zj0cacq4 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4668778588604029\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 31\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.08933275602202363\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 98\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 161\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 254\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e3d51f09e34d3fac5092e5dedf1f60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01666843505002665, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_075601-zj0cacq4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/zj0cacq4\" target=\"_blank\">ethereal-sweep-52</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/31\n",
      "1143/1146 [============================>.] - ETA: 0s - loss: 1299.5454INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_075601-zj0cacq4/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_075601-zj0cacq4/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 3ms/step - loss: 1297.2173 - val_loss: 2.8669\n",
      "Epoch 2/31\n",
      "1130/1146 [============================>.] - ETA: 0s - loss: 1.5021INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_075601-zj0cacq4/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_075601-zj0cacq4/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 2ms/step - loss: 1.4975 - val_loss: 0.9182\n",
      "Epoch 3/31\n",
      "1141/1146 [============================>.] - ETA: 0s - loss: 1.1171INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_075601-zj0cacq4/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_075601-zj0cacq4/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 3ms/step - loss: 1.1171 - val_loss: 0.8889\n",
      "Epoch 4/31\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1.0001 - val_loss: 1.1066\n",
      "Epoch 5/31\n",
      "1137/1146 [============================>.] - ETA: 0s - loss: 0.9112INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_075601-zj0cacq4/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_075601-zj0cacq4/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.9108 - val_loss: 0.8767\n",
      "Epoch 6/31\n",
      "1135/1146 [============================>.] - ETA: 0s - loss: 0.8629INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_075601-zj0cacq4/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_075601-zj0cacq4/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.8622 - val_loss: 0.7406\n",
      "Epoch 7/31\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 429390944.0000 - val_loss: 809899.0000\n",
      "Epoch 8/31\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1027447.3125 - val_loss: 315761.1250\n",
      "Epoch 9/31\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 355062.6562 - val_loss: 198004.6875\n",
      "Epoch 10/31\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 185852.9844 - val_loss: 256677.7500\n",
      "Epoch 11/31\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 81961.8672 - val_loss: 55298.1094\n",
      "Epoch 12/31\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 49585.2305 - val_loss: 29780.0625\n",
      "Epoch 13/31\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 266691136.0000 - val_loss: 6311136768.0000\n",
      "Epoch 14/31\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 187553360.0000 - val_loss: 2855942.7500\n",
      "Epoch 15/31\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 907804.0625 - val_loss: 611189.7500\n",
      "Epoch 16/31\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 407312.8750 - val_loss: 251337.6094\n",
      "Epoch 17/31\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 217952.5938 - val_loss: 122509.9219\n",
      "Epoch 18/31\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 161013.4219 - val_loss: 89440.7109\n",
      "Epoch 19/31\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1453928448.0000 - val_loss: 61715544.0000\n",
      "Epoch 20/31\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 7135595.0000 - val_loss: 1405207.3750\n",
      "Epoch 21/31\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2518739.7500 - val_loss: 1270716.2500\n",
      "Epoch 22/31\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 578128576.0000 - val_loss: 19019330.0000\n",
      "Epoch 23/31\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 6541585.0000 - val_loss: 3447378.5000\n",
      "Epoch 24/31\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2317767.0000 - val_loss: 1076002.1250\n",
      "Epoch 25/31\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1211601.6250 - val_loss: 3134428.5000\n",
      "Epoch 26/31\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 778632.5000 - val_loss: 248123.0312\n",
      "Epoch 27/31\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 361689.4062 - val_loss: 182466.4844\n",
      "Epoch 28/31\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 202149.9375 - val_loss: 83371.2344\n",
      "Epoch 29/31\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 110373.0078 - val_loss: 68142.0938\n",
      "Epoch 30/31\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2418287616.0000 - val_loss: 34438496.0000\n",
      "Epoch 31/31\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 13472932.0000 - val_loss: 14964576.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▁▁▁▁▂▁▁▁▁▁▂▂▁▁▁▁▅▁▁▃▁▁▁▁▁▁▁█▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>5</td></tr><tr><td>best_val_loss</td><td>0.74064</td></tr><tr><td>epoch</td><td>30</td></tr><tr><td>loss</td><td>13472932.0</td></tr><tr><td>val_loss</td><td>14964576.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">ethereal-sweep-52</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/zj0cacq4\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/zj0cacq4</a><br/>Synced 6 W&B file(s), 1 media file(s), 21 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_075601-zj0cacq4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lv4fijlw with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4789036025147468\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 57\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.06426150614583769\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 103\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 192\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 86\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 171\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 138\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_075738-lv4fijlw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/lv4fijlw\" target=\"_blank\">helpful-sweep-53</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/57\n",
      "1115/1146 [============================>.] - ETA: 0s - loss: 1680.0983INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_075738-lv4fijlw/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_075738-lv4fijlw/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 3ms/step - loss: 1636.1093 - val_loss: 2.7408\n",
      "Epoch 2/57\n",
      "1138/1146 [============================>.] - ETA: 0s - loss: 2.1941INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_075738-lv4fijlw/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_075738-lv4fijlw/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 2ms/step - loss: 2.1919 - val_loss: 1.4459\n",
      "Epoch 3/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1.3594 - val_loss: 1.5744\n",
      "Epoch 4/57\n",
      "1135/1146 [============================>.] - ETA: 0s - loss: 1.0830INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_075738-lv4fijlw/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_075738-lv4fijlw/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 2ms/step - loss: 1.0818 - val_loss: 1.2339\n",
      "Epoch 5/57\n",
      "1126/1146 [============================>.] - ETA: 0s - loss: 0.9632INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_075738-lv4fijlw/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_075738-lv4fijlw/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.9619 - val_loss: 0.8250\n",
      "Epoch 6/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.9076 - val_loss: 0.8526\n",
      "Epoch 7/57\n",
      "1131/1146 [============================>.] - ETA: 0s - loss: 0.8514INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_075738-lv4fijlw/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_075738-lv4fijlw/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.8504 - val_loss: 0.7615\n",
      "Epoch 8/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.8150 - val_loss: 0.7733\n",
      "Epoch 9/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.8114 - val_loss: 0.8465\n",
      "Epoch 10/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.8365 - val_loss: 0.7632\n",
      "Epoch 11/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 46200300.0000 - val_loss: 118175.8516\n",
      "Epoch 12/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 93718.6719 - val_loss: 53980.5664\n",
      "Epoch 13/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 51648.4453 - val_loss: 20178.8125\n",
      "Epoch 14/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 31702.3086 - val_loss: 13694.5664\n",
      "Epoch 15/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 15554.1465 - val_loss: 19074.4531\n",
      "Epoch 16/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 66551500.0000 - val_loss: 598119.3750\n",
      "Epoch 17/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 421512.5000 - val_loss: 202739.4531\n",
      "Epoch 18/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 155091.8594 - val_loss: 90926.2109\n",
      "Epoch 19/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 70613.7266 - val_loss: 29336.2812\n",
      "Epoch 20/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 44644.9570 - val_loss: 27153.4805\n",
      "Epoch 21/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 20896.9180 - val_loss: 9370.1240\n",
      "Epoch 22/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 146923600.0000 - val_loss: 1667878.8750\n",
      "Epoch 23/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 971397.6875 - val_loss: 395932.0938\n",
      "Epoch 24/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 383258.8438 - val_loss: 157345.5938\n",
      "Epoch 25/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 173953.9844 - val_loss: 106837.1953\n",
      "Epoch 26/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 90501.4688 - val_loss: 55913.7539\n",
      "Epoch 27/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 32194078.0000 - val_loss: 234442.0938\n",
      "Epoch 28/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 146169.6094 - val_loss: 133105.5000\n",
      "Epoch 29/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 76039.9844 - val_loss: 60858.9648\n",
      "Epoch 30/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 47859.6602 - val_loss: 18513.0977\n",
      "Epoch 31/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 27224.2852 - val_loss: 14459.0215\n",
      "Epoch 32/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 14840.5049 - val_loss: 15197.6191\n",
      "Epoch 33/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 65213556.0000 - val_loss: 3467788.0000\n",
      "Epoch 34/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 427822.1250 - val_loss: 155317.5781\n",
      "Epoch 35/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 157251.7031 - val_loss: 112751.9062\n",
      "Epoch 36/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 97307.6562 - val_loss: 40233.6289\n",
      "Epoch 37/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 58337.1211 - val_loss: 43093.2812\n",
      "Epoch 38/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 608151552.0000 - val_loss: 30185990.0000\n",
      "Epoch 39/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 4284805.5000 - val_loss: 1794892.0000\n",
      "Epoch 40/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2098943.2500 - val_loss: 1334546.8750\n",
      "Epoch 41/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1177590.8750 - val_loss: 1353278.6250\n",
      "Epoch 42/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 634976.2500 - val_loss: 399965.5000\n",
      "Epoch 43/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 306730.6562 - val_loss: 175113.6250\n",
      "Epoch 44/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 185009.4531 - val_loss: 66366.8906\n",
      "Epoch 45/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 87485.6328 - val_loss: 39637.7344\n",
      "Epoch 46/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 48892.1953 - val_loss: 39944.4219\n",
      "Epoch 47/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 59756148.0000 - val_loss: 314903.8125\n",
      "Epoch 48/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 331064.8438 - val_loss: 176237.0000\n",
      "Epoch 49/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 195337.2656 - val_loss: 109407.5859\n",
      "Epoch 50/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 119684.0781 - val_loss: 115100.3750\n",
      "Epoch 51/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 72627.2500 - val_loss: 60936.7188\n",
      "Epoch 52/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 45071.8164 - val_loss: 19817.9355\n",
      "Epoch 53/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 217929584.0000 - val_loss: 4980071.0000\n",
      "Epoch 54/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2762537.2500 - val_loss: 1022023.1250\n",
      "Epoch 55/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 708907.8750 - val_loss: 592522.4375\n",
      "Epoch 56/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 362631.4062 - val_loss: 150826.2188\n",
      "Epoch 57/57\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 229664.3750 - val_loss: 161348.9219\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▁▁▁▁▁▂▁▁▁▂▁▁▁▃▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>6</td></tr><tr><td>best_val_loss</td><td>0.76147</td></tr><tr><td>epoch</td><td>56</td></tr><tr><td>loss</td><td>229664.375</td></tr><tr><td>val_loss</td><td>161348.92188</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">helpful-sweep-53</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/lv4fijlw\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/lv4fijlw</a><br/>Synced 6 W&B file(s), 1 media file(s), 21 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_075738-lv4fijlw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: y01tarjb with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.19074744742961056\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 83\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01820104860992966\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 171\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 183\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 98\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 243\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_075943-y01tarjb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/y01tarjb\" target=\"_blank\">misunderstood-sweep-54</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/83\n",
      "2269/2291 [============================>.] - ETA: 0s - loss: 1.0564INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_075943-y01tarjb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_075943-y01tarjb/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 5s 2ms/step - loss: 1.0545 - val_loss: 0.9201\n",
      "Epoch 2/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 6416.2041 - val_loss: 79.5879\n",
      "Epoch 3/83\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 32.6571 - val_loss: 16.8688\n",
      "Epoch 4/83\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 9.5501 - val_loss: 4.2926\n",
      "Epoch 5/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3.6374 - val_loss: 2.4549\n",
      "Epoch 6/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 24186.4883 - val_loss: 217.0288\n",
      "Epoch 7/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 146.8567 - val_loss: 51.1442\n",
      "Epoch 8/83\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 46.6627 - val_loss: 20.4194\n",
      "Epoch 9/83\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 8715.8682 - val_loss: 120.4910\n",
      "Epoch 10/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 81.3635 - val_loss: 34.2331\n",
      "Epoch 11/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 22.4506 - val_loss: 11.3648\n",
      "Epoch 12/83\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 7.6629 - val_loss: 4.7749\n",
      "Epoch 13/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 4.7434 - val_loss: 1.5233\n",
      "Epoch 14/83\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 12983.6914 - val_loss: 89.4884\n",
      "Epoch 15/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 50.9063 - val_loss: 22.4335\n",
      "Epoch 16/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 19.8332 - val_loss: 12.5087\n",
      "Epoch 17/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 17530.6777 - val_loss: 161.0403\n",
      "Epoch 18/83\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 108.1682 - val_loss: 37.6825\n",
      "Epoch 19/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 36.5495 - val_loss: 21.6204\n",
      "Epoch 20/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 18307.8594 - val_loss: 1076.8020\n",
      "Epoch 21/83\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 302.2777 - val_loss: 69.4313\n",
      "Epoch 22/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 74.0618 - val_loss: 38.7358\n",
      "Epoch 23/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 25.1434 - val_loss: 15.2222\n",
      "Epoch 24/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 9.2003 - val_loss: 5.9137\n",
      "Epoch 25/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 14336.1299 - val_loss: 167.0331\n",
      "Epoch 26/83\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 111.9622 - val_loss: 37.6508\n",
      "Epoch 27/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 41.5131 - val_loss: 32.3890\n",
      "Epoch 28/83\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 17.4978 - val_loss: 7.7884\n",
      "Epoch 29/83\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 10067.5479 - val_loss: 64.0041\n",
      "Epoch 30/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 52.9101 - val_loss: 24.7645\n",
      "Epoch 31/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 20.6167 - val_loss: 17.0997\n",
      "Epoch 32/83\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 53713.1367 - val_loss: 3711.7393\n",
      "Epoch 33/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 715.8289 - val_loss: 178.3517\n",
      "Epoch 34/83\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 163.5894 - val_loss: 89.0000\n",
      "Epoch 35/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 61972.7617 - val_loss: 4879.4878\n",
      "Epoch 36/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 994.2043 - val_loss: 334.0454\n",
      "Epoch 37/83\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 243.4245 - val_loss: 149.3374\n",
      "Epoch 38/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 28623.4961 - val_loss: 1644.7111\n",
      "Epoch 39/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 434.5086 - val_loss: 104.2507\n",
      "Epoch 40/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 105.2357 - val_loss: 97.8482\n",
      "Epoch 41/83\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 45.5850 - val_loss: 21.6059\n",
      "Epoch 42/83\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 23091.3906 - val_loss: 697.5261\n",
      "Epoch 43/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 330.5340 - val_loss: 182.3035\n",
      "Epoch 44/83\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 100.3444 - val_loss: 61.6261\n",
      "Epoch 45/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 14716.4775 - val_loss: 494.1609\n",
      "Epoch 46/83\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 150.6171 - val_loss: 165.5926\n",
      "Epoch 47/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 50.0250 - val_loss: 21.8989\n",
      "Epoch 48/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 23.6135 - val_loss: 14.2321\n",
      "Epoch 49/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 10076.6797 - val_loss: 125.2462\n",
      "Epoch 50/83\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 87.3067 - val_loss: 54.4134\n",
      "Epoch 51/83\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 38.6088 - val_loss: 68.7441\n",
      "Epoch 52/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 15.2107 - val_loss: 6.1129\n",
      "Epoch 53/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 18432.7793 - val_loss: 125.2237\n",
      "Epoch 54/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 84.5994 - val_loss: 58.9832\n",
      "Epoch 55/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 38.4171 - val_loss: 43.1779\n",
      "Epoch 56/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 32152.4023 - val_loss: 215.6040\n",
      "Epoch 57/83\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 128.9573 - val_loss: 81.0291\n",
      "Epoch 58/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 57.5954 - val_loss: 30.0701\n",
      "Epoch 59/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 26301.7383 - val_loss: 509.5634\n",
      "Epoch 60/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 397.7605 - val_loss: 79.4312\n",
      "Epoch 61/83\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 105.0177 - val_loss: 39.9623\n",
      "Epoch 62/83\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 20204.4961 - val_loss: 666.6190\n",
      "Epoch 63/83\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 400.4818 - val_loss: 159.7366\n",
      "Epoch 64/83\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 111.5300 - val_loss: 46.3391\n",
      "Epoch 65/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 16714.5801 - val_loss: 395.4181\n",
      "Epoch 66/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 300.0390 - val_loss: 109.6755\n",
      "Epoch 67/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 86.3465 - val_loss: 49.5464\n",
      "Epoch 68/83\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 35.2654 - val_loss: 17.3778\n",
      "Epoch 69/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 8398.4756 - val_loss: 143.3172\n",
      "Epoch 70/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 96.9080 - val_loss: 37.7928\n",
      "Epoch 71/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 33.8937 - val_loss: 14.9024\n",
      "Epoch 72/83\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 12.7973 - val_loss: 7.2514\n",
      "Epoch 73/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 6.6725 - val_loss: 70.8434\n",
      "Epoch 74/83\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 9191.0928 - val_loss: 150.4794\n",
      "Epoch 75/83\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 42.8547 - val_loss: 26.1137\n",
      "Epoch 76/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 15.7717 - val_loss: 6.8431\n",
      "Epoch 77/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 6.5952 - val_loss: 3.0977\n",
      "Epoch 78/83\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 8084.3154 - val_loss: 69.3810\n",
      "Epoch 79/83\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 45.8551 - val_loss: 21.6416\n",
      "Epoch 80/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 19.6384 - val_loss: 7.5630\n",
      "Epoch 81/83\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 18028.7285 - val_loss: 821.7545\n",
      "Epoch 82/83\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 259.7735 - val_loss: 66.3547\n",
      "Epoch 83/83\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 65.0478 - val_loss: 40.1817\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06a06961f99042eeadef40445f32c36c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='2.501 MB of 2.501 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▁▁▂▁▁▁▃▁▁▁▁▁▁█▁▁▅▁▁▃▁▂▁▃▁▁▄▁▁▁▁▁▁▂▁▂▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▂▄▁▁▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.92006</td></tr><tr><td>epoch</td><td>82</td></tr><tr><td>loss</td><td>65.04783</td></tr><tr><td>val_loss</td><td>40.18172</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">misunderstood-sweep-54</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/y01tarjb\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/y01tarjb</a><br/>Synced 6 W&B file(s), 1 media file(s), 5 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_075943-y01tarjb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2nvhr03k with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3553872839982336\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 74\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.045917776622398\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 178\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 171\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 213\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 82\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 232\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_080440-2nvhr03k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/2nvhr03k\" target=\"_blank\">fancy-sweep-55</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/74\n",
      "1136/1146 [============================>.] - ETA: 0s - loss: 36.6557INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_080440-2nvhr03k/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_080440-2nvhr03k/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 3ms/step - loss: 36.3721 - val_loss: 0.7759\n",
      "Epoch 2/74\n",
      "1132/1146 [============================>.] - ETA: 0s - loss: 0.7974INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_080440-2nvhr03k/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_080440-2nvhr03k/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.7974 - val_loss: 0.7467\n",
      "Epoch 3/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.7755 - val_loss: 0.7711\n",
      "Epoch 4/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.7724 - val_loss: 0.7691\n",
      "Epoch 5/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.7779 - val_loss: 1.0497\n",
      "Epoch 6/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.8073 - val_loss: 1.2773\n",
      "Epoch 7/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 102177832.0000 - val_loss: 4659288.0000\n",
      "Epoch 8/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 473822.5938 - val_loss: 115538.0938\n",
      "Epoch 9/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 103558.5859 - val_loss: 63099.5234\n",
      "Epoch 10/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 63233.1992 - val_loss: 100504.7656\n",
      "Epoch 11/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 52219.1250 - val_loss: 27961.0703\n",
      "Epoch 12/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 29628.2441 - val_loss: 27248.5918\n",
      "Epoch 13/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 15358.8262 - val_loss: 21259.1699\n",
      "Epoch 14/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 6919.7754 - val_loss: 6120.7778\n",
      "Epoch 15/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 10551156.0000 - val_loss: 96869.4453\n",
      "Epoch 16/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 54108.5977 - val_loss: 57507.3945\n",
      "Epoch 17/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 25136.6230 - val_loss: 73240.8359\n",
      "Epoch 18/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 13644.5977 - val_loss: 10672.0195\n",
      "Epoch 19/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 6260.3667 - val_loss: 6703.6128\n",
      "Epoch 20/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 32980930.0000 - val_loss: 223561.4062\n",
      "Epoch 21/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 161182.3594 - val_loss: 103140.4375\n",
      "Epoch 22/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 73017.2188 - val_loss: 28543.4746\n",
      "Epoch 23/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 44502.0273 - val_loss: 22729.9707\n",
      "Epoch 24/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 7729858.0000 - val_loss: 355777.9062\n",
      "Epoch 25/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 92427.2422 - val_loss: 171818.1406\n",
      "Epoch 26/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 30011.2090 - val_loss: 72988.9688\n",
      "Epoch 27/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 14617.4043 - val_loss: 7128.1392\n",
      "Epoch 28/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 7991.0874 - val_loss: 4399.7886\n",
      "Epoch 29/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 4131.0312 - val_loss: 3320.1909\n",
      "Epoch 30/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2323.8293 - val_loss: 1290.7983\n",
      "Epoch 31/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 13116845.0000 - val_loss: 2984270336.0000\n",
      "Epoch 32/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 27343864.0000 - val_loss: 219594.7500\n",
      "Epoch 33/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 176877.9688 - val_loss: 94470.0469\n",
      "Epoch 34/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 94388.2500 - val_loss: 42359.0117\n",
      "Epoch 35/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 56679.2891 - val_loss: 31904.7949\n",
      "Epoch 36/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 32103.0117 - val_loss: 17028.2812\n",
      "Epoch 37/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 19317.3730 - val_loss: 11575.0176\n",
      "Epoch 38/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 11049.2051 - val_loss: 6550.1392\n",
      "Epoch 39/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 30106520.0000 - val_loss: 184888.2812\n",
      "Epoch 40/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 147559.2031 - val_loss: 124835.5391\n",
      "Epoch 41/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 79407.2188 - val_loss: 71139.3125\n",
      "Epoch 42/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 46868.6641 - val_loss: 54258.8555\n",
      "Epoch 43/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 28790.2109 - val_loss: 23869.6777\n",
      "Epoch 44/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 17109544.0000 - val_loss: 395097.6562\n",
      "Epoch 45/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 248621.0781 - val_loss: 61821.6172\n",
      "Epoch 46/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 68474.6172 - val_loss: 33886.1836\n",
      "Epoch 47/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 37186.3555 - val_loss: 68629.7109\n",
      "Epoch 48/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 20677.6992 - val_loss: 33394.8320\n",
      "Epoch 49/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 12698.7812 - val_loss: 19443.2754\n",
      "Epoch 50/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 7817.3076 - val_loss: 7201.8936\n",
      "Epoch 51/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 5671.2427 - val_loss: 4140.6479\n",
      "Epoch 52/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 32877004.0000 - val_loss: 861241.3125\n",
      "Epoch 53/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 299568.2188 - val_loss: 137542.1875\n",
      "Epoch 54/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 110269.1875 - val_loss: 56798.3984\n",
      "Epoch 55/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 76027.2266 - val_loss: 39629.3516\n",
      "Epoch 56/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 48745.8086 - val_loss: 29465.4980\n",
      "Epoch 57/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 24574.8320 - val_loss: 16710.0430\n",
      "Epoch 58/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 14576.9102 - val_loss: 10364.7500\n",
      "Epoch 59/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8435.5693 - val_loss: 6026.7729\n",
      "Epoch 60/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 62834892.0000 - val_loss: 308124.9375\n",
      "Epoch 61/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 293865.8750 - val_loss: 152819.7500\n",
      "Epoch 62/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 168014.5625 - val_loss: 124526.0234\n",
      "Epoch 63/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 99236.4453 - val_loss: 39823.3789\n",
      "Epoch 64/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 64919.4414 - val_loss: 88783.1953\n",
      "Epoch 65/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 35669.2227 - val_loss: 20814.5859\n",
      "Epoch 66/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 18186092.0000 - val_loss: 125018.7969\n",
      "Epoch 67/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 99033.6172 - val_loss: 113103.4141\n",
      "Epoch 68/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 55471.1055 - val_loss: 35830.6406\n",
      "Epoch 69/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 34141.9141 - val_loss: 14858.9512\n",
      "Epoch 70/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 20291.9551 - val_loss: 14035.0635\n",
      "Epoch 71/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 11680.8271 - val_loss: 5497.5874\n",
      "Epoch 72/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 7673.1006 - val_loss: 5738.7471\n",
      "Epoch 73/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 4704.8276 - val_loss: 3799.5388\n",
      "Epoch 74/74\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 21457652.0000 - val_loss: 148472.3438\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▄▁▁▁▁▁▃▁▁▁▁▁▁▁▁█▁▁▃▁▁▁▃</td></tr><tr><td>val_loss</td><td>▁▁▁▁▃▃▁▁▃▂▁▃▁▄▁▁▁▅▂▁▁▃▂█▂▂▁▁▃▂▁▁▆▃▃▃▂▁▁▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>1</td></tr><tr><td>best_val_loss</td><td>0.74666</td></tr><tr><td>epoch</td><td>73</td></tr><tr><td>loss</td><td>21457652.0</td></tr><tr><td>val_loss</td><td>148472.34375</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">fancy-sweep-55</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/2nvhr03k\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/2nvhr03k</a><br/>Synced 6 W&B file(s), 1 media file(s), 9 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_080440-2nvhr03k/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6n0xnqx4 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.08501412971688302\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 89\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.05653185881350084\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 90\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 181\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 87\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 154\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 177\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_080746-6n0xnqx4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/6n0xnqx4\" target=\"_blank\">confused-sweep-55</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/89\n",
      "1522/1527 [============================>.] - ETA: 0s - loss: 78.5990INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_080746-6n0xnqx4/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_080746-6n0xnqx4/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 4s 2ms/step - loss: 78.3575 - val_loss: 0.8428\n",
      "Epoch 2/89\n",
      "1513/1527 [============================>.] - ETA: 0s - loss: 0.8101INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_080746-6n0xnqx4/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_080746-6n0xnqx4/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.8096 - val_loss: 0.7895\n",
      "Epoch 3/89\n",
      "1495/1527 [============================>.] - ETA: 0s - loss: 0.7795INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_080746-6n0xnqx4/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_080746-6n0xnqx4/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.7789 - val_loss: 0.7678\n",
      "Epoch 4/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 0.7735 - val_loss: 0.7934\n",
      "Epoch 5/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 0.7849 - val_loss: 0.7792\n",
      "Epoch 6/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 49351632.0000 - val_loss: 39977768.0000\n",
      "Epoch 7/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 637599.0625 - val_loss: 140212.4688\n",
      "Epoch 8/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 108493.2109 - val_loss: 53108.7109\n",
      "Epoch 9/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 51180.6797 - val_loss: 17119.1895\n",
      "Epoch 10/89\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 23284.8789 - val_loss: 9775.7998\n",
      "Epoch 11/89\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 79270944.0000 - val_loss: 2574725.0000\n",
      "Epoch 12/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 627548.5000 - val_loss: 216322.5625\n",
      "Epoch 13/89\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 188859.8906 - val_loss: 162860.7656\n",
      "Epoch 14/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 112435.3594 - val_loss: 163763.0781\n",
      "Epoch 15/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 46227.1680 - val_loss: 18143.2207\n",
      "Epoch 16/89\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 26675.9199 - val_loss: 12592.5830\n",
      "Epoch 17/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 31291130.0000 - val_loss: 155812.7500\n",
      "Epoch 18/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 102752.4141 - val_loss: 44154.0234\n",
      "Epoch 19/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 52013.1133 - val_loss: 19276.4434\n",
      "Epoch 20/89\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 26985.0020 - val_loss: 13707.1836\n",
      "Epoch 21/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 33628716.0000 - val_loss: 195004.6719\n",
      "Epoch 22/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 147950.8750 - val_loss: 84323.9609\n",
      "Epoch 23/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 73393.4688 - val_loss: 56584.2422\n",
      "Epoch 24/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 38041.4531 - val_loss: 14949.9785\n",
      "Epoch 25/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 31017294.0000 - val_loss: 259719.1250\n",
      "Epoch 26/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 254316.5938 - val_loss: 131383.5156\n",
      "Epoch 27/89\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 114643.8906 - val_loss: 54017.4648\n",
      "Epoch 28/89\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 48471.7305 - val_loss: 27362.7715\n",
      "Epoch 29/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 26873.7871 - val_loss: 13134.3525\n",
      "Epoch 30/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 25861524.0000 - val_loss: 290618.7188\n",
      "Epoch 31/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 144609.8750 - val_loss: 61721.8008\n",
      "Epoch 32/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 56436.0391 - val_loss: 29457.2422\n",
      "Epoch 33/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 29698.1270 - val_loss: 14377.8203\n",
      "Epoch 34/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 71895944.0000 - val_loss: 320376.0938\n",
      "Epoch 35/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 279087.0000 - val_loss: 117838.4609\n",
      "Epoch 36/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 133918.6719 - val_loss: 63896.0000\n",
      "Epoch 37/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 74271.8672 - val_loss: 39280.0586\n",
      "Epoch 38/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 22810656.0000 - val_loss: 1980825.2500\n",
      "Epoch 39/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 395785.1250 - val_loss: 142159.5781\n",
      "Epoch 40/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 101328.7344 - val_loss: 65531.1797\n",
      "Epoch 41/89\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 47818.5977 - val_loss: 27207.7559\n",
      "Epoch 42/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 25215.4551 - val_loss: 17064.6133\n",
      "Epoch 43/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 80464088.0000 - val_loss: 747428.2500\n",
      "Epoch 44/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 570108.5625 - val_loss: 220284.3750\n",
      "Epoch 45/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 236594.8281 - val_loss: 148661.3125\n",
      "Epoch 46/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 130730.3047 - val_loss: 51385.9961\n",
      "Epoch 47/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 78701.9531 - val_loss: 36881.5898\n",
      "Epoch 48/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 39837.5352 - val_loss: 21867.4570\n",
      "Epoch 49/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 38217700.0000 - val_loss: 271454.2812\n",
      "Epoch 50/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 171737.1875 - val_loss: 87265.7188\n",
      "Epoch 51/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 86154.1172 - val_loss: 41395.8906\n",
      "Epoch 52/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 49039.6602 - val_loss: 32024.9668\n",
      "Epoch 53/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 40805836.0000 - val_loss: 203916.2812\n",
      "Epoch 54/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 192263.7969 - val_loss: 142291.2656\n",
      "Epoch 55/89\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 94356.7109 - val_loss: 51098.9258\n",
      "Epoch 56/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 12435220.0000 - val_loss: 127651.5234\n",
      "Epoch 57/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 110102.7500 - val_loss: 63454.0234\n",
      "Epoch 58/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 43791.0547 - val_loss: 42968.1055\n",
      "Epoch 59/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 23939.0859 - val_loss: 13065.7588\n",
      "Epoch 60/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 13372.2197 - val_loss: 5689.0356\n",
      "Epoch 61/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 31532214.0000 - val_loss: 1195160.7500\n",
      "Epoch 62/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 339965.9062 - val_loss: 138887.0469\n",
      "Epoch 63/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 104343.8281 - val_loss: 41443.3008\n",
      "Epoch 64/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 46854.5820 - val_loss: 21906.0938\n",
      "Epoch 65/89\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 28226.3984 - val_loss: 18735.5156\n",
      "Epoch 66/89\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 17476.5840 - val_loss: 6778.7495\n",
      "Epoch 67/89\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 89855088.0000 - val_loss: 590227.0000\n",
      "Epoch 68/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 496290.8125 - val_loss: 208754.8594\n",
      "Epoch 69/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 310436.4375 - val_loss: 79464.3125\n",
      "Epoch 70/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 65237752.0000 - val_loss: 788731.6250\n",
      "Epoch 71/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 475294.9688 - val_loss: 200065.8125\n",
      "Epoch 72/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 189626.2031 - val_loss: 101127.5781\n",
      "Epoch 73/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 102135.1875 - val_loss: 57262.9453\n",
      "Epoch 74/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 60398.1836 - val_loss: 36121.1914\n",
      "Epoch 75/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 5297454.0000 - val_loss: 1382096384.0000\n",
      "Epoch 76/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 45227884.0000 - val_loss: 269712.0625\n",
      "Epoch 77/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 234953.4375 - val_loss: 97755.3750\n",
      "Epoch 78/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 130578.5938 - val_loss: 52510.9102\n",
      "Epoch 79/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 63394.1914 - val_loss: 29014.2871\n",
      "Epoch 80/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 34544.1055 - val_loss: 24440.5547\n",
      "Epoch 81/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 39159.6797 - val_loss: 11144.2188\n",
      "Epoch 82/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 62427184.0000 - val_loss: 761223.7500\n",
      "Epoch 83/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 477082.4688 - val_loss: 257254.1562\n",
      "Epoch 84/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 216444.6406 - val_loss: 104713.1484\n",
      "Epoch 85/89\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 137986.9688 - val_loss: 64127.4141\n",
      "Epoch 86/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 67248.0156 - val_loss: 26709.4297\n",
      "Epoch 87/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 80208840.0000 - val_loss: 432085.4688\n",
      "Epoch 88/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 337324.4688 - val_loss: 165036.5625\n",
      "Epoch 89/89\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 155602.1406 - val_loss: 90796.1641\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▁▁▁▁▁▁▁▄▁▄▁▃▁▇▁▁▁█▁▁▁▁▁▁▁▄▁▁▁▇▁▁▁▁▆▁▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>2</td></tr><tr><td>best_val_loss</td><td>0.76782</td></tr><tr><td>epoch</td><td>88</td></tr><tr><td>loss</td><td>155602.14062</td></tr><tr><td>val_loss</td><td>90796.16406</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">confused-sweep-55</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/6n0xnqx4\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/6n0xnqx4</a><br/>Synced 6 W&B file(s), 1 media file(s), 13 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_080746-6n0xnqx4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rtnzfeir with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.27887123976407213\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.08969830226094197\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 226\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 148\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 214\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_081122-rtnzfeir</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/rtnzfeir\" target=\"_blank\">blooming-sweep-55</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "4559/4581 [============================>.] - ETA: 0s - loss: 2769.0552INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_081122-rtnzfeir/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_081122-rtnzfeir/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4581/4581 [==============================] - 6s 1ms/step - loss: 2756.2395 - val_loss: 1.9278\n",
      "Epoch 2/64\n",
      "4569/4581 [============================>.] - ETA: 0s - loss: 1.7005INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_081122-rtnzfeir/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_081122-rtnzfeir/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1.6989 - val_loss: 1.3034\n",
      "Epoch 3/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 282030880.0000 - val_loss: 390515.0938\n",
      "Epoch 4/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 788023.8125 - val_loss: 17801.4219\n",
      "Epoch 5/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 432963936.0000 - val_loss: 2481424.2500\n",
      "Epoch 6/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 349438464.0000 - val_loss: 36475449344.0000\n",
      "Epoch 7/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 56743796.0000 - val_loss: 815367.8125\n",
      "Epoch 8/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 130044656.0000 - val_loss: 590712.4375\n",
      "Epoch 9/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 463497.8438 - val_loss: 296389.9688\n",
      "Epoch 10/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 257183856.0000 - val_loss: 1323333.2500\n",
      "Epoch 11/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 611186.8125 - val_loss: 120974.6094\n",
      "Epoch 12/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 512378624.0000 - val_loss: 909466.6875\n",
      "Epoch 13/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 347393248.0000 - val_loss: 80601800.0000\n",
      "Epoch 14/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 6647217.5000 - val_loss: 804621.9375\n",
      "Epoch 15/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 100045888.0000 - val_loss: 446954.4375\n",
      "Epoch 16/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 256134816.0000 - val_loss: 29865400.0000\n",
      "Epoch 17/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 3939153.2500 - val_loss: 582903.4375\n",
      "Epoch 18/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 250021808.0000 - val_loss: 2561066.7500\n",
      "Epoch 19/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1405935.6250 - val_loss: 169428.2031\n",
      "Epoch 20/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 507357440.0000 - val_loss: 7960124.5000\n",
      "Epoch 21/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 3501223.7500 - val_loss: 412064.7500\n",
      "Epoch 22/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 244185888.0000 - val_loss: 5047991.0000\n",
      "Epoch 23/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2460028.0000 - val_loss: 373260.5625\n",
      "Epoch 24/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 181554656.0000 - val_loss: 902638.6250\n",
      "Epoch 25/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 741805.3750 - val_loss: 149365.1562\n",
      "Epoch 26/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 112751088.0000 - val_loss: 1073997.0000\n",
      "Epoch 27/64\n",
      "4581/4581 [==============================] - 4s 933us/step - loss: 661029.1250 - val_loss: 94643.4297\n",
      "Epoch 28/64\n",
      "4581/4581 [==============================] - 4s 966us/step - loss: 197332016.0000 - val_loss: 534988.6250\n",
      "Epoch 29/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 170185280.0000 - val_loss: 2211056.2500\n",
      "Epoch 30/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1073554.7500 - val_loss: 262187.5938\n",
      "Epoch 31/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 399913280.0000 - val_loss: 1104233.6250\n",
      "Epoch 32/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 235653872.0000 - val_loss: 9331159.0000\n",
      "Epoch 33/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 3959907.2500 - val_loss: 836586.3750\n",
      "Epoch 34/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 407080160.0000 - val_loss: 4488410.0000\n",
      "Epoch 35/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 3107230.0000 - val_loss: 1384838.5000\n",
      "Epoch 36/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 236229392.0000 - val_loss: 1174077.1250\n",
      "Epoch 37/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 217289760.0000 - val_loss: 7400559.0000\n",
      "Epoch 38/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 3477334.2500 - val_loss: 920921.5625\n",
      "Epoch 39/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 164510576.0000 - val_loss: 3576729.0000\n",
      "Epoch 40/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1638134.0000 - val_loss: 332848.2188\n",
      "Epoch 41/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 346982112.0000 - val_loss: 7214103.5000\n",
      "Epoch 42/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 3441398.7500 - val_loss: 1291457.7500\n",
      "Epoch 43/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 499344544.0000 - val_loss: 3072357.2500\n",
      "Epoch 44/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 463813888.0000 - val_loss: 5424741.5000\n",
      "Epoch 45/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 4172473.2500 - val_loss: 828171.0625\n",
      "Epoch 46/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 696776704.0000 - val_loss: 3595147.5000\n",
      "Epoch 47/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 334569088.0000 - val_loss: 4849894.5000\n",
      "Epoch 48/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 3415047.2500 - val_loss: 850005.6875\n",
      "Epoch 49/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 461682976.0000 - val_loss: 2972300.7500\n",
      "Epoch 50/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 110801640.0000 - val_loss: 9614351.0000\n",
      "Epoch 51/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 3212144.7500 - val_loss: 804514.3750\n",
      "Epoch 52/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 188972320.0000 - val_loss: 4026935.2500\n",
      "Epoch 53/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2201311.2500 - val_loss: 702303.1250\n",
      "Epoch 54/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 277630784.0000 - val_loss: 1400337.3750\n",
      "Epoch 55/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 343296128.0000 - val_loss: 14282456.0000\n",
      "Epoch 56/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 3153847.0000 - val_loss: 548346.3750\n",
      "Epoch 57/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 204147232.0000 - val_loss: 2469076.7500\n",
      "Epoch 58/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1637037.6250 - val_loss: 594608.1250\n",
      "Epoch 59/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 315626464.0000 - val_loss: 4456702.0000\n",
      "Epoch 60/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 248509056.0000 - val_loss: 17504760.0000\n",
      "Epoch 61/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 4654493.5000 - val_loss: 949183.1250\n",
      "Epoch 62/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 366493472.0000 - val_loss: 144971776.0000\n",
      "Epoch 63/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 14910768.0000 - val_loss: 1528338.1250\n",
      "Epoch 64/64\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1109459.2500 - val_loss: 730109.3125\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▁▅▂▁▄▆▄▂▁▄▆▃▁▁▂▃▁▅▁▅▃▁▃▄▆▆█▄▆▁▃▄▄▃▄▃▅▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▂█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>1</td></tr><tr><td>best_val_loss</td><td>1.30337</td></tr><tr><td>epoch</td><td>63</td></tr><tr><td>loss</td><td>1109459.25</td></tr><tr><td>val_loss</td><td>730109.3125</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">blooming-sweep-55</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/rtnzfeir\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/rtnzfeir</a><br/>Synced 6 W&B file(s), 1 media file(s), 9 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_081122-rtnzfeir/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6lzab8fx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.45823779839898743\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.003132533453098041\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 223\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 209\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 81\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 221\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 255\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_081701-6lzab8fx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/6lzab8fx\" target=\"_blank\">elated-sweep-56</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/24\n",
      "1138/1146 [============================>.] - ETA: 0s - loss: 0.8527INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_081701-6lzab8fx/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_081701-6lzab8fx/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.8525 - val_loss: 0.8340\n",
      "Epoch 2/24\n",
      "1122/1146 [============================>.] - ETA: 0s - loss: 0.7765INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_081701-6lzab8fx/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_081701-6lzab8fx/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.7757 - val_loss: 0.7242\n",
      "Epoch 3/24\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.7508 - val_loss: 0.8231\n",
      "Epoch 4/24\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.7364 - val_loss: 0.7656\n",
      "Epoch 5/24\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.7215 - val_loss: 0.7315\n",
      "Epoch 6/24\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.7158 - val_loss: 0.7271\n",
      "Epoch 7/24\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.7076 - val_loss: 0.7273\n",
      "Epoch 8/24\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.7064 - val_loss: 0.7375\n",
      "Epoch 9/24\n",
      "1137/1146 [============================>.] - ETA: 0s - loss: 0.7065INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_081701-6lzab8fx/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_081701-6lzab8fx/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.7060 - val_loss: 0.6947\n",
      "Epoch 10/24\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.7029 - val_loss: 0.7356\n",
      "Epoch 11/24\n",
      "1138/1146 [============================>.] - ETA: 0s - loss: 0.6987INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_081701-6lzab8fx/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_081701-6lzab8fx/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.6984 - val_loss: 0.6696\n",
      "Epoch 12/24\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.6953 - val_loss: 0.6728\n",
      "Epoch 13/24\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 1.2112 - val_loss: 0.7006\n",
      "Epoch 14/24\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.6834 - val_loss: 0.6854\n",
      "Epoch 15/24\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.6748 - val_loss: 0.6819\n",
      "Epoch 16/24\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.6776 - val_loss: 0.6867\n",
      "Epoch 17/24\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.6844 - val_loss: 0.6768\n",
      "Epoch 18/24\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.6844 - val_loss: 0.6780\n",
      "Epoch 19/24\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.6917 - val_loss: 0.7153\n",
      "Epoch 20/24\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.6899 - val_loss: 0.7242\n",
      "Epoch 21/24\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.6899 - val_loss: 0.7594\n",
      "Epoch 22/24\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.6844 - val_loss: 0.7918\n",
      "Epoch 23/24\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.6916 - val_loss: 0.7179\n",
      "Epoch 24/24\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.6833 - val_loss: 0.7511\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▃▃▄▄▄▅▅▅▆▆▆▆▇▇▇██</td></tr><tr><td>loss</td><td>▃▂▂▂▂▂▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▃█▅▄▃▃▄▂▄▁▁▂▂▂▂▁▁▃▃▅▆▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>10</td></tr><tr><td>best_val_loss</td><td>0.66961</td></tr><tr><td>epoch</td><td>23</td></tr><tr><td>loss</td><td>0.68333</td></tr><tr><td>val_loss</td><td>0.75114</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">elated-sweep-56</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/6lzab8fx\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/6lzab8fx</a><br/>Synced 6 W&B file(s), 1 media file(s), 17 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_081701-6lzab8fx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ztstf2yz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.11396113491891556\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.08764238006968646\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 205\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 249\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 68\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 180\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 247\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_081828-ztstf2yz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/ztstf2yz\" target=\"_blank\">avid-sweep-57</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "2288/2291 [============================>.] - ETA: 0s - loss: 10548.8877INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_081828-ztstf2yz/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_081828-ztstf2yz/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 5s 2ms/step - loss: 10539.1777 - val_loss: 9.0966\n",
      "Epoch 2/60\n",
      "2272/2291 [============================>.] - ETA: 0s - loss: 4.7618INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_081828-ztstf2yz/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_081828-ztstf2yz/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 4.7431 - val_loss: 2.8995\n",
      "Epoch 3/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1492109312.0000 - val_loss: 11397967.0000\n",
      "Epoch 4/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 8361252.0000 - val_loss: 3388291.7500\n",
      "Epoch 5/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 3194003.7500 - val_loss: 1403831.7500\n",
      "Epoch 6/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 872814.3125 - val_loss: 235380.1562\n",
      "Epoch 7/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1041756544.0000 - val_loss: 2164801.0000\n",
      "Epoch 8/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 2148327.2500 - val_loss: 991976.0625\n",
      "Epoch 9/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 783287.8125 - val_loss: 275079.4062\n",
      "Epoch 10/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1501321856.0000 - val_loss: 25616610.0000\n",
      "Epoch 11/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 13225826.0000 - val_loss: 5973073.0000\n",
      "Epoch 12/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 3546798.5000 - val_loss: 1977844.0000\n",
      "Epoch 13/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 813220480.0000 - val_loss: 2645905.7500\n",
      "Epoch 14/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 2724748.0000 - val_loss: 1316065.3750\n",
      "Epoch 15/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1276144384.0000 - val_loss: 15064508416.0000\n",
      "Epoch 16/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 60936668.0000 - val_loss: 4848763.0000\n",
      "Epoch 17/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 3545756.7500 - val_loss: 1259110.5000\n",
      "Epoch 18/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 6839872512.0000 - val_loss: 19765662.0000\n",
      "Epoch 19/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 19697894.0000 - val_loss: 12747035.0000\n",
      "Epoch 20/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 7787565.0000 - val_loss: 5778557.0000\n",
      "Epoch 21/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1303438848.0000 - val_loss: 13534260.0000\n",
      "Epoch 22/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 11006796.0000 - val_loss: 6033696.0000\n",
      "Epoch 23/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 3583361.5000 - val_loss: 1589958.5000\n",
      "Epoch 24/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 2125993856.0000 - val_loss: 60714108.0000\n",
      "Epoch 25/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 22473270.0000 - val_loss: 6030698.5000\n",
      "Epoch 26/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 5345553.5000 - val_loss: 2473751.0000\n",
      "Epoch 27/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 2428687.7500 - val_loss: 1616174.5000\n",
      "Epoch 28/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 3778181376.0000 - val_loss: 16400739.0000\n",
      "Epoch 29/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 16957380.0000 - val_loss: 11807331.0000\n",
      "Epoch 30/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 8714081280.0000 - val_loss: 131711456.0000\n",
      "Epoch 31/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 57557436.0000 - val_loss: 25073920.0000\n",
      "Epoch 32/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 17905642.0000 - val_loss: 6285530.0000\n",
      "Epoch 33/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 7245311.5000 - val_loss: 7044442.0000\n",
      "Epoch 34/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 2362655744.0000 - val_loss: 84721592.0000\n",
      "Epoch 35/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 28764422.0000 - val_loss: 11258334.0000\n",
      "Epoch 36/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 8081083.0000 - val_loss: 4076753.0000\n",
      "Epoch 37/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 3700460.5000 - val_loss: 1974563.7500\n",
      "Epoch 38/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 2144983168.0000 - val_loss: 10766500.0000\n",
      "Epoch 39/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 11137900.0000 - val_loss: 45655732.0000\n",
      "Epoch 40/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 6812710.0000 - val_loss: 1931766.0000\n",
      "Epoch 41/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1857964928.0000 - val_loss: 29766046.0000\n",
      "Epoch 42/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 9993695.0000 - val_loss: 5453021.5000\n",
      "Epoch 43/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 3976224.7500 - val_loss: 1729919.2500\n",
      "Epoch 44/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1898037.5000 - val_loss: 848577.9375\n",
      "Epoch 45/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 3661297920.0000 - val_loss: 28248782.0000\n",
      "Epoch 46/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 14417740.0000 - val_loss: 4605657.0000\n",
      "Epoch 47/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1451010944.0000 - val_loss: 51544816.0000\n",
      "Epoch 48/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 17053818.0000 - val_loss: 7197921.0000\n",
      "Epoch 49/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 6374091.5000 - val_loss: 2972268.7500\n",
      "Epoch 50/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 2688131.7500 - val_loss: 1642406.7500\n",
      "Epoch 51/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 4188629248.0000 - val_loss: 40915763200.0000\n",
      "Epoch 52/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 255669344.0000 - val_loss: 16298579.0000\n",
      "Epoch 53/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 13371728.0000 - val_loss: 6855694.0000\n",
      "Epoch 54/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 8031121408.0000 - val_loss: 98602432.0000\n",
      "Epoch 55/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 62410580.0000 - val_loss: 16074506.0000\n",
      "Epoch 56/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 19537776.0000 - val_loss: 7464451.5000\n",
      "Epoch 57/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 8956002.0000 - val_loss: 5553198.0000\n",
      "Epoch 58/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 2221501696.0000 - val_loss: 17539606.0000\n",
      "Epoch 59/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 11083965.0000 - val_loss: 4779634.5000\n",
      "Epoch 60/60\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 4099760.7500 - val_loss: 2263329.7500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79215e3fff7d4434a7572d23feeb42fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='5.110 MB of 5.110 MB uploaded (0.016 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▁▁▃▁▄▁▃▁▁▁▁▁▁▁▁▁█▁▁▁▅▁▁▅▁▄▁▁▁▄▁▁▁▁▁▁▅▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▃▁▁▁▁▁▂▁▁▁▁▁▂▂▃▂█▂▁▂▁▃▁▁▁▅▁▁▂▂▂▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>1</td></tr><tr><td>best_val_loss</td><td>2.89953</td></tr><tr><td>epoch</td><td>59</td></tr><tr><td>loss</td><td>4099760.75</td></tr><tr><td>val_loss</td><td>2263329.75</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">avid-sweep-57</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/ztstf2yz\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/ztstf2yz</a><br/>Synced 6 W&B file(s), 1 media file(s), 9 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_081828-ztstf2yz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0c7ohp5v with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.47588227533326255\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 53\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.048648499613182045\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 89\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 116\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 242\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 142\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_082231-0c7ohp5v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/0c7ohp5v\" target=\"_blank\">eager-sweep-58</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/53\n",
      "1507/1527 [============================>.] - ETA: 0s - loss: 33.3569INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_082231-0c7ohp5v/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_082231-0c7ohp5v/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 4s 2ms/step - loss: 32.9366 - val_loss: 0.7606\n",
      "Epoch 2/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.8250 - val_loss: 0.7730\n",
      "Epoch 3/53\n",
      "1525/1527 [============================>.] - ETA: 0s - loss: 0.8119INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_082231-0c7ohp5v/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_082231-0c7ohp5v/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.8118 - val_loss: 0.7332\n",
      "Epoch 4/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.8371 - val_loss: 0.7863\n",
      "Epoch 5/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.8714 - val_loss: 0.9908\n",
      "Epoch 6/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 7996960.5000 - val_loss: 37508284.0000\n",
      "Epoch 7/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 530678.5625 - val_loss: 6256.1475\n",
      "Epoch 8/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 13688.6768 - val_loss: 5115.3931\n",
      "Epoch 9/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 6601.1895 - val_loss: 2494.1111\n",
      "Epoch 10/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 3611.8215 - val_loss: 1076.0994\n",
      "Epoch 11/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 9195887.0000 - val_loss: 295944.8438\n",
      "Epoch 12/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 84389.2969 - val_loss: 31680.8770\n",
      "Epoch 13/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 20309.3711 - val_loss: 10810.0820\n",
      "Epoch 14/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 9600.0771 - val_loss: 6347.9399\n",
      "Epoch 15/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 16034487.0000 - val_loss: 78135.6562\n",
      "Epoch 16/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 95222.7578 - val_loss: 158748.8750\n",
      "Epoch 17/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 33588.0508 - val_loss: 10211.2578\n",
      "Epoch 18/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 11833.5322 - val_loss: 4607.9717\n",
      "Epoch 19/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 6007.2480 - val_loss: 3866.5950\n",
      "Epoch 20/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 31439176.0000 - val_loss: 233144.0469\n",
      "Epoch 21/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 211308.1094 - val_loss: 64742.5195\n",
      "Epoch 22/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 77975.4531 - val_loss: 21841.8828\n",
      "Epoch 23/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 35466.8945 - val_loss: 16075.1699\n",
      "Epoch 24/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 16233.7920 - val_loss: 5750.9243\n",
      "Epoch 25/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 25228456.0000 - val_loss: 121828.9609\n",
      "Epoch 26/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 116542.6641 - val_loss: 54681.4141\n",
      "Epoch 27/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 53649.3086 - val_loss: 25785.0000\n",
      "Epoch 28/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 27535.2676 - val_loss: 10847.6816\n",
      "Epoch 29/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 14317.1895 - val_loss: 6480.8335\n",
      "Epoch 30/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 7499.4985 - val_loss: 267322.0312\n",
      "Epoch 31/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 16977666.0000 - val_loss: 74540.7656\n",
      "Epoch 32/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 72488.8672 - val_loss: 27130.0449\n",
      "Epoch 33/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 30003.5234 - val_loss: 15410.0039\n",
      "Epoch 34/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 13133.8945 - val_loss: 6434.0029\n",
      "Epoch 35/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 14947013.0000 - val_loss: 98701.3750\n",
      "Epoch 36/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 109764.3047 - val_loss: 52075.1016\n",
      "Epoch 37/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 45407.5938 - val_loss: 23132.7031\n",
      "Epoch 38/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 24279.8281 - val_loss: 10141.1602\n",
      "Epoch 39/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 25606038.0000 - val_loss: 227660.0938\n",
      "Epoch 40/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 170436.8750 - val_loss: 77517.5391\n",
      "Epoch 41/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 79464.5938 - val_loss: 31827.5312\n",
      "Epoch 42/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 39087.2188 - val_loss: 24745.8906\n",
      "Epoch 43/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 18302.7559 - val_loss: 7147.8130\n",
      "Epoch 44/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 31673042.0000 - val_loss: 575227.1875\n",
      "Epoch 45/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 294468.0312 - val_loss: 103950.4766\n",
      "Epoch 46/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 113714.1172 - val_loss: 52560.4727\n",
      "Epoch 47/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 55787.6562 - val_loss: 19351.6016\n",
      "Epoch 48/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 26607.3516 - val_loss: 12536.2100\n",
      "Epoch 49/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 7339655.0000 - val_loss: 106209.4766\n",
      "Epoch 50/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 93202.7188 - val_loss: 35465.1367\n",
      "Epoch 51/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 35049.1641 - val_loss: 14254.2793\n",
      "Epoch 52/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 15776.0498 - val_loss: 7759.4897\n",
      "Epoch 53/53\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 7283.5786 - val_loss: 3777.8989\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▁▁▃▁▁▁▄▁▁▅▁▁▁▁▁▁█▁▁▁▁▆▁▁▅▁▁█▁▁▁▁▁▁▃▁▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>2</td></tr><tr><td>best_val_loss</td><td>0.73324</td></tr><tr><td>epoch</td><td>52</td></tr><tr><td>loss</td><td>7283.57861</td></tr><tr><td>val_loss</td><td>3777.89893</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">eager-sweep-58</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/0c7ohp5v\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/0c7ohp5v</a><br/>Synced 6 W&B file(s), 1 media file(s), 9 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_082231-0c7ohp5v/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kunht4ak with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5951274739327591\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 22\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.019388922232122265\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 185\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 216\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 154\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 238\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 83\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_082510-kunht4ak</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/kunht4ak\" target=\"_blank\">wild-sweep-59</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/22\n",
      "1145/1146 [============================>.] - ETA: 0s - loss: 1.7904INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_082510-kunht4ak/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_082510-kunht4ak/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 4s 3ms/step - loss: 1.7904 - val_loss: 0.8361\n",
      "Epoch 2/22\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.8292 - val_loss: 0.8454\n",
      "Epoch 3/22\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.8449 - val_loss: 1.1041\n",
      "Epoch 4/22\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.8715 - val_loss: 1.0703\n",
      "Epoch 5/22\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.8688 - val_loss: 0.9165\n",
      "Epoch 6/22\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 46941.0977 - val_loss: 210.6189\n",
      "Epoch 7/22\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 134.2339 - val_loss: 65.2254\n",
      "Epoch 8/22\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 58.9113 - val_loss: 23.7081\n",
      "Epoch 9/22\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 35.1491 - val_loss: 14.2246\n",
      "Epoch 10/22\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 19.8690 - val_loss: 13.4920\n",
      "Epoch 11/22\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 11.4781 - val_loss: 3.8066\n",
      "Epoch 12/22\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 6.8685 - val_loss: 3.9273\n",
      "Epoch 13/22\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 3.9236 - val_loss: 1.8608\n",
      "Epoch 14/22\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2.5638 - val_loss: 1.7006\n",
      "Epoch 15/22\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 65890.3594 - val_loss: 359.7806\n",
      "Epoch 16/22\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 303.9190 - val_loss: 178.1157\n",
      "Epoch 17/22\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 138.3712 - val_loss: 56.3184\n",
      "Epoch 18/22\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 69.0776 - val_loss: 30.8626\n",
      "Epoch 19/22\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 34.1900 - val_loss: 15.2309\n",
      "Epoch 20/22\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 17.5715 - val_loss: 23.4112\n",
      "Epoch 21/22\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 29667.1309 - val_loss: 476.9859\n",
      "Epoch 22/22\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 303.1949 - val_loss: 145.6451\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>loss</td><td>▁▁▁▁▁▆▁▁▁▁▁▁▁▁█▁▁▁▁▁▄▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▄▂▁▁▁▁▁▁▁▆▄▂▁▁▁█▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.83611</td></tr><tr><td>epoch</td><td>21</td></tr><tr><td>loss</td><td>303.19492</td></tr><tr><td>val_loss</td><td>145.64513</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">wild-sweep-59</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/kunht4ak\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/kunht4ak</a><br/>Synced 6 W&B file(s), 1 media file(s), 5 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_082510-kunht4ak/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lefbmacq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.34821398316116386\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 78\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.04535263701987673\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 153\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 153\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 89\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_082616-lefbmacq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/lefbmacq\" target=\"_blank\">stoic-sweep-60</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/78\n",
      "2251/2291 [============================>.] - ETA: 0s - loss: 6.6128INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_082616-lefbmacq/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_082616-lefbmacq/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 6.5147 - val_loss: 0.8463\n",
      "Epoch 2/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.8343 - val_loss: 1.1540\n",
      "Epoch 3/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.9273 - val_loss: 1.0142\n",
      "Epoch 4/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 686030.6250 - val_loss: 1084.9835\n",
      "Epoch 5/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1326.5126 - val_loss: 363.1488\n",
      "Epoch 6/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 295.6414 - val_loss: 71.5661\n",
      "Epoch 7/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1772297.8750 - val_loss: 30245.5449\n",
      "Epoch 8/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 8526.6963 - val_loss: 4018.7432\n",
      "Epoch 9/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2869.6838 - val_loss: 1066.0959\n",
      "Epoch 10/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 6173641.5000 - val_loss: 22085.3438\n",
      "Epoch 11/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 23275.9277 - val_loss: 14773.7578\n",
      "Epoch 12/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 7171.7480 - val_loss: 2517.3486\n",
      "Epoch 13/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2170.8669 - val_loss: 816.8483\n",
      "Epoch 14/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 6771798.5000 - val_loss: 38847.6602\n",
      "Epoch 15/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 21263.0039 - val_loss: 8930.0938\n",
      "Epoch 16/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 8880.6953 - val_loss: 2754.4717\n",
      "Epoch 17/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2766174.0000 - val_loss: 40332.5352\n",
      "Epoch 18/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 14672.9707 - val_loss: 5139.4136\n",
      "Epoch 19/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 5625.0957 - val_loss: 2298.8755\n",
      "Epoch 20/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2177722.5000 - val_loss: 15788.9160\n",
      "Epoch 21/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 10549.1816 - val_loss: 4042.3999\n",
      "Epoch 22/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1947253.8750 - val_loss: 26946.5254\n",
      "Epoch 23/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 16573.9395 - val_loss: 5911.9150\n",
      "Epoch 24/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 5051.2842 - val_loss: 2362.2078\n",
      "Epoch 25/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1195221.5000 - val_loss: 18925.2773\n",
      "Epoch 26/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 11291.0635 - val_loss: 2951.7622\n",
      "Epoch 27/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3329.3198 - val_loss: 1214.2701\n",
      "Epoch 28/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1182.8591 - val_loss: 697.9464\n",
      "Epoch 29/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1712840.5000 - val_loss: 8012.3677\n",
      "Epoch 30/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 7250.8486 - val_loss: 4105.5161\n",
      "Epoch 31/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2508.2651 - val_loss: 824.4834\n",
      "Epoch 32/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2138610.2500 - val_loss: 32760.8145\n",
      "Epoch 33/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 20987.0078 - val_loss: 7179.5386\n",
      "Epoch 34/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 5928.2773 - val_loss: 3919.6704\n",
      "Epoch 35/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1205841.8750 - val_loss: 41801.6406\n",
      "Epoch 36/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 18813.5879 - val_loss: 5838.0620\n",
      "Epoch 37/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 5143.5088 - val_loss: 1497.9852\n",
      "Epoch 38/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2806377.7500 - val_loss: 39758.0938\n",
      "Epoch 39/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 27510.1172 - val_loss: 9107.2686\n",
      "Epoch 40/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 9344.7041 - val_loss: 3981.9690\n",
      "Epoch 41/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1465199.8750 - val_loss: 93659.4844\n",
      "Epoch 42/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 32718.3457 - val_loss: 14083.7988\n",
      "Epoch 43/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 7603.2900 - val_loss: 3064.8103\n",
      "Epoch 44/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2244.7507 - val_loss: 627.4050\n",
      "Epoch 45/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 606.1968 - val_loss: 260.6584\n",
      "Epoch 46/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 887237.3750 - val_loss: 8951.9971\n",
      "Epoch 47/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 6190.7246 - val_loss: 3076.9343\n",
      "Epoch 48/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2116.1289 - val_loss: 869.4748\n",
      "Epoch 49/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2568190.7500 - val_loss: 121338.1484\n",
      "Epoch 50/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 45963.0000 - val_loss: 12286.6660\n",
      "Epoch 51/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 12076.8633 - val_loss: 8339.6406\n",
      "Epoch 52/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2102834.5000 - val_loss: 112825.3594\n",
      "Epoch 53/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 47931.2969 - val_loss: 16135.1191\n",
      "Epoch 54/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 10771.7334 - val_loss: 4760.6284\n",
      "Epoch 55/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3719.8284 - val_loss: 21412.8262\n",
      "Epoch 56/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1501.6514 - val_loss: 1548.9629\n",
      "Epoch 57/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1875835.0000 - val_loss: 11177.6250\n",
      "Epoch 58/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 11877.5371 - val_loss: 3697.3784\n",
      "Epoch 59/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 4352.5889 - val_loss: 1974.8833\n",
      "Epoch 60/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3944621.7500 - val_loss: 26204.6934\n",
      "Epoch 61/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 22728.3047 - val_loss: 11958.0205\n",
      "Epoch 62/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 7971.4487 - val_loss: 2768.6619\n",
      "Epoch 63/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1735589.1250 - val_loss: 67695.9141\n",
      "Epoch 64/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 39614.6094 - val_loss: 8709.2510\n",
      "Epoch 65/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 8297.6562 - val_loss: 3934.1560\n",
      "Epoch 66/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2521118.7500 - val_loss: 29948.2422\n",
      "Epoch 67/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 22838.5117 - val_loss: 9777.8213\n",
      "Epoch 68/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 7580.7070 - val_loss: 2399.3801\n",
      "Epoch 69/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2809.3635 - val_loss: 1056.3815\n",
      "Epoch 70/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1946527.0000 - val_loss: 14856.3350\n",
      "Epoch 71/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 11965.6982 - val_loss: 3825.1602\n",
      "Epoch 72/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 4120.4507 - val_loss: 1874.5129\n",
      "Epoch 73/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1564.8474 - val_loss: 539.2155\n",
      "Epoch 74/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2016942.0000 - val_loss: 26721.2285\n",
      "Epoch 75/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 14035.6270 - val_loss: 12271.2529\n",
      "Epoch 76/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 4849.7896 - val_loss: 2473.5476\n",
      "Epoch 77/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1874.6997 - val_loss: 855.3846\n",
      "Epoch 78/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3831771.2500 - val_loss: 24431.2402\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▂▁▁▇▁█▁▁▃▃▁▁▁▁▃▁▁▄▁▁▁▂▁▁▃▁▁▁▅▁▁▄▁▃▁▃▁▅</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▂▁▃▁▁▂▃▁▁▁▁▃▁▁▃▁▂▁▂▁▂█▁▁▁▃▁▂▃▁▂▁▃▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.84632</td></tr><tr><td>epoch</td><td>77</td></tr><tr><td>loss</td><td>3831771.25</td></tr><tr><td>val_loss</td><td>24431.24023</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">stoic-sweep-60</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/lefbmacq\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/lefbmacq</a><br/>Synced 6 W&B file(s), 1 media file(s), 5 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_082616-lefbmacq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: epn2qrhn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.12406113648898376\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 91\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0948014443735528\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 73\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 152\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 115\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 80\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 169\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_083002-epn2qrhn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/epn2qrhn\" target=\"_blank\">worthy-sweep-61</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/91\n",
      "1518/1527 [============================>.] - ETA: 0s - loss: 445.4742INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_083002-epn2qrhn/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_083002-epn2qrhn/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 3s 2ms/step - loss: 442.9312 - val_loss: 1.2154\n",
      "Epoch 2/91\n",
      "1520/1527 [============================>.] - ETA: 0s - loss: 1.0349INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_083002-epn2qrhn/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_083002-epn2qrhn/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1.0347 - val_loss: 0.8197\n",
      "Epoch 3/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 0.8827 - val_loss: 0.8243\n",
      "Epoch 4/91\n",
      "1525/1527 [============================>.] - ETA: 0s - loss: 0.8191INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_083002-epn2qrhn/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_083002-epn2qrhn/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.8190 - val_loss: 0.7597\n",
      "Epoch 5/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 0.7897 - val_loss: 0.8178\n",
      "Epoch 6/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 1443635456.0000 - val_loss: 13316683.0000\n",
      "Epoch 7/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 4276099.5000 - val_loss: 1909868.8750\n",
      "Epoch 8/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 1247288.7500 - val_loss: 363526.5312\n",
      "Epoch 9/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 639994.0000 - val_loss: 192105.3906\n",
      "Epoch 10/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 322983.7188 - val_loss: 188091.7969\n",
      "Epoch 11/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 97021008.0000 - val_loss: 181295.0781\n",
      "Epoch 12/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 198990.7344 - val_loss: 81840.3047\n",
      "Epoch 13/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 85388.7422 - val_loss: 95194.2500\n",
      "Epoch 14/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 72656.3828 - val_loss: 11636.2246\n",
      "Epoch 15/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 356821984.0000 - val_loss: 1452920.0000\n",
      "Epoch 16/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 1299424.8750 - val_loss: 781028.4375\n",
      "Epoch 17/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 517820.6875 - val_loss: 164958.3438\n",
      "Epoch 18/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 242535.5625 - val_loss: 196376.9375\n",
      "Epoch 19/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 2719300352.0000 - val_loss: 30955152.0000\n",
      "Epoch 20/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 17272964.0000 - val_loss: 4385668.0000\n",
      "Epoch 21/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 6184719.0000 - val_loss: 2918299.7500\n",
      "Epoch 22/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 4435354.5000 - val_loss: 1818260.2500\n",
      "Epoch 23/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 213582304.0000 - val_loss: 1402693.7500\n",
      "Epoch 24/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 1118168.0000 - val_loss: 453943.4688\n",
      "Epoch 25/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 502755.3438 - val_loss: 326244.0312\n",
      "Epoch 26/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 247550.8594 - val_loss: 114671.3750\n",
      "Epoch 27/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 1189927424.0000 - val_loss: 9614580.0000\n",
      "Epoch 28/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 6573337.0000 - val_loss: 1522710.2500\n",
      "Epoch 29/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 2482334.0000 - val_loss: 1463193.5000\n",
      "Epoch 30/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 1364962.2500 - val_loss: 719114.9375\n",
      "Epoch 31/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 340632832.0000 - val_loss: 2953371.0000\n",
      "Epoch 32/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 2119834.5000 - val_loss: 815202.7500\n",
      "Epoch 33/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 1055547.5000 - val_loss: 669514.9375\n",
      "Epoch 34/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 447708.1562 - val_loss: 267027.0312\n",
      "Epoch 35/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 246646.1406 - val_loss: 109941.2031\n",
      "Epoch 36/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 622250944.0000 - val_loss: 2786524.5000\n",
      "Epoch 37/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 2379317.7500 - val_loss: 884822.5625\n",
      "Epoch 38/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 1097225.8750 - val_loss: 635892.6250\n",
      "Epoch 39/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 554993.3125 - val_loss: 317813.2812\n",
      "Epoch 40/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 349575.0312 - val_loss: 143319.8906\n",
      "Epoch 41/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 295845248.0000 - val_loss: 1270835.7500\n",
      "Epoch 42/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 1644340.2500 - val_loss: 732797.3125\n",
      "Epoch 43/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 796332.0000 - val_loss: 384851.9688\n",
      "Epoch 44/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 420384.8125 - val_loss: 273781.9688\n",
      "Epoch 45/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 529051616.0000 - val_loss: 13761475.0000\n",
      "Epoch 46/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 3592128.2500 - val_loss: 3213774.2500\n",
      "Epoch 47/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 1498046.8750 - val_loss: 1133812.3750\n",
      "Epoch 48/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 902703.7500 - val_loss: 979297.0000\n",
      "Epoch 49/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 334729.0938 - val_loss: 324016.2188\n",
      "Epoch 50/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 763073920.0000 - val_loss: 5393843.0000\n",
      "Epoch 51/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 4709666.0000 - val_loss: 2172580.7500\n",
      "Epoch 52/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 2908544.5000 - val_loss: 1013195.6250\n",
      "Epoch 53/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 1135811.7500 - val_loss: 489329.7500\n",
      "Epoch 54/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 606527.6250 - val_loss: 385014.4375\n",
      "Epoch 55/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 989294528.0000 - val_loss: 4956864.0000\n",
      "Epoch 56/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 4456694.5000 - val_loss: 2296730.5000\n",
      "Epoch 57/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 2038846.2500 - val_loss: 812388.0000\n",
      "Epoch 58/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 1145778.6250 - val_loss: 623410.4375\n",
      "Epoch 59/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 595760.6875 - val_loss: 248903.5938\n",
      "Epoch 60/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 365078.4375 - val_loss: 229639.9219\n",
      "Epoch 61/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 830787392.0000 - val_loss: 12652758.0000\n",
      "Epoch 62/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 9761100.0000 - val_loss: 2382502.5000\n",
      "Epoch 63/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 3329196.2500 - val_loss: 2569340.0000\n",
      "Epoch 64/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 1472662.0000 - val_loss: 696631.8750\n",
      "Epoch 65/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 773906.4375 - val_loss: 332506.9688\n",
      "Epoch 66/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 397782.3750 - val_loss: 190954.6875\n",
      "Epoch 67/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 218340.4688 - val_loss: 327758.5625\n",
      "Epoch 68/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 1051913472.0000 - val_loss: 8351853.5000\n",
      "Epoch 69/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 5472306.0000 - val_loss: 2169749.2500\n",
      "Epoch 70/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 2419109.7500 - val_loss: 963647.8750\n",
      "Epoch 71/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 1804516.7500 - val_loss: 577923.2500\n",
      "Epoch 72/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 767677248.0000 - val_loss: 38885080.0000\n",
      "Epoch 73/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 10672974.0000 - val_loss: 4907223.0000\n",
      "Epoch 74/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 3403874.0000 - val_loss: 1630318.5000\n",
      "Epoch 75/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 1985337.8750 - val_loss: 1543525.3750\n",
      "Epoch 76/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 1351362.6250 - val_loss: 670202.7500\n",
      "Epoch 77/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 1702565760.0000 - val_loss: 10994034.0000\n",
      "Epoch 78/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 12768478.0000 - val_loss: 7965019.0000\n",
      "Epoch 79/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 6698895.0000 - val_loss: 2381183.2500\n",
      "Epoch 80/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 3096991.7500 - val_loss: 1534305.6250\n",
      "Epoch 81/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 1680094.1250 - val_loss: 900405.5625\n",
      "Epoch 82/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 834663.0000 - val_loss: 530672.1875\n",
      "Epoch 83/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 577207424.0000 - val_loss: 6422312.5000\n",
      "Epoch 84/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 5076610.5000 - val_loss: 3065057.2500\n",
      "Epoch 85/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 2312919.0000 - val_loss: 1073676.3750\n",
      "Epoch 86/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 1282268.7500 - val_loss: 666730.2500\n",
      "Epoch 87/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 722328.0000 - val_loss: 477295.0625\n",
      "Epoch 88/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 293879616.0000 - val_loss: 35469200.0000\n",
      "Epoch 89/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 7411253.0000 - val_loss: 1625506.7500\n",
      "Epoch 90/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 1558645.3750 - val_loss: 976951.8750\n",
      "Epoch 91/91\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 771576.3750 - val_loss: 414406.8125\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>loss</td><td>▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▁▅▁▁▁▁▂▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▇▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▃▁▁▂▁▇▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>3</td></tr><tr><td>best_val_loss</td><td>0.75971</td></tr><tr><td>epoch</td><td>90</td></tr><tr><td>loss</td><td>771576.375</td></tr><tr><td>val_loss</td><td>414406.8125</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">worthy-sweep-61</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/epn2qrhn\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/epn2qrhn</a><br/>Synced 6 W&B file(s), 1 media file(s), 13 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_083002-epn2qrhn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7qt07e0i with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.21086763827743796\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 85\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.03447637863729326\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 217\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 101\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 198\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 94\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_083322-7qt07e0i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/7qt07e0i\" target=\"_blank\">eternal-sweep-62</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/85\n",
      "2268/2291 [============================>.] - ETA: 0s - loss: 4.9939INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_083322-7qt07e0i/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_083322-7qt07e0i/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 5s 2ms/step - loss: 4.9538 - val_loss: 0.7479\n",
      "Epoch 2/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.8249 - val_loss: 0.7657\n",
      "Epoch 3/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 308330.9375 - val_loss: 2241.3101\n",
      "Epoch 4/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1342.1465 - val_loss: 396.9772\n",
      "Epoch 5/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 296.5224 - val_loss: 98.2569\n",
      "Epoch 6/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 91.0008 - val_loss: 51.2082\n",
      "Epoch 7/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 39.6240 - val_loss: 12.9854\n",
      "Epoch 8/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 387492.7812 - val_loss: 3736.2324\n",
      "Epoch 9/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1312.0900 - val_loss: 513.9943\n",
      "Epoch 10/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1133492.2500 - val_loss: 21559.9941\n",
      "Epoch 11/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 8923.7559 - val_loss: 4159.2661\n",
      "Epoch 12/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2178.0381 - val_loss: 1889.3923\n",
      "Epoch 13/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 834.4487 - val_loss: 493.7171\n",
      "Epoch 14/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 606282.8125 - val_loss: 6763.5537\n",
      "Epoch 15/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2926.6904 - val_loss: 1945.2113\n",
      "Epoch 16/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1075.3318 - val_loss: 725.3137\n",
      "Epoch 17/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 974796.0625 - val_loss: 49530.8008\n",
      "Epoch 18/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 15392.5820 - val_loss: 4784.9849\n",
      "Epoch 19/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2739.2139 - val_loss: 1036.0762\n",
      "Epoch 20/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 885.4740 - val_loss: 384.1860\n",
      "Epoch 21/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1686739.5000 - val_loss: 19454.1445\n",
      "Epoch 22/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 12090.8027 - val_loss: 5766.9585\n",
      "Epoch 23/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3893.2434 - val_loss: 5294.2339\n",
      "Epoch 24/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1097296.5000 - val_loss: 44766.4102\n",
      "Epoch 25/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 13119.1533 - val_loss: 4718.0615\n",
      "Epoch 26/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3259.5605 - val_loss: 1039.1705\n",
      "Epoch 27/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1231.9211 - val_loss: 698.8476\n",
      "Epoch 28/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 989824.8125 - val_loss: 13893.3535\n",
      "Epoch 29/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 8718.7314 - val_loss: 3322.8342\n",
      "Epoch 30/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2800.3127 - val_loss: 1116.1110\n",
      "Epoch 31/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 430057.0938 - val_loss: 630361.8125\n",
      "Epoch 32/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 15347.1240 - val_loss: 1998.5439\n",
      "Epoch 33/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2197.2898 - val_loss: 2646.1926\n",
      "Epoch 34/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1223792.1250 - val_loss: 8203.3125\n",
      "Epoch 35/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 6068.2515 - val_loss: 4220.8188\n",
      "Epoch 36/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2446.6250 - val_loss: 1025.8984\n",
      "Epoch 37/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 924531.2500 - val_loss: 8828.5684\n",
      "Epoch 38/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 5204.9629 - val_loss: 7253.3086\n",
      "Epoch 39/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2401.0159 - val_loss: 699.8547\n",
      "Epoch 40/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 601.0009 - val_loss: 257.9501\n",
      "Epoch 41/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1798952.6250 - val_loss: 9571.8203\n",
      "Epoch 42/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 10464.2549 - val_loss: 4822.5005\n",
      "Epoch 43/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1022900.3125 - val_loss: 6568.3750\n",
      "Epoch 44/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 6276.2271 - val_loss: 2625.9111\n",
      "Epoch 45/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2603.4155 - val_loss: 1604.8086\n",
      "Epoch 46/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 4203100.5000 - val_loss: 80164.2422\n",
      "Epoch 47/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 53692.1523 - val_loss: 15378.6143\n",
      "Epoch 48/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 14769.1953 - val_loss: 4845.0894\n",
      "Epoch 49/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 4542.5532 - val_loss: 1389.4459\n",
      "Epoch 50/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1302026.1250 - val_loss: 8616.4219\n",
      "Epoch 51/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 10012.7461 - val_loss: 2965.0459\n",
      "Epoch 52/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 795007.8125 - val_loss: 22303.8438\n",
      "Epoch 53/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 11271.6992 - val_loss: 4416.9863\n",
      "Epoch 54/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3800.5867 - val_loss: 2332.8625\n",
      "Epoch 55/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1631.2013 - val_loss: 496.9441\n",
      "Epoch 56/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 601988.8750 - val_loss: 8351.1172\n",
      "Epoch 57/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 6878.8213 - val_loss: 3547.2593\n",
      "Epoch 58/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2525.6934 - val_loss: 1389.3190\n",
      "Epoch 59/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1175.9913 - val_loss: 1220.0171\n",
      "Epoch 60/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 935406.7500 - val_loss: 7209.5293\n",
      "Epoch 61/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 5586.9028 - val_loss: 3484.7795\n",
      "Epoch 62/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2087.2385 - val_loss: 758.5712\n",
      "Epoch 63/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 819.6589 - val_loss: 295.3000\n",
      "Epoch 64/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 406819.0625 - val_loss: 4710.6479\n",
      "Epoch 65/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3367.6279 - val_loss: 1359.4337\n",
      "Epoch 66/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1286.7885 - val_loss: 623.1719\n",
      "Epoch 67/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1014594.1250 - val_loss: 12989.9648\n",
      "Epoch 68/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 7895.9365 - val_loss: 3488.5735\n",
      "Epoch 69/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2837.3652 - val_loss: 1433.1602\n",
      "Epoch 70/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1074.4437 - val_loss: 473.0049\n",
      "Epoch 71/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 449.0205 - val_loss: 294.1996\n",
      "Epoch 72/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1293870.5000 - val_loss: 9622.5986\n",
      "Epoch 73/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 6844.6226 - val_loss: 3452.5559\n",
      "Epoch 74/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 315656.7500 - val_loss: 9309.1133\n",
      "Epoch 75/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 5274.3555 - val_loss: 1739.6987\n",
      "Epoch 76/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1592.8881 - val_loss: 648.0117\n",
      "Epoch 77/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 600.5367 - val_loss: 271.2664\n",
      "Epoch 78/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 692234.8125 - val_loss: 3785.8472\n",
      "Epoch 79/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3648.4541 - val_loss: 1504.6211\n",
      "Epoch 80/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1787.8018 - val_loss: 606.3339\n",
      "Epoch 81/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 15113.5820 - val_loss: 13559278.0000\n",
      "Epoch 82/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 549194.8750 - val_loss: 4278.8740\n",
      "Epoch 83/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3673.9695 - val_loss: 1902.3867\n",
      "Epoch 84/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 919928.5625 - val_loss: 824865.2500\n",
      "Epoch 85/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 34908.2695 - val_loss: 6946.8149\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▂▁▁▁▁▁▁▁▁▁▃▁▁▂▁▁▃▁▄▁█▁▃▂▁▁▁▁▁▁▃▁▃▂▁▂▁▂▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.74785</td></tr><tr><td>epoch</td><td>84</td></tr><tr><td>loss</td><td>34908.26953</td></tr><tr><td>val_loss</td><td>6946.81494</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">eternal-sweep-62</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/7qt07e0i\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/7qt07e0i</a><br/>Synced 6 W&B file(s), 1 media file(s), 5 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_083322-7qt07e0i/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: n8gfrog9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3926357242678766\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.05184075919783803\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 151\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 104\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 215\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 201\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 202\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_083749-n8gfrog9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/n8gfrog9\" target=\"_blank\">brisk-sweep-63</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/99\n",
      "2267/2291 [============================>.] - ETA: 0s - loss: 123.5293INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_083749-n8gfrog9/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_083749-n8gfrog9/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 5s 2ms/step - loss: 122.2916 - val_loss: 0.8128\n",
      "Epoch 2/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 0.8498 - val_loss: 0.8453\n",
      "Epoch 3/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 0.8269 - val_loss: 0.8676\n",
      "Epoch 4/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 0.8656 - val_loss: 0.8785\n",
      "Epoch 5/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 21961072.0000 - val_loss: 318213.0000\n",
      "Epoch 6/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 113662.7109 - val_loss: 24536.1152\n",
      "Epoch 7/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 22572.2637 - val_loss: 7816.3184\n",
      "Epoch 8/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 6799.4580 - val_loss: 2267.7561\n",
      "Epoch 9/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 21619204.0000 - val_loss: 647124.5000\n",
      "Epoch 10/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 116504.7969 - val_loss: 45541.8477\n",
      "Epoch 11/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 38181.5469 - val_loss: 15044.2656\n",
      "Epoch 12/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 48585256.0000 - val_loss: 214564.5312\n",
      "Epoch 13/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 221101.7344 - val_loss: 86062.7031\n",
      "Epoch 14/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 70622.5625 - val_loss: 33363.5508\n",
      "Epoch 15/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 16970910.0000 - val_loss: 97887.7422\n",
      "Epoch 16/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 66758.1094 - val_loss: 23005.5723\n",
      "Epoch 17/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 24122776.0000 - val_loss: 798579.3750\n",
      "Epoch 18/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 369593.3125 - val_loss: 141569.7656\n",
      "Epoch 19/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 90283.1328 - val_loss: 32467.8945\n",
      "Epoch 20/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 31437438.0000 - val_loss: 34742556.0000\n",
      "Epoch 21/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1212837.8750 - val_loss: 157253.8125\n",
      "Epoch 22/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 146115.2188 - val_loss: 46819.4766\n",
      "Epoch 23/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 45894.0508 - val_loss: 19992.4043\n",
      "Epoch 24/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 19778134.0000 - val_loss: 153781.9219\n",
      "Epoch 25/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 110342.1641 - val_loss: 54011.8164\n",
      "Epoch 26/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 38551.2656 - val_loss: 12996.7236\n",
      "Epoch 27/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 12531.2939 - val_loss: 5102.9878\n",
      "Epoch 28/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 19665022.0000 - val_loss: 87337.6406\n",
      "Epoch 29/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 90872.1094 - val_loss: 31087.6758\n",
      "Epoch 30/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 6450124.5000 - val_loss: 6536930.5000\n",
      "Epoch 31/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 189519.6406 - val_loss: 36134.7500\n",
      "Epoch 32/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 28117.6133 - val_loss: 13384.8555\n",
      "Epoch 33/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 11082.8428 - val_loss: 4869.4756\n",
      "Epoch 34/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 20382834.0000 - val_loss: 99220.4766\n",
      "Epoch 35/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 89731.4141 - val_loss: 46145.1875\n",
      "Epoch 36/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 45379728.0000 - val_loss: 12354310.0000\n",
      "Epoch 37/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 914018.6875 - val_loss: 196930.6406\n",
      "Epoch 38/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 157194.0938 - val_loss: 56184.8633\n",
      "Epoch 39/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 52194.9023 - val_loss: 17058.6523\n",
      "Epoch 40/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 13303737.0000 - val_loss: 372844.2500\n",
      "Epoch 41/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 174988.3281 - val_loss: 75556.9062\n",
      "Epoch 42/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 52640.1055 - val_loss: 21824.1152\n",
      "Epoch 43/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 20900.0371 - val_loss: 6632.8867\n",
      "Epoch 44/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 36057416.0000 - val_loss: 2559716.2500\n",
      "Epoch 45/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 496021.3750 - val_loss: 177879.3125\n",
      "Epoch 46/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 116152.4844 - val_loss: 62463.4219\n",
      "Epoch 47/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 45784.8516 - val_loss: 24821.5137\n",
      "Epoch 48/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 30148866.0000 - val_loss: 370429.4062\n",
      "Epoch 49/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 232334.3594 - val_loss: 77451.4531\n",
      "Epoch 50/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 79520.3438 - val_loss: 27410.7070\n",
      "Epoch 51/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 29794.7480 - val_loss: 24088.1953\n",
      "Epoch 52/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 14271.5684 - val_loss: 4780.6284\n",
      "Epoch 53/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 24059472.0000 - val_loss: 309662.9688\n",
      "Epoch 54/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 175769.6094 - val_loss: 79453.0781\n",
      "Epoch 55/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 52818.2891 - val_loss: 16343.2246\n",
      "Epoch 56/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 18744.9648 - val_loss: 10196.0449\n",
      "Epoch 57/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 61167380.0000 - val_loss: 288789.8125\n",
      "Epoch 58/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 323311.5312 - val_loss: 205745.4062\n",
      "Epoch 59/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 126899.0781 - val_loss: 39094.4844\n",
      "Epoch 60/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 8617000.0000 - val_loss: 160859.9219\n",
      "Epoch 61/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 95244.4609 - val_loss: 29169.3398\n",
      "Epoch 62/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 30250.9141 - val_loss: 15411.3828\n",
      "Epoch 63/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 39720984.0000 - val_loss: 288729.2812\n",
      "Epoch 64/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 296152.3438 - val_loss: 97078.8672\n",
      "Epoch 65/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 111113.2266 - val_loss: 50593.1172\n",
      "Epoch 66/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 57552.3906 - val_loss: 31474.0195\n",
      "Epoch 67/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 22913.8066 - val_loss: 6742.5020\n",
      "Epoch 68/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 43421740.0000 - val_loss: 237661.9062\n",
      "Epoch 69/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 186784.6562 - val_loss: 70580.3828\n",
      "Epoch 70/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 75201.7812 - val_loss: 45157.3555\n",
      "Epoch 71/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 234797584.0000 - val_loss: 3542385.5000\n",
      "Epoch 72/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 2061305.6250 - val_loss: 610919.8750\n",
      "Epoch 73/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 593141.1875 - val_loss: 203060.7188\n",
      "Epoch 74/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 163921.4219 - val_loss: 132483.9531\n",
      "Epoch 75/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 44137868.0000 - val_loss: 339510.0312\n",
      "Epoch 76/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 288745.6562 - val_loss: 108899.5234\n",
      "Epoch 77/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 85197616.0000 - val_loss: 3741601.5000\n",
      "Epoch 78/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1207846.1250 - val_loss: 465121.0625\n",
      "Epoch 79/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 282797.7500 - val_loss: 104050.4297\n",
      "Epoch 80/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 27915732.0000 - val_loss: 2383895.2500\n",
      "Epoch 81/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 746724.0000 - val_loss: 183755.7656\n",
      "Epoch 82/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 193383.0781 - val_loss: 110542.7266\n",
      "Epoch 83/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 51694276.0000 - val_loss: 804469.2500\n",
      "Epoch 84/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 505466.2500 - val_loss: 328958.8438\n",
      "Epoch 85/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 196068.5469 - val_loss: 88532.2969\n",
      "Epoch 86/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 84829.6406 - val_loss: 52372.4023\n",
      "Epoch 87/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 66304564.0000 - val_loss: 951921.0625\n",
      "Epoch 88/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 613554.9375 - val_loss: 338540.7188\n",
      "Epoch 89/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 242148.9219 - val_loss: 63146.5703\n",
      "Epoch 90/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 87687.1406 - val_loss: 49987.9062\n",
      "Epoch 91/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 59327000.0000 - val_loss: 453422.6875\n",
      "Epoch 92/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 360981.3125 - val_loss: 141746.0625\n",
      "Epoch 93/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 37791340.0000 - val_loss: 6217688.0000\n",
      "Epoch 94/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 777447.5625 - val_loss: 176048.3438\n",
      "Epoch 95/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 160159.9375 - val_loss: 71736.0312\n",
      "Epoch 96/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 62282.9375 - val_loss: 31821.7559\n",
      "Epoch 97/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 31838484.0000 - val_loss: 324804.2188\n",
      "Epoch 98/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 256824.9844 - val_loss: 95922.6328\n",
      "Epoch 99/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 106300.2891 - val_loss: 48358.8086\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "277c3c0f1f4b4076aa7b61077f8abf8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.259 MB of 3.259 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▂▁▁▂▁▁▁▁▂▁▂▁▁▁▂▁▂█▁▁▁▁▃▁▁▃▂▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▃▁▁▁▁▁▁▁▁▅▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.81281</td></tr><tr><td>epoch</td><td>98</td></tr><tr><td>loss</td><td>106300.28906</td></tr><tr><td>val_loss</td><td>48358.80859</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">brisk-sweep-63</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/n8gfrog9\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/n8gfrog9</a><br/>Synced 6 W&B file(s), 1 media file(s), 5 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_083749-n8gfrog9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vlo8olpd with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3209144299467145\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 83\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.04462486062042571\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 216\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 248\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 78\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 104\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_084405-vlo8olpd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/vlo8olpd\" target=\"_blank\">warm-sweep-64</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/83\n",
      "1501/1527 [============================>.] - ETA: 0s - loss: 92.0174INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_084405-vlo8olpd/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_084405-vlo8olpd/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 4s 2ms/step - loss: 90.4809 - val_loss: 0.8232\n",
      "Epoch 2/83\n",
      "1515/1527 [============================>.] - ETA: 0s - loss: 0.8647INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_084405-vlo8olpd/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_084405-vlo8olpd/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 4s 2ms/step - loss: 0.8644 - val_loss: 0.7920\n",
      "Epoch 3/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 4299764.5000 - val_loss: 5452.5684\n",
      "Epoch 4/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 7166.7661 - val_loss: 2630.5784\n",
      "Epoch 5/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 3995.1721 - val_loss: 3226.5618\n",
      "Epoch 6/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 2474.2256 - val_loss: 736.8691\n",
      "Epoch 7/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1058.8896 - val_loss: 432.6299\n",
      "Epoch 8/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 5851828.0000 - val_loss: 15225.2998\n",
      "Epoch 9/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 14596.2559 - val_loss: 6372.4780\n",
      "Epoch 10/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 7152.3135 - val_loss: 3113.2786\n",
      "Epoch 11/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 2978.3760 - val_loss: 1008.3672\n",
      "Epoch 12/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1362.2903 - val_loss: 817.5147\n",
      "Epoch 13/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 7326957.0000 - val_loss: 22624.1484\n",
      "Epoch 14/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 26010.2734 - val_loss: 14814.7490\n",
      "Epoch 15/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 10495.1240 - val_loss: 4505.7876\n",
      "Epoch 16/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 9574059.0000 - val_loss: 77887.1172\n",
      "Epoch 17/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 107806.9766 - val_loss: 17950.8008\n",
      "Epoch 18/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 14532.7393 - val_loss: 6960.0308\n",
      "Epoch 19/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 11969.7451 - val_loss: 3167.7698\n",
      "Epoch 20/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 37661956.0000 - val_loss: 219082.9531\n",
      "Epoch 21/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 156147.0469 - val_loss: 51376.1602\n",
      "Epoch 22/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 203758.7344 - val_loss: 21064.8711\n",
      "Epoch 23/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 16829970.0000 - val_loss: 364809.3750\n",
      "Epoch 24/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 176032.2344 - val_loss: 50554.0273\n",
      "Epoch 25/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 54991.9727 - val_loss: 35284.8633\n",
      "Epoch 26/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 25531.8535 - val_loss: 10958.5703\n",
      "Epoch 27/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 11908.2881 - val_loss: 5231.6587\n",
      "Epoch 28/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 6039.9038 - val_loss: 2897.9978\n",
      "Epoch 29/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 40892996.0000 - val_loss: 617780.0625\n",
      "Epoch 30/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 255380.6094 - val_loss: 85345.5000\n",
      "Epoch 31/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 109499.0391 - val_loss: 52111.8398\n",
      "Epoch 32/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 54629.3438 - val_loss: 25144.4297\n",
      "Epoch 33/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 24392.4883 - val_loss: 12829.4043\n",
      "Epoch 34/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 11102052.0000 - val_loss: 313902.4688\n",
      "Epoch 35/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 108417.2656 - val_loss: 49875.0664\n",
      "Epoch 36/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 37948.0430 - val_loss: 22026.2559\n",
      "Epoch 37/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 17031.3359 - val_loss: 7681.7563\n",
      "Epoch 38/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 7996.1289 - val_loss: 3026.7859\n",
      "Epoch 39/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 3743.8706 - val_loss: 1837.5270\n",
      "Epoch 40/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 17377268.0000 - val_loss: 87796.2031\n",
      "Epoch 41/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 80788.9609 - val_loss: 32913.3867\n",
      "Epoch 42/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 37815.9336 - val_loss: 13087.3125\n",
      "Epoch 43/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 16667.1035 - val_loss: 5849.8892\n",
      "Epoch 44/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 8135.0752 - val_loss: 3298.9612\n",
      "Epoch 45/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 18062730.0000 - val_loss: 54190.5859\n",
      "Epoch 46/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 68358.8594 - val_loss: 28152.9980\n",
      "Epoch 47/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 33766.3945 - val_loss: 18334.7031\n",
      "Epoch 48/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 17678.9746 - val_loss: 6632.9062\n",
      "Epoch 49/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 8719.2490 - val_loss: 4971.1719\n",
      "Epoch 50/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 9730283.0000 - val_loss: 51821.9219\n",
      "Epoch 51/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 52582.9023 - val_loss: 17142.1934\n",
      "Epoch 52/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 20505.2129 - val_loss: 7825.7241\n",
      "Epoch 53/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 10354.9990 - val_loss: 4892.7637\n",
      "Epoch 54/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 5715.7153 - val_loss: 8830.0527\n",
      "Epoch 55/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 19035270.0000 - val_loss: 94689.6016\n",
      "Epoch 56/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 71688.7969 - val_loss: 27929.3477\n",
      "Epoch 57/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 30105.5176 - val_loss: 29592.6035\n",
      "Epoch 58/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 15519.2539 - val_loss: 8969.5098\n",
      "Epoch 59/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 7808.9438 - val_loss: 3363.3865\n",
      "Epoch 60/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 14914503.0000 - val_loss: 170064.4375\n",
      "Epoch 61/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 153609.2969 - val_loss: 48717.4531\n",
      "Epoch 62/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 65916.1953 - val_loss: 23105.2109\n",
      "Epoch 63/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 33544.0508 - val_loss: 18639.5293\n",
      "Epoch 64/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 19192.1172 - val_loss: 9073.0225\n",
      "Epoch 65/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 52187592.0000 - val_loss: 775222.1875\n",
      "Epoch 66/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 399985.2812 - val_loss: 155289.2500\n",
      "Epoch 67/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 169885.0000 - val_loss: 75040.0078\n",
      "Epoch 68/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 90007.0859 - val_loss: 65860.0938\n",
      "Epoch 69/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 44418.7461 - val_loss: 20559.7441\n",
      "Epoch 70/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 13018056.0000 - val_loss: 218295.9062\n",
      "Epoch 71/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 154526.8438 - val_loss: 58263.0742\n",
      "Epoch 72/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 60242.3125 - val_loss: 29525.6504\n",
      "Epoch 73/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 26947.4531 - val_loss: 11105.9922\n",
      "Epoch 74/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 11950.8838 - val_loss: 4351.4609\n",
      "Epoch 75/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 5444.9619 - val_loss: 2677.8118\n",
      "Epoch 76/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 3273.2847 - val_loss: 1348.8671\n",
      "Epoch 77/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 11225738.0000 - val_loss: 58057.7969\n",
      "Epoch 78/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 41857.3711 - val_loss: 20422.5547\n",
      "Epoch 79/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 23349.1055 - val_loss: 10226.1318\n",
      "Epoch 80/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 12769.8955 - val_loss: 5630.1509\n",
      "Epoch 81/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 7150.2339 - val_loss: 2954.2334\n",
      "Epoch 82/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 21288576.0000 - val_loss: 773221.9375\n",
      "Epoch 83/83\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 292085.2188 - val_loss: 66234.7500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▃▁▁▁▁▄▁▁▁▁▁▁▁▁▁▅▁▁▇▁█▁▁▁▁█▁▁▁▁▁▁▆▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▂▁▁▁▁▂▁▁▃▂█▁▁▃▁▂▁▁▁▁▃▂▁▂▁▄▂▆▂▁▁▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>1</td></tr><tr><td>best_val_loss</td><td>0.79203</td></tr><tr><td>epoch</td><td>82</td></tr><tr><td>loss</td><td>292085.21875</td></tr><tr><td>val_loss</td><td>66234.75</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">warm-sweep-64</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/vlo8olpd\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/vlo8olpd</a><br/>Synced 6 W&B file(s), 1 media file(s), 9 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_084405-vlo8olpd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rs9bupu1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.02303398085966164\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 93\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.07404084312483625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 78\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 143\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 112\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 143\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 238\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_084816-rs9bupu1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/rs9bupu1\" target=\"_blank\">smart-sweep-65</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/93\n",
      "1117/1146 [============================>.] - ETA: 0s - loss: 4903.6104INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_084816-rs9bupu1/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_084816-rs9bupu1/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 2ms/step - loss: 4783.5977 - val_loss: 6.0846\n",
      "Epoch 2/93\n",
      "1119/1146 [============================>.] - ETA: 0s - loss: 4.6684INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_084816-rs9bupu1/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_084816-rs9bupu1/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 2ms/step - loss: 4.6125 - val_loss: 4.2018\n",
      "Epoch 3/93\n",
      "1129/1146 [============================>.] - ETA: 0s - loss: 2.1336INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_084816-rs9bupu1/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_084816-rs9bupu1/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 2ms/step - loss: 2.1261 - val_loss: 1.0374\n",
      "Epoch 4/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1.4344 - val_loss: 1.4460\n",
      "Epoch 5/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1.2208 - val_loss: 1.2819\n",
      "Epoch 6/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 518049024.0000 - val_loss: 2658084.0000\n",
      "Epoch 7/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1084412.0000 - val_loss: 923485.3125\n",
      "Epoch 8/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 371369.7812 - val_loss: 1157443.0000\n",
      "Epoch 9/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 11201995.0000 - val_loss: 1616531.3750\n",
      "Epoch 10/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 170493.8438 - val_loss: 69665.4688\n",
      "Epoch 11/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 77079.2969 - val_loss: 63409.5195\n",
      "Epoch 12/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 40030.7852 - val_loss: 13361.0732\n",
      "Epoch 13/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 343673856.0000 - val_loss: 70372912.0000\n",
      "Epoch 14/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 3103002.7500 - val_loss: 922644.7500\n",
      "Epoch 15/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 695905.1875 - val_loss: 597149.6250\n",
      "Epoch 16/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 492935.1875 - val_loss: 7003593.5000\n",
      "Epoch 17/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1061560.1250 - val_loss: 69456.0547\n",
      "Epoch 18/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 54382.5352 - val_loss: 184272.2188\n",
      "Epoch 19/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 153015808.0000 - val_loss: 602695.5000\n",
      "Epoch 20/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 421349.0938 - val_loss: 246150.2656\n",
      "Epoch 21/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 210783.6094 - val_loss: 193262.7344\n",
      "Epoch 22/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 130154.9141 - val_loss: 43446.7656\n",
      "Epoch 23/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 82053.6953 - val_loss: 5008160.0000\n",
      "Epoch 24/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 393839.7500 - val_loss: 21852.4062\n",
      "Epoch 25/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 16429.0469 - val_loss: 9384.6445\n",
      "Epoch 26/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 9140.2402 - val_loss: 7537.1011\n",
      "Epoch 27/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 369820128.0000 - val_loss: 1614364.7500\n",
      "Epoch 28/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1454282.5000 - val_loss: 1250714.1250\n",
      "Epoch 29/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 706301.9375 - val_loss: 612412.7500\n",
      "Epoch 30/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 400826.5000 - val_loss: 270067.7812\n",
      "Epoch 31/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 268070.1875 - val_loss: 395987.6562\n",
      "Epoch 32/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 210800.7500 - val_loss: 84293.7734\n",
      "Epoch 33/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 608313728.0000 - val_loss: 9176276.0000\n",
      "Epoch 34/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 3675220.5000 - val_loss: 2920554.7500\n",
      "Epoch 35/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1532214.1250 - val_loss: 5215208.5000\n",
      "Epoch 36/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 846289.3750 - val_loss: 726419.5000\n",
      "Epoch 37/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 508067.5312 - val_loss: 288436.8438\n",
      "Epoch 38/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 275898976.0000 - val_loss: 20970648.0000\n",
      "Epoch 39/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2948056.7500 - val_loss: 2442233.5000\n",
      "Epoch 40/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 890313.7500 - val_loss: 3522057.2500\n",
      "Epoch 41/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 626742.4375 - val_loss: 332612.5938\n",
      "Epoch 42/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 271517.4375 - val_loss: 221553.3906\n",
      "Epoch 43/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 168905.5312 - val_loss: 139511.2344\n",
      "Epoch 44/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 117332.0547 - val_loss: 55743.6836\n",
      "Epoch 45/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 310823936.0000 - val_loss: 1403455.0000\n",
      "Epoch 46/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1117833.3750 - val_loss: 1608776.7500\n",
      "Epoch 47/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 478757.5000 - val_loss: 1225431.0000\n",
      "Epoch 48/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 396271.0625 - val_loss: 349650.4062\n",
      "Epoch 49/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 199074.1250 - val_loss: 158380.2812\n",
      "Epoch 50/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 133769.1562 - val_loss: 487140.9688\n",
      "Epoch 51/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 259495088.0000 - val_loss: 1275852.5000\n",
      "Epoch 52/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1230504.0000 - val_loss: 1464381.3750\n",
      "Epoch 53/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 622191.7500 - val_loss: 847015.8750\n",
      "Epoch 54/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 393801.3750 - val_loss: 272206.2500\n",
      "Epoch 55/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 206848.4219 - val_loss: 149377.5156\n",
      "Epoch 56/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 104417704.0000 - val_loss: 1927030.6250\n",
      "Epoch 57/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 770588.5625 - val_loss: 552892.3750\n",
      "Epoch 58/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 329055.1250 - val_loss: 278345.7812\n",
      "Epoch 59/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 218907.9375 - val_loss: 158594.2500\n",
      "Epoch 60/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 137674.8438 - val_loss: 299273.0938\n",
      "Epoch 61/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 97482.8828 - val_loss: 1538597.1250\n",
      "Epoch 62/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 359942240.0000 - val_loss: 2027625.7500\n",
      "Epoch 63/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1570580.3750 - val_loss: 2066635.7500\n",
      "Epoch 64/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 869052.3125 - val_loss: 862100.3750\n",
      "Epoch 65/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 526561.5000 - val_loss: 965819.6250\n",
      "Epoch 66/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 210462736.0000 - val_loss: 9663029.0000\n",
      "Epoch 67/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 3045792.5000 - val_loss: 1484483.8750\n",
      "Epoch 68/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 950611.9375 - val_loss: 1491727.6250\n",
      "Epoch 69/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 471959.7500 - val_loss: 371893.0625\n",
      "Epoch 70/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 278966.1250 - val_loss: 658557.0000\n",
      "Epoch 71/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 208352.5312 - val_loss: 156774.5625\n",
      "Epoch 72/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 403380192.0000 - val_loss: 7226311.0000\n",
      "Epoch 73/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2884710.0000 - val_loss: 1884447.2500\n",
      "Epoch 74/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1273444.5000 - val_loss: 1407989.3750\n",
      "Epoch 75/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 742699.5625 - val_loss: 1956306.2500\n",
      "Epoch 76/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 491214.2812 - val_loss: 776555.2500\n",
      "Epoch 77/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 348283.0938 - val_loss: 1290478.5000\n",
      "Epoch 78/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 331406368.0000 - val_loss: 2013289.2500\n",
      "Epoch 79/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1824250.1250 - val_loss: 1951173.6250\n",
      "Epoch 80/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 999654.1875 - val_loss: 783752.5000\n",
      "Epoch 81/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 669547.8750 - val_loss: 504230.1562\n",
      "Epoch 82/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 425588.1875 - val_loss: 305358.9062\n",
      "Epoch 83/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 206043.0156 - val_loss: 308539.5625\n",
      "Epoch 84/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 174968.7031 - val_loss: 150872.7344\n",
      "Epoch 85/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 280180736.0000 - val_loss: 11084125.0000\n",
      "Epoch 86/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2775820.5000 - val_loss: 1949791.5000\n",
      "Epoch 87/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1049518.7500 - val_loss: 1589132.8750\n",
      "Epoch 88/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 718086.8750 - val_loss: 537310.7500\n",
      "Epoch 89/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 972324.3125 - val_loss: 482161.3750\n",
      "Epoch 90/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 201007.7969 - val_loss: 147069.7031\n",
      "Epoch 91/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 685098624.0000 - val_loss: 9596417.0000\n",
      "Epoch 92/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 6166735.5000 - val_loss: 3356640.7500\n",
      "Epoch 93/93\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2205819.2500 - val_loss: 1394583.2500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▁▁▁▁▁▁▄▁▁▁▁▁▁▁▆▁▁▇▁▁▁▁▁▁█▁▁▁▁▁▁▇▁▁▆▁▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁█▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▂▁▁▅▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>2</td></tr><tr><td>best_val_loss</td><td>1.03736</td></tr><tr><td>epoch</td><td>92</td></tr><tr><td>loss</td><td>2205819.25</td></tr><tr><td>val_loss</td><td>1394583.25</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">smart-sweep-65</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/rs9bupu1\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/rs9bupu1</a><br/>Synced 6 W&B file(s), 1 media file(s), 13 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_084816-rs9bupu1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tv0aw0lt with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.29329013762957873\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 98\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01163987568025774\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 241\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 157\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 119\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 238\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 204\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_085141-tv0aw0lt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/tv0aw0lt\" target=\"_blank\">major-sweep-66</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/98\n",
      "1144/1146 [============================>.] - ETA: 0s - loss: 0.9946INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_085141-tv0aw0lt/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_085141-tv0aw0lt/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.9945 - val_loss: 0.9981\n",
      "Epoch 2/98\n",
      "1126/1146 [============================>.] - ETA: 0s - loss: 0.8300INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_085141-tv0aw0lt/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_085141-tv0aw0lt/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 4s 3ms/step - loss: 0.8294 - val_loss: 0.8451\n",
      "Epoch 3/98\n",
      "1124/1146 [============================>.] - ETA: 0s - loss: 0.8012INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_085141-tv0aw0lt/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_085141-tv0aw0lt/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.8010 - val_loss: 0.7967\n",
      "Epoch 4/98\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1680.1351 - val_loss: 11.6369\n",
      "Epoch 5/98\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 8.6481 - val_loss: 3.3635\n",
      "Epoch 6/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 3.4622 - val_loss: 1.7884\n",
      "Epoch 7/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 2.5036 - val_loss: 2.7085\n",
      "Epoch 8/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 1.5698 - val_loss: 1.0596\n",
      "Epoch 9/98\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1.2316 - val_loss: 1.1542\n",
      "Epoch 10/98\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.9579 - val_loss: 0.8783\n",
      "Epoch 11/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.8728 - val_loss: 0.8434\n",
      "Epoch 12/98\n",
      "1124/1146 [============================>.] - ETA: 0s - loss: 0.7921INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_085141-tv0aw0lt/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_085141-tv0aw0lt/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.7921 - val_loss: 0.7751\n",
      "Epoch 13/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.7737 - val_loss: 0.9316\n",
      "Epoch 14/98\n",
      "1138/1146 [============================>.] - ETA: 0s - loss: 0.7509INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_085141-tv0aw0lt/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_085141-tv0aw0lt/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.7502 - val_loss: 0.7557\n",
      "Epoch 15/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.7359 - val_loss: 0.8658\n",
      "Epoch 16/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 5093.4712 - val_loss: 113.7859\n",
      "Epoch 17/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 48.6327 - val_loss: 22.6691\n",
      "Epoch 18/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 16.0249 - val_loss: 9.3093\n",
      "Epoch 19/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 9.1365 - val_loss: 7.3439\n",
      "Epoch 20/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 5.1398 - val_loss: 24.5394\n",
      "Epoch 21/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 3.6665 - val_loss: 2.2703\n",
      "Epoch 22/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 2.0130 - val_loss: 1.9148\n",
      "Epoch 23/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 1.3824 - val_loss: 1.8691\n",
      "Epoch 24/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 3874.5381 - val_loss: 32.1005\n",
      "Epoch 25/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 30.9016 - val_loss: 18.7082\n",
      "Epoch 26/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 10.8388 - val_loss: 10.5159\n",
      "Epoch 27/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 6.2094 - val_loss: 9.3167\n",
      "Epoch 28/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 4.7029 - val_loss: 2.1695\n",
      "Epoch 29/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 2.1144 - val_loss: 1.2235\n",
      "Epoch 30/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 1.5760 - val_loss: 1.1984\n",
      "Epoch 31/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 1.1505 - val_loss: 1.2093\n",
      "Epoch 32/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 1588.4265 - val_loss: 18.1730\n",
      "Epoch 33/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 7.6121 - val_loss: 9.6767\n",
      "Epoch 34/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 3.9067 - val_loss: 3.8026\n",
      "Epoch 35/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 2.2822 - val_loss: 2.6147\n",
      "Epoch 36/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 1.6055 - val_loss: 1.2204\n",
      "Epoch 37/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 1.1758 - val_loss: 0.9213\n",
      "Epoch 38/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.9902 - val_loss: 0.8943\n",
      "Epoch 39/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.8684 - val_loss: 0.8453\n",
      "Epoch 40/98\n",
      "1141/1146 [============================>.] - ETA: 0s - loss: 0.7968INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_085141-tv0aw0lt/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_085141-tv0aw0lt/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 3ms/step - loss: 0.7966 - val_loss: 0.7125\n",
      "Epoch 41/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 0.7697 - val_loss: 0.8198\n",
      "Epoch 42/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 2412.1848 - val_loss: 116.3939\n",
      "Epoch 43/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 9.0090 - val_loss: 5.3505\n",
      "Epoch 44/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 4.2414 - val_loss: 3.2329\n",
      "Epoch 45/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 2.6221 - val_loss: 1.9969\n",
      "Epoch 46/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 1.7819 - val_loss: 1.1959\n",
      "Epoch 47/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 3456.9751 - val_loss: 18.2777\n",
      "Epoch 48/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 12.7522 - val_loss: 43.2634\n",
      "Epoch 49/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 8.1364 - val_loss: 4.9921\n",
      "Epoch 50/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 3.8949 - val_loss: 3.8053\n",
      "Epoch 51/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 2.8343 - val_loss: 2.1352\n",
      "Epoch 52/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 1.8718 - val_loss: 1.4523\n",
      "Epoch 53/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 1.5065 - val_loss: 3.4807\n",
      "Epoch 54/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 4268.2534 - val_loss: 11.9883\n",
      "Epoch 55/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 17.5663 - val_loss: 13.0810\n",
      "Epoch 56/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 10.0963 - val_loss: 9.7903\n",
      "Epoch 57/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 6.6779 - val_loss: 9.3935\n",
      "Epoch 58/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 3.9318 - val_loss: 6.3180\n",
      "Epoch 59/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 2.8049 - val_loss: 1.2141\n",
      "Epoch 60/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 3991.7783 - val_loss: 135.2474\n",
      "Epoch 61/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 45.5244 - val_loss: 15.7508\n",
      "Epoch 62/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 18.0455 - val_loss: 12.0749\n",
      "Epoch 63/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 9.1680 - val_loss: 4.7256\n",
      "Epoch 64/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 6.0389 - val_loss: 2.7410\n",
      "Epoch 65/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 3.2070 - val_loss: 2.6030\n",
      "Epoch 66/98\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2.3008 - val_loss: 2.3866\n",
      "Epoch 67/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 1.7061 - val_loss: 1.0208\n",
      "Epoch 68/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 2381.8530 - val_loss: 4169.0645\n",
      "Epoch 69/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 93.2333 - val_loss: 16.1592\n",
      "Epoch 70/98\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 10.6630 - val_loss: 7.0415\n",
      "Epoch 71/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 5.9263 - val_loss: 5.0770\n",
      "Epoch 72/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 3.9215 - val_loss: 3.5024\n",
      "Epoch 73/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 2.3975 - val_loss: 1.9056\n",
      "Epoch 74/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 1.6898 - val_loss: 1.1770\n",
      "Epoch 75/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 1959.1768 - val_loss: 15.6257\n",
      "Epoch 76/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 11.8842 - val_loss: 6.5972\n",
      "Epoch 77/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 6.3821 - val_loss: 6.3666\n",
      "Epoch 78/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 4.0808 - val_loss: 2.4674\n",
      "Epoch 79/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 2.4945 - val_loss: 2.5409\n",
      "Epoch 80/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 1.6499 - val_loss: 0.9657\n",
      "Epoch 81/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 1.2157 - val_loss: 0.9562\n",
      "Epoch 82/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 1.0149 - val_loss: 0.8565\n",
      "Epoch 83/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 1967.5781 - val_loss: 10.2551\n",
      "Epoch 84/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 12.4243 - val_loss: 8.1394\n",
      "Epoch 85/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 6.4030 - val_loss: 5.5259\n",
      "Epoch 86/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 3.8381 - val_loss: 3.2541\n",
      "Epoch 87/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 2.5714 - val_loss: 1.7662\n",
      "Epoch 88/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 1.8959 - val_loss: 1.6330\n",
      "Epoch 89/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 8138.8076 - val_loss: 571.7629\n",
      "Epoch 90/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 107.5496 - val_loss: 94.6667\n",
      "Epoch 91/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 34.3603 - val_loss: 14.5951\n",
      "Epoch 92/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 17.1911 - val_loss: 9.8585\n",
      "Epoch 93/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 8.8473 - val_loss: 5.1427\n",
      "Epoch 94/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 5.7706 - val_loss: 9.2990\n",
      "Epoch 95/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 4.1237 - val_loss: 2.1887\n",
      "Epoch 96/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 1419.9469 - val_loss: 32.4027\n",
      "Epoch 97/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 17.5067 - val_loss: 8.9476\n",
      "Epoch 98/98\n",
      "1146/1146 [==============================] - 3s 2ms/step - loss: 6.6314 - val_loss: 4.7464\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▅▁▁▄▁▁▄▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>39</td></tr><tr><td>best_val_loss</td><td>0.71245</td></tr><tr><td>epoch</td><td>97</td></tr><tr><td>loss</td><td>6.63142</td></tr><tr><td>val_loss</td><td>4.74644</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">major-sweep-66</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/tv0aw0lt\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/tv0aw0lt</a><br/>Synced 6 W&B file(s), 1 media file(s), 25 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_085141-tv0aw0lt/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: q54qblio with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.27483191756932\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 57\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.08944736530837008\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 245\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 176\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 218\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 116\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 81\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_085607-q54qblio</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/q54qblio\" target=\"_blank\">light-sweep-67</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/57\n",
      "4537/4581 [============================>.] - ETA: 0s - loss: 689.6661INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_085607-q54qblio/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_085607-q54qblio/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4581/4581 [==============================] - 7s 1ms/step - loss: 683.1697 - val_loss: 0.9237\n",
      "Epoch 2/57\n",
      "4576/4581 [============================>.] - ETA: 0s - loss: 0.9946INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_085607-q54qblio/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_085607-q54qblio/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4581/4581 [==============================] - 6s 1ms/step - loss: 0.9944 - val_loss: 0.8059\n",
      "Epoch 3/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 265567056.0000 - val_loss: 454532.8125\n",
      "Epoch 4/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 173478.2812 - val_loss: 62485.5312\n",
      "Epoch 5/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1403806080.0000 - val_loss: 2045163.7500\n",
      "Epoch 6/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1066872512.0000 - val_loss: 16839438.0000\n",
      "Epoch 7/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 5236711.0000 - val_loss: 415461.4688\n",
      "Epoch 8/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1672913280.0000 - val_loss: 5506130.5000\n",
      "Epoch 9/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 4369882.5000 - val_loss: 896958.0000\n",
      "Epoch 10/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 744464320.0000 - val_loss: 2078588.2500\n",
      "Epoch 11/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 327950560.0000 - val_loss: 2899659.0000\n",
      "Epoch 12/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 982694272.0000 - val_loss: 41437396.0000\n",
      "Epoch 13/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 12858800.0000 - val_loss: 1983093.1250\n",
      "Epoch 14/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 161372752.0000 - val_loss: 2754167.2500\n",
      "Epoch 15/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1502974.7500 - val_loss: 377890.1562\n",
      "Epoch 16/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 379792096.0000 - val_loss: 3559871.7500\n",
      "Epoch 17/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2514593.0000 - val_loss: 588935.8125\n",
      "Epoch 18/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 294989888.0000 - val_loss: 2352824.2500\n",
      "Epoch 19/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1362402.5000 - val_loss: 359173.0000\n",
      "Epoch 20/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 470093312.0000 - val_loss: 1748795.8750\n",
      "Epoch 21/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 164600864.0000 - val_loss: 3230250.2500\n",
      "Epoch 22/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2249133.2500 - val_loss: 585896.5625\n",
      "Epoch 23/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 195107584.0000 - val_loss: 2817226.0000\n",
      "Epoch 24/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1704811.6250 - val_loss: 340171.7188\n",
      "Epoch 25/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 480134720.0000 - val_loss: 5098569.5000\n",
      "Epoch 26/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 276896640.0000 - val_loss: 612175168.0000\n",
      "Epoch 27/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 10601410.0000 - val_loss: 1004276.3125\n",
      "Epoch 28/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 357658368.0000 - val_loss: 5322415.5000\n",
      "Epoch 29/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2675955.2500 - val_loss: 1592827.1250\n",
      "Epoch 30/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 436119520.0000 - val_loss: 4083941.2500\n",
      "Epoch 31/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2027320.1250 - val_loss: 852780.7500\n",
      "Epoch 32/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 156871920.0000 - val_loss: 980474.4375\n",
      "Epoch 33/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1022683.8125 - val_loss: 206087.2656\n",
      "Epoch 34/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 207735472.0000 - val_loss: 1241234.5000\n",
      "Epoch 35/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 552550912.0000 - val_loss: 82837008.0000\n",
      "Epoch 36/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 8688887.0000 - val_loss: 1301881.5000\n",
      "Epoch 37/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 494063232.0000 - val_loss: 2560580.0000\n",
      "Epoch 38/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1683063.6250 - val_loss: 287823.0625\n",
      "Epoch 39/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 502603744.0000 - val_loss: 2978910.7500\n",
      "Epoch 40/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1063683072.0000 - val_loss: 220793168.0000\n",
      "Epoch 41/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 27090964.0000 - val_loss: 3694902.5000\n",
      "Epoch 42/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2388023.5000 - val_loss: 398696.6875\n",
      "Epoch 43/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 501169856.0000 - val_loss: 2529552.5000\n",
      "Epoch 44/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2114011.0000 - val_loss: 278731.4062\n",
      "Epoch 45/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1198717952.0000 - val_loss: 6686213.5000\n",
      "Epoch 46/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 3602953.2500 - val_loss: 1000504.3750\n",
      "Epoch 47/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 317942688.0000 - val_loss: 5046320.5000\n",
      "Epoch 48/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2360383.2500 - val_loss: 527284.5000\n",
      "Epoch 49/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 184944496.0000 - val_loss: 1682255.2500\n",
      "Epoch 50/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1028608.3750 - val_loss: 163213.3125\n",
      "Epoch 51/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 590720256.0000 - val_loss: 3720773.5000\n",
      "Epoch 52/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 578316032.0000 - val_loss: 7580165.0000\n",
      "Epoch 53/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 5622148.5000 - val_loss: 888238.2500\n",
      "Epoch 54/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 302646432.0000 - val_loss: 2679215.5000\n",
      "Epoch 55/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1879722.2500 - val_loss: 1150729.8750\n",
      "Epoch 56/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 357978720.0000 - val_loss: 5943609.0000\n",
      "Epoch 57/57\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 3081269.0000 - val_loss: 754659.3750\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f038aa10d204905a95990e89adcc029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='4.735 MB of 4.735 MB uploaded (0.016 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▂▇▅█▁▂▅▁▁▃▂▁▂▁▂▃▂▂▁▁▂▂▃▁▁▃▁▁▁▆▁▁▂▃▃▂▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>1</td></tr><tr><td>best_val_loss</td><td>0.80594</td></tr><tr><td>epoch</td><td>56</td></tr><tr><td>loss</td><td>3081269.0</td></tr><tr><td>val_loss</td><td>754659.375</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">light-sweep-67</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/q54qblio\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/q54qblio</a><br/>Synced 6 W&B file(s), 1 media file(s), 9 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_085607-q54qblio/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yt8uz6c8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5202895969862006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 36\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.08391067602792977\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 194\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 167\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 145\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 202\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 156\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_090115-yt8uz6c8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/yt8uz6c8\" target=\"_blank\">exalted-sweep-68</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/36\n",
      "2276/2291 [============================>.] - ETA: 0s - loss: 6205.5996INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_090115-yt8uz6c8/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_090115-yt8uz6c8/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 5s 2ms/step - loss: 6167.3970 - val_loss: 7.8050\n",
      "Epoch 2/36\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 344943744.0000 - val_loss: 879623.9375\n",
      "Epoch 3/36\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 367179456.0000 - val_loss: 7669224.0000\n",
      "Epoch 4/36\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 3329246.5000 - val_loss: 643056.3750\n",
      "Epoch 5/36\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 773967.3125 - val_loss: 246493.7188\n",
      "Epoch 6/36\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 241866.8281 - val_loss: 378720.1875\n",
      "Epoch 7/36\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 226328672.0000 - val_loss: 671328.5000\n",
      "Epoch 8/36\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 663321.5625 - val_loss: 251493.7031\n",
      "Epoch 9/36\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 179539.6406 - val_loss: 96136.8359\n",
      "Epoch 10/36\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 61210.7148 - val_loss: 60082.7930\n",
      "Epoch 11/36\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 555923520.0000 - val_loss: 2330765.5000\n",
      "Epoch 12/36\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1528360.6250 - val_loss: 664507.6250\n",
      "Epoch 13/36\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 507475.5312 - val_loss: 304058.3750\n",
      "Epoch 14/36\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 1392632064.0000 - val_loss: 12874681.0000\n",
      "Epoch 15/36\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 12072492.0000 - val_loss: 2484854.5000\n",
      "Epoch 16/36\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 3192668.0000 - val_loss: 2326847.2500\n",
      "Epoch 17/36\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 687244608.0000 - val_loss: 16662608.0000\n",
      "Epoch 18/36\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 8279732.0000 - val_loss: 1641605.1250\n",
      "Epoch 19/36\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 2027369.0000 - val_loss: 812588.8125\n",
      "Epoch 20/36\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 838659520.0000 - val_loss: 7686075904.0000\n",
      "Epoch 21/36\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 65148364.0000 - val_loss: 5199822.0000\n",
      "Epoch 22/36\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 3593196.0000 - val_loss: 2196385.2500\n",
      "Epoch 23/36\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 740260032.0000 - val_loss: 15734673.0000\n",
      "Epoch 24/36\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 7476005.0000 - val_loss: 2620224.7500\n",
      "Epoch 25/36\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 2244724.0000 - val_loss: 1175718.0000\n",
      "Epoch 26/36\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 535039200.0000 - val_loss: 13734221824.0000\n",
      "Epoch 27/36\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 84904736.0000 - val_loss: 3725793.2500\n",
      "Epoch 28/36\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 2453521.7500 - val_loss: 882317.1250\n",
      "Epoch 29/36\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 824388.0625 - val_loss: 270300.2188\n",
      "Epoch 30/36\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 931404160.0000 - val_loss: 77423264.0000\n",
      "Epoch 31/36\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 19767360.0000 - val_loss: 4448211.5000\n",
      "Epoch 32/36\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 4171194.0000 - val_loss: 1521523.7500\n",
      "Epoch 33/36\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1277382.1250 - val_loss: 421395.4375\n",
      "Epoch 34/36\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 589783040.0000 - val_loss: 6615916.5000\n",
      "Epoch 35/36\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 5916383.5000 - val_loss: 2349769.7500\n",
      "Epoch 36/36\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 1663021.0000 - val_loss: 414480.5938\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▃▃▁▁▁▂▁▁▁▄▁▁█▁▁▄▁▁▅▁▁▅▁▁▄▁▁▁▆▁▁▁▄▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>7.80503</td></tr><tr><td>epoch</td><td>35</td></tr><tr><td>loss</td><td>1663021.0</td></tr><tr><td>val_loss</td><td>414480.59375</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">exalted-sweep-68</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/yt8uz6c8\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/yt8uz6c8</a><br/>Synced 6 W&B file(s), 1 media file(s), 5 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_090115-yt8uz6c8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0erfhotc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.03441949713983043\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.02451161819510761\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 79\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 136\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 110\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 252\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 191\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_090333-0erfhotc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/0erfhotc\" target=\"_blank\">daily-sweep-69</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1495/1527 [============================>.] - ETA: 0s - loss: 1.2900INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_090333-0erfhotc/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_090333-0erfhotc/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 4s 2ms/step - loss: 1.2813 - val_loss: 0.9633\n",
      "Epoch 2/50\n",
      "1514/1527 [============================>.] - ETA: 0s - loss: 0.8392INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_090333-0erfhotc/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_090333-0erfhotc/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 4s 2ms/step - loss: 0.8398 - val_loss: 0.8600\n",
      "Epoch 3/50\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 37952.3086 - val_loss: 318.0746\n",
      "Epoch 4/50\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 117.1857 - val_loss: 38.4457\n",
      "Epoch 5/50\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 45.4842 - val_loss: 37.9270\n",
      "Epoch 6/50\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 19.4893 - val_loss: 12.5309\n",
      "Epoch 7/50\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 9.3404 - val_loss: 7.9080\n",
      "Epoch 8/50\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 65698.6172 - val_loss: 743.1099\n",
      "Epoch 9/50\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 308.5316 - val_loss: 103.3436\n",
      "Epoch 10/50\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 115.0215 - val_loss: 42.7706\n",
      "Epoch 11/50\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 49.5188 - val_loss: 19.6853\n",
      "Epoch 12/50\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 29.2176 - val_loss: 13.1402\n",
      "Epoch 13/50\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 341108.2500 - val_loss: 1472.1138\n",
      "Epoch 14/50\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1234.1636 - val_loss: 874.5158\n",
      "Epoch 15/50\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 529.2159 - val_loss: 276.0598\n",
      "Epoch 16/50\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 311.3033 - val_loss: 217.5375\n",
      "Epoch 17/50\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 90720.4844 - val_loss: 846.4273\n",
      "Epoch 18/50\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 622.7075 - val_loss: 331.6530\n",
      "Epoch 19/50\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 231.2900 - val_loss: 115.5016\n",
      "Epoch 20/50\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 113.4114 - val_loss: 50.3438\n",
      "Epoch 21/50\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 57.1289 - val_loss: 37.0271\n",
      "Epoch 22/50\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 93356.5703 - val_loss: 769.3986\n",
      "Epoch 23/50\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 449.4503 - val_loss: 171.4154\n",
      "Epoch 24/50\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 187.5519 - val_loss: 127.5541\n",
      "Epoch 25/50\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 101.9540 - val_loss: 66.3870\n",
      "Epoch 26/50\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 70.9887 - val_loss: 25.4062\n",
      "Epoch 27/50\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 149848.8906 - val_loss: 2564.6626\n",
      "Epoch 28/50\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1155.4385 - val_loss: 428.6677\n",
      "Epoch 29/50\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 498.2036 - val_loss: 324.5760\n",
      "Epoch 30/50\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 239.7639 - val_loss: 150.9649\n",
      "Epoch 31/50\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 70179.9531 - val_loss: 4372.1523\n",
      "Epoch 32/50\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 1081.0948 - val_loss: 474.6320\n",
      "Epoch 33/50\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 371.5174 - val_loss: 141.1015\n",
      "Epoch 34/50\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 174.5454 - val_loss: 113.2947\n",
      "Epoch 35/50\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 84.7347 - val_loss: 46.0967\n",
      "Epoch 36/50\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 215410.5469 - val_loss: 2184.2087\n",
      "Epoch 37/50\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1459.4141 - val_loss: 886.1158\n",
      "Epoch 38/50\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 686.0499 - val_loss: 372.8804\n",
      "Epoch 39/50\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 348.4733 - val_loss: 262.4527\n",
      "Epoch 40/50\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 264689.0938 - val_loss: 6590.0757\n",
      "Epoch 41/50\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 2388.4260 - val_loss: 967.0685\n",
      "Epoch 42/50\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 913.1779 - val_loss: 490.3197\n",
      "Epoch 43/50\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 482.6584 - val_loss: 213.3023\n",
      "Epoch 44/50\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 345.8481 - val_loss: 92.9219\n",
      "Epoch 45/50\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 778129.4375 - val_loss: 11885.8486\n",
      "Epoch 46/50\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 9973.0859 - val_loss: 1473.6949\n",
      "Epoch 47/50\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1514.6067 - val_loss: 1346.8470\n",
      "Epoch 48/50\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1183.7498 - val_loss: 766.5671\n",
      "Epoch 49/50\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 584.5240 - val_loss: 810.6088\n",
      "Epoch 50/50\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 299.5116 - val_loss: 258.5994\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▂▁▁▁▂▁▁▁█▁▁▃▁▁▁▃▁▁▁▄▁▁▂▁▁▁▅▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▁▁▂▁▁▁▂▁▁▁▃▂▁▂▂▁▁▂▁▁▁▅▂▂█▂▁▁▄▂▂▁▃▂▁▁▃▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>1</td></tr><tr><td>best_val_loss</td><td>0.86</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>loss</td><td>299.51163</td></tr><tr><td>val_loss</td><td>258.59937</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">daily-sweep-69</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/0erfhotc\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/0erfhotc</a><br/>Synced 6 W&B file(s), 1 media file(s), 9 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_090333-0erfhotc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: m3p5box8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.326572767761558\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 33\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0630521529009863\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 144\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 242\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 101\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 166\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 130\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_090557-m3p5box8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/m3p5box8\" target=\"_blank\">lively-sweep-70</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/33\n",
      "2290/2291 [============================>.] - ETA: 0s - loss: 87.3418INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_090557-m3p5box8/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_090557-m3p5box8/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 87.3376 - val_loss: 0.7812\n",
      "Epoch 2/33\n",
      "2289/2291 [============================>.] - ETA: 0s - loss: 0.8643INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_090557-m3p5box8/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_090557-m3p5box8/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 0.8643 - val_loss: 0.7528\n",
      "Epoch 3/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.8523 - val_loss: 0.8520\n",
      "Epoch 4/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.8871 - val_loss: 0.9424\n",
      "Epoch 5/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 173573792.0000 - val_loss: 897019.5000\n",
      "Epoch 6/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 459495.1250 - val_loss: 95779.3516\n",
      "Epoch 7/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 63124624.0000 - val_loss: 1235706.5000\n",
      "Epoch 8/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 645426.2500 - val_loss: 243215.1250\n",
      "Epoch 9/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 131473.0469 - val_loss: 61317.6328\n",
      "Epoch 10/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 28870486.0000 - val_loss: 132836.8438\n",
      "Epoch 11/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 110749.8906 - val_loss: 30625.3848\n",
      "Epoch 12/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 36959.7031 - val_loss: 13641.8301\n",
      "Epoch 13/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 74295624.0000 - val_loss: 2483345.5000\n",
      "Epoch 14/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 717214.1250 - val_loss: 191901.4062\n",
      "Epoch 15/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 160687.1094 - val_loss: 61885.8438\n",
      "Epoch 16/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 56951.6992 - val_loss: 17211.1465\n",
      "Epoch 17/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 282390624.0000 - val_loss: 1436152.2500\n",
      "Epoch 18/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1173294.2500 - val_loss: 712336.8125\n",
      "Epoch 19/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 432064.7812 - val_loss: 155217.5938\n",
      "Epoch 20/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 223547712.0000 - val_loss: 1983369.0000\n",
      "Epoch 21/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1262027.1250 - val_loss: 571877.5625\n",
      "Epoch 22/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 29460426.0000 - val_loss: 472225.4688\n",
      "Epoch 23/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 324065.9375 - val_loss: 125983.5938\n",
      "Epoch 24/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 108124.2500 - val_loss: 53872.0742\n",
      "Epoch 25/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 89330680.0000 - val_loss: 1161565.3750\n",
      "Epoch 26/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 871155.6250 - val_loss: 224162.6094\n",
      "Epoch 27/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 236798.4219 - val_loss: 92103.1016\n",
      "Epoch 28/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 86640.6406 - val_loss: 40793.1758\n",
      "Epoch 29/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 49676592.0000 - val_loss: 317864.5000\n",
      "Epoch 30/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 242810.2188 - val_loss: 105686.4766\n",
      "Epoch 31/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 80968.3750 - val_loss: 49733.1523\n",
      "Epoch 32/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 26231.0293 - val_loss: 8784.1289\n",
      "Epoch 33/33\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 8508.9590 - val_loss: 3019.9504\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▁▁▅▁▃▁▁▂▁▁▃▁▁▁█▁▁▇▁▂▁▁▃▁▁▁▂▁▁▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▄▁▄▂▁▁▁▁█▂▁▁▅▃▁▇▃▂▁▁▄▂▁▁▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>1</td></tr><tr><td>best_val_loss</td><td>0.75284</td></tr><tr><td>epoch</td><td>32</td></tr><tr><td>loss</td><td>8508.95898</td></tr><tr><td>val_loss</td><td>3019.95044</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">lively-sweep-70</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/m3p5box8\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/m3p5box8</a><br/>Synced 6 W&B file(s), 1 media file(s), 9 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_090557-m3p5box8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: c422zm4q with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.06861894476520189\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 62\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.04940051950419144\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 154\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 225\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 223\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 188\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_090755-c422zm4q</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/c422zm4q\" target=\"_blank\">sparkling-sweep-71</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/62\n",
      "1516/1527 [============================>.] - ETA: 0s - loss: 134.3174INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_090755-c422zm4q/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_090755-c422zm4q/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 4s 2ms/step - loss: 133.3790 - val_loss: 0.7954\n",
      "Epoch 2/62\n",
      "1513/1527 [============================>.] - ETA: 0s - loss: 0.8175INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_090755-c422zm4q/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_090755-c422zm4q/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.8172 - val_loss: 0.7173\n",
      "Epoch 3/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.7783 - val_loss: 0.7447\n",
      "Epoch 4/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.7712 - val_loss: 0.7701\n",
      "Epoch 5/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.7851 - val_loss: 0.8175\n",
      "Epoch 6/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.7996 - val_loss: 0.8686\n",
      "Epoch 7/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.8676 - val_loss: 0.8607\n",
      "Epoch 8/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 19133446.0000 - val_loss: 55570.2812\n",
      "Epoch 9/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 34633.1641 - val_loss: 17029.8730\n",
      "Epoch 10/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 13912.5283 - val_loss: 48918.3906\n",
      "Epoch 11/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 6957.9731 - val_loss: 2142.2971\n",
      "Epoch 12/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 2404.3027 - val_loss: 1311.8475\n",
      "Epoch 13/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1452.8680 - val_loss: 470.4467\n",
      "Epoch 14/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 663.8331 - val_loss: 267.4644\n",
      "Epoch 15/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 44771348.0000 - val_loss: 75114.4219\n",
      "Epoch 16/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 94406.9844 - val_loss: 32754.0723\n",
      "Epoch 17/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 43555.4023 - val_loss: 22396.5137\n",
      "Epoch 18/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 41753060.0000 - val_loss: 1020891776.0000\n",
      "Epoch 19/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 24846872.0000 - val_loss: 236632.1406\n",
      "Epoch 20/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 232837.9062 - val_loss: 86729.2500\n",
      "Epoch 21/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 100004.1094 - val_loss: 65700.4844\n",
      "Epoch 22/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 48554.2656 - val_loss: 16265.6602\n",
      "Epoch 23/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 44039740.0000 - val_loss: 417789.6562\n",
      "Epoch 24/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 253072.8906 - val_loss: 166949.0781\n",
      "Epoch 25/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 102429.4141 - val_loss: 96411.4297\n",
      "Epoch 26/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 45630.1367 - val_loss: 63980.5859\n",
      "Epoch 27/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 17223258.0000 - val_loss: 50007.7188\n",
      "Epoch 28/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 59562.6250 - val_loss: 57245.0391\n",
      "Epoch 29/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 29703.1816 - val_loss: 9680.4639\n",
      "Epoch 30/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 12144.8477 - val_loss: 7102.2993\n",
      "Epoch 31/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 21190830.0000 - val_loss: 302274.0938\n",
      "Epoch 32/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 164433.4219 - val_loss: 83151.5625\n",
      "Epoch 33/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 59921.1406 - val_loss: 28748.9121\n",
      "Epoch 34/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 34136.0625 - val_loss: 23717.2031\n",
      "Epoch 35/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 40586292.0000 - val_loss: 869408.3125\n",
      "Epoch 36/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 394902.9062 - val_loss: 318490.7812\n",
      "Epoch 37/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 119867.5859 - val_loss: 56682.2422\n",
      "Epoch 38/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 53271.6562 - val_loss: 60646.0391\n",
      "Epoch 39/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 31195.0664 - val_loss: 12197.3018\n",
      "Epoch 40/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 27456.2305 - val_loss: 10072.9277\n",
      "Epoch 41/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 87363520.0000 - val_loss: 586800.5625\n",
      "Epoch 42/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 413461.0938 - val_loss: 216118.3438\n",
      "Epoch 43/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 175236.3438 - val_loss: 157814.5938\n",
      "Epoch 44/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 96587.1250 - val_loss: 57943.6328\n",
      "Epoch 45/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 59864.3320 - val_loss: 34289.2461\n",
      "Epoch 46/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 50837780.0000 - val_loss: 999092.3125\n",
      "Epoch 47/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 361161.3438 - val_loss: 102074.5234\n",
      "Epoch 48/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 115988.8125 - val_loss: 42936.8398\n",
      "Epoch 49/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 67049.2656 - val_loss: 24372.3594\n",
      "Epoch 50/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 35443520.0000 - val_loss: 352493.8438\n",
      "Epoch 51/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 234543.7344 - val_loss: 92960.5469\n",
      "Epoch 52/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 111141.3984 - val_loss: 54369.4688\n",
      "Epoch 53/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 70270.2266 - val_loss: 28186.1387\n",
      "Epoch 54/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 35640132.0000 - val_loss: 926934.3125\n",
      "Epoch 55/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 389837.2812 - val_loss: 107406.0391\n",
      "Epoch 56/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 137227.7969 - val_loss: 66633.0391\n",
      "Epoch 57/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 75043.5703 - val_loss: 50181.4141\n",
      "Epoch 58/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 42248.1055 - val_loss: 22004.8242\n",
      "Epoch 59/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 25070.8809 - val_loss: 11653.7920\n",
      "Epoch 60/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 104700344.0000 - val_loss: 484306.7812\n",
      "Epoch 61/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 523263.5312 - val_loss: 220896.9219\n",
      "Epoch 62/62\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 264817.3750 - val_loss: 122503.1328\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▁▁▁▂▁▁▁▄▁▄▃▁▁▁▁▂▁▁▁▁▄▁▁▁▇▁▁▄▁▁▁▁▃▁▁▁█▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>1</td></tr><tr><td>best_val_loss</td><td>0.71733</td></tr><tr><td>epoch</td><td>61</td></tr><tr><td>loss</td><td>264817.375</td></tr><tr><td>val_loss</td><td>122503.13281</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">sparkling-sweep-71</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/c422zm4q\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/c422zm4q</a><br/>Synced 6 W&B file(s), 1 media file(s), 9 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_090755-c422zm4q/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vqxbkdj3 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4153513634425426\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 43\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.08924769873611044\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 82\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 240\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 91\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 209\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 230\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091100-vqxbkdj3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/vqxbkdj3\" target=\"_blank\">earthy-sweep-72</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/43\n",
      "1142/1146 [============================>.] - ETA: 0s - loss: 835052928.0000INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091100-vqxbkdj3/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091100-vqxbkdj3/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 4s 3ms/step - loss: 832887168.0000 - val_loss: 17024386.0000\n",
      "Epoch 2/43\n",
      "1131/1146 [============================>.] - ETA: 0s - loss: 6089288.0000INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091100-vqxbkdj3/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091100-vqxbkdj3/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 2ms/step - loss: 6037613.5000 - val_loss: 983726.9375\n",
      "Epoch 3/43\n",
      "1120/1146 [============================>.] - ETA: 0s - loss: 1409201.0000INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091100-vqxbkdj3/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091100-vqxbkdj3/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 3ms/step - loss: 1404265.6250 - val_loss: 906209.7500\n",
      "Epoch 4/43\n",
      "1136/1146 [============================>.] - ETA: 0s - loss: 795857.4375INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091100-vqxbkdj3/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091100-vqxbkdj3/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 2ms/step - loss: 795274.0625 - val_loss: 276804.0312\n",
      "Epoch 5/43\n",
      "1122/1146 [============================>.] - ETA: 0s - loss: 491039.3125INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091100-vqxbkdj3/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091100-vqxbkdj3/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 2ms/step - loss: 485340.8125 - val_loss: 225818.6250\n",
      "Epoch 6/43\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 236817.0625 - val_loss: 384650.7188\n",
      "Epoch 7/43\n",
      "1131/1146 [============================>.] - ETA: 0s - loss: 119377.0625INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091100-vqxbkdj3/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091100-vqxbkdj3/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 3ms/step - loss: 118508.3203 - val_loss: 34472.9219\n",
      "Epoch 8/43\n",
      "1138/1146 [============================>.] - ETA: 0s - loss: 56823.8398INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091100-vqxbkdj3/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091100-vqxbkdj3/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 2ms/step - loss: 56718.8125 - val_loss: 28292.1836\n",
      "Epoch 9/43\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1817891072.0000 - val_loss: 7475089.5000\n",
      "Epoch 10/43\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 5527381.0000 - val_loss: 1717998.3750\n",
      "Epoch 11/43\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2161095.0000 - val_loss: 1884878.5000\n",
      "Epoch 12/43\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1235792.2500 - val_loss: 1545712.8750\n",
      "Epoch 13/43\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 758327.5625 - val_loss: 567857.1875\n",
      "Epoch 14/43\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 409422.9688 - val_loss: 128513.2734\n",
      "Epoch 15/43\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 215837.4375 - val_loss: 171358.9688\n",
      "Epoch 16/43\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 3021401088.0000 - val_loss: 8609220.0000\n",
      "Epoch 17/43\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 12713943.0000 - val_loss: 12247231.0000\n",
      "Epoch 18/43\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 6207914.0000 - val_loss: 4560190.0000\n",
      "Epoch 19/43\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 3636540.5000 - val_loss: 1614167.5000\n",
      "Epoch 20/43\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2089760.1250 - val_loss: 981367.3750\n",
      "Epoch 21/43\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1024197.3750 - val_loss: 790406.5625\n",
      "Epoch 22/43\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 686978.2500 - val_loss: 228668.7188\n",
      "Epoch 23/43\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 373743.9062 - val_loss: 224307.2500\n",
      "Epoch 24/43\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 6559071744.0000 - val_loss: 45021648.0000\n",
      "Epoch 25/43\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 40339336.0000 - val_loss: 15077606.0000\n",
      "Epoch 26/43\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 19222594.0000 - val_loss: 5728281.0000\n",
      "Epoch 27/43\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 7111726.0000 - val_loss: 5492901.0000\n",
      "Epoch 28/43\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 4112547.5000 - val_loss: 1597788.3750\n",
      "Epoch 29/43\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 5317501440.0000 - val_loss: 40875288.0000\n",
      "Epoch 30/43\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 31153704.0000 - val_loss: 16035496.0000\n",
      "Epoch 31/43\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 16402550.0000 - val_loss: 15684633.0000\n",
      "Epoch 32/43\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 9844776.0000 - val_loss: 7559889.5000\n",
      "Epoch 33/43\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 5082605.0000 - val_loss: 2005882.1250\n",
      "Epoch 34/43\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2784623.7500 - val_loss: 1549801.7500\n",
      "Epoch 35/43\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2567782400.0000 - val_loss: 22792460.0000\n",
      "Epoch 36/43\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 14746941.0000 - val_loss: 11435665.0000\n",
      "Epoch 37/43\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 7868762.0000 - val_loss: 12904361.0000\n",
      "Epoch 38/43\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 4433346.0000 - val_loss: 2459443.0000\n",
      "Epoch 39/43\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2416311.2500 - val_loss: 1130715.7500\n",
      "Epoch 40/43\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1416773.5000 - val_loss: 898398.3125\n",
      "Epoch 41/43\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 855232.7500 - val_loss: 418014.7188\n",
      "Epoch 42/43\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 557456.1875 - val_loss: 354212.2188\n",
      "Epoch 43/43\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2092390016.0000 - val_loss: 11464991.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>loss</td><td>▂▁▁▁▁▁▁▁▃▁▁▁▁▁▄▁▁▁▁▁▁▁█▁▁▁▇▁▁▁▁▁▄▁▁▁▁▁▁▃</td></tr><tr><td>val_loss</td><td>▄▁▁▁▁▁▁▁▂▁▁▁▁▁▂▃▂▁▁▁▁▁█▃▂▂▇▃▃▂▁▁▅▃▃▁▁▁▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>7</td></tr><tr><td>best_val_loss</td><td>28292.18359</td></tr><tr><td>epoch</td><td>42</td></tr><tr><td>loss</td><td>2092390016.0</td></tr><tr><td>val_loss</td><td>11464991.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">earthy-sweep-72</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/vqxbkdj3\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/vqxbkdj3</a><br/>Synced 6 W&B file(s), 1 media file(s), 29 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_091100-vqxbkdj3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: nckrwujn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2752143467664206\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 69\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.019556004168072707\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 213\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 67\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 168\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091257-nckrwujn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/nckrwujn\" target=\"_blank\">light-sweep-73</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/69\n",
      "1495/1527 [============================>.] - ETA: 0s - loss: 0.9719INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091257-nckrwujn/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091257-nckrwujn/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.9700 - val_loss: 0.8847\n",
      "Epoch 2/69\n",
      "1505/1527 [============================>.] - ETA: 0s - loss: 0.8575INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091257-nckrwujn/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091257-nckrwujn/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.8579 - val_loss: 0.8193\n",
      "Epoch 3/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 1460.2032 - val_loss: 2.9589\n",
      "Epoch 4/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 3.0411 - val_loss: 1.6530\n",
      "Epoch 5/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 2.0419 - val_loss: 1.4311\n",
      "Epoch 6/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 1.3723 - val_loss: 0.9818\n",
      "Epoch 7/69\n",
      "1527/1527 [==============================] - ETA: 0s - loss: 1.0165INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091257-nckrwujn/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091257-nckrwujn/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1.0165 - val_loss: 0.7931\n",
      "Epoch 8/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 0.8520 - val_loss: 0.8686\n",
      "Epoch 9/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 0.7947 - val_loss: 0.8233\n",
      "Epoch 10/69\n",
      "1506/1527 [============================>.] - ETA: 0s - loss: 0.7843INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091257-nckrwujn/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091257-nckrwujn/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.7828 - val_loss: 0.6835\n",
      "Epoch 11/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 3187.4141 - val_loss: 15.1315\n",
      "Epoch 12/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 9.9006 - val_loss: 6.0728\n",
      "Epoch 13/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 4.4277 - val_loss: 2.3580\n",
      "Epoch 14/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 2.5648 - val_loss: 1.7296\n",
      "Epoch 15/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 1.6463 - val_loss: 1.0362\n",
      "Epoch 16/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 1.1536 - val_loss: 1.0308\n",
      "Epoch 17/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 0.9311 - val_loss: 0.7505\n",
      "Epoch 18/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 7480.8525 - val_loss: 436.0797\n",
      "Epoch 19/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 95.9307 - val_loss: 44.8564\n",
      "Epoch 20/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 31.5246 - val_loss: 28.0856\n",
      "Epoch 21/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 16.4794 - val_loss: 6.5619\n",
      "Epoch 22/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 1608.2985 - val_loss: 175683.7344\n",
      "Epoch 23/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 22333.5000 - val_loss: 115.5184\n",
      "Epoch 24/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 145.2969 - val_loss: 65.7032\n",
      "Epoch 25/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 65.8650 - val_loss: 34.9769\n",
      "Epoch 26/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 31.1455 - val_loss: 13.4247\n",
      "Epoch 27/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 8062.6060 - val_loss: 72.2452\n",
      "Epoch 28/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 58.7137 - val_loss: 32.1278\n",
      "Epoch 29/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 27.9913 - val_loss: 13.0871\n",
      "Epoch 30/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 14.7742 - val_loss: 9.5004\n",
      "Epoch 31/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 7.9299 - val_loss: 4.8665\n",
      "Epoch 32/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 4.6810 - val_loss: 3.3796\n",
      "Epoch 33/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 3.3513 - val_loss: 2.1702\n",
      "Epoch 34/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 8997.5039 - val_loss: 292.9731\n",
      "Epoch 35/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 100.1568 - val_loss: 45.8108\n",
      "Epoch 36/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 32.5901 - val_loss: 14.7967\n",
      "Epoch 37/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 15.2203 - val_loss: 7.5689\n",
      "Epoch 38/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 9.0500 - val_loss: 6.0089\n",
      "Epoch 39/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 5.6813 - val_loss: 2.6323\n",
      "Epoch 40/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 2.4316 - val_loss: 1.1559\n",
      "Epoch 41/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 7421.4658 - val_loss: 58.5298\n",
      "Epoch 42/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 48.5761 - val_loss: 15.6887\n",
      "Epoch 43/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 21.2644 - val_loss: 19.1807\n",
      "Epoch 44/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 10.5076 - val_loss: 9.9386\n",
      "Epoch 45/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 5.8557 - val_loss: 2.5261\n",
      "Epoch 46/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 6747.7930 - val_loss: 1996.1958\n",
      "Epoch 47/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 152.8808 - val_loss: 35.6240\n",
      "Epoch 48/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 33.6365 - val_loss: 14.0217\n",
      "Epoch 49/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 17.0066 - val_loss: 11.3409\n",
      "Epoch 50/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 9.8029 - val_loss: 7.1880\n",
      "Epoch 51/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 5.2426 - val_loss: 2.2585\n",
      "Epoch 52/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 14762.7676 - val_loss: 344.2286\n",
      "Epoch 53/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 209.5453 - val_loss: 50.1992\n",
      "Epoch 54/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 61.1255 - val_loss: 27.2232\n",
      "Epoch 55/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 28.6886 - val_loss: 11.8212\n",
      "Epoch 56/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 15.1582 - val_loss: 7.9727\n",
      "Epoch 57/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 7.9001 - val_loss: 4.1468\n",
      "Epoch 58/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 4.4673 - val_loss: 2.0828\n",
      "Epoch 59/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 5837.8501 - val_loss: 296.2223\n",
      "Epoch 60/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 88.6967 - val_loss: 18.1167\n",
      "Epoch 61/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 27.9780 - val_loss: 19.1777\n",
      "Epoch 62/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 16.0429 - val_loss: 10.8977\n",
      "Epoch 63/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 9.5169 - val_loss: 13.4096\n",
      "Epoch 64/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 5.1649 - val_loss: 2.2136\n",
      "Epoch 65/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 8275.4121 - val_loss: 45.0528\n",
      "Epoch 66/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 39.9443 - val_loss: 19.7437\n",
      "Epoch 67/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 20.3693 - val_loss: 11.3726\n",
      "Epoch 68/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 10.4289 - val_loss: 6.6958\n",
      "Epoch 69/69\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 6324.7705 - val_loss: 79.2925\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7f0f8d0ddb04e0a9befe23ef023a8dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.736 MB of 3.736 MB uploaded (0.016 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▁▁▁▁▂▁▁▁▃▁▁█▁▄▁▁▁▄▁▁▁▃▁▁▃▁▁▁▁▁▁▁▁▁▁▄▁▃</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▃▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>9</td></tr><tr><td>best_val_loss</td><td>0.68354</td></tr><tr><td>epoch</td><td>68</td></tr><tr><td>loss</td><td>6324.77051</td></tr><tr><td>val_loss</td><td>79.2925</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">light-sweep-73</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/nckrwujn\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/nckrwujn</a><br/>Synced 6 W&B file(s), 1 media file(s), 17 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_091257-nckrwujn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: imhfgrov with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5990684384704583\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 69\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.026840306526142055\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 176\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 210\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 77\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 208\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091536-imhfgrov</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/imhfgrov\" target=\"_blank\">silver-sweep-74</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/69\n",
      "2264/2291 [============================>.] - ETA: 0s - loss: 1.4052INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091536-imhfgrov/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091536-imhfgrov/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1.4001 - val_loss: 0.8433\n",
      "Epoch 2/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 51103.7891 - val_loss: 1525.0826\n",
      "Epoch 3/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 401.8165 - val_loss: 73.2833\n",
      "Epoch 4/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 117.7020 - val_loss: 27.0375\n",
      "Epoch 5/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 75155.4922 - val_loss: 866.4185\n",
      "Epoch 6/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 476.7255 - val_loss: 112.6320\n",
      "Epoch 7/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 128.6664 - val_loss: 44.2571\n",
      "Epoch 8/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 40.2228 - val_loss: 31.6205\n",
      "Epoch 9/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 75650.4062 - val_loss: 716.6531\n",
      "Epoch 10/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 578.4471 - val_loss: 138.7099\n",
      "Epoch 11/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 162.6044 - val_loss: 138.4494\n",
      "Epoch 12/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 96990.2656 - val_loss: 2282.7354\n",
      "Epoch 13/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1101.7826 - val_loss: 324.9203\n",
      "Epoch 14/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 275.9985 - val_loss: 126.1851\n",
      "Epoch 15/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 149029.5625 - val_loss: 2709.3076\n",
      "Epoch 16/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1723.1527 - val_loss: 406.1772\n",
      "Epoch 17/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 472.0687 - val_loss: 1554.4105\n",
      "Epoch 18/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 191947.7031 - val_loss: 1332.4156\n",
      "Epoch 19/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 749.3141 - val_loss: 307.7798\n",
      "Epoch 20/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 291.4102 - val_loss: 154.1014\n",
      "Epoch 21/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 173277.9531 - val_loss: 1523.2834\n",
      "Epoch 22/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 878.9574 - val_loss: 247.4297\n",
      "Epoch 23/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 329.4571 - val_loss: 101.2656\n",
      "Epoch 24/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 182.6574 - val_loss: 31.1320\n",
      "Epoch 25/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 143560.9844 - val_loss: 1309.3375\n",
      "Epoch 26/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 895.6745 - val_loss: 523.4899\n",
      "Epoch 27/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 287.6582 - val_loss: 150.6678\n",
      "Epoch 28/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 146404.4062 - val_loss: 7023.4072\n",
      "Epoch 29/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2033.6721 - val_loss: 544.5009\n",
      "Epoch 30/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 553.1251 - val_loss: 225.5643\n",
      "Epoch 31/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 180.6747 - val_loss: 42.7059\n",
      "Epoch 32/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 94.6767 - val_loss: 15.5251\n",
      "Epoch 33/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 16.2787 - val_loss: 9.4586\n",
      "Epoch 34/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 112273.3906 - val_loss: 901.0745\n",
      "Epoch 35/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 539.2937 - val_loss: 187.9884\n",
      "Epoch 36/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 201.4111 - val_loss: 83.8168\n",
      "Epoch 37/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 106041.0312 - val_loss: 1616.0901\n",
      "Epoch 38/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1320.0068 - val_loss: 581.1761\n",
      "Epoch 39/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 400.5389 - val_loss: 114.3144\n",
      "Epoch 40/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 141.6942 - val_loss: 75.9240\n",
      "Epoch 41/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 55606.9492 - val_loss: 1108.8005\n",
      "Epoch 42/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 687.9675 - val_loss: 231.7387\n",
      "Epoch 43/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 187.4109 - val_loss: 67.1912\n",
      "Epoch 44/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 9703.6797 - val_loss: 4872417.5000\n",
      "Epoch 45/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 63537.8359 - val_loss: 426.9857\n",
      "Epoch 46/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 321.7464 - val_loss: 114.8078\n",
      "Epoch 47/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 103.4026 - val_loss: 40.7699\n",
      "Epoch 48/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 138183.1875 - val_loss: 2062.8416\n",
      "Epoch 49/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1439.1366 - val_loss: 453.6045\n",
      "Epoch 50/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 424.0735 - val_loss: 114.1858\n",
      "Epoch 51/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 136.2158 - val_loss: 58.8245\n",
      "Epoch 52/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 48.8669 - val_loss: 21.3680\n",
      "Epoch 53/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 21.4226 - val_loss: 13.6723\n",
      "Epoch 54/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 291004.9375 - val_loss: 1058.4235\n",
      "Epoch 55/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1163.5345 - val_loss: 340.7608\n",
      "Epoch 56/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 416.4717 - val_loss: 173.7327\n",
      "Epoch 57/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 64520.4688 - val_loss: 1441.4193\n",
      "Epoch 58/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 669.5607 - val_loss: 187.2492\n",
      "Epoch 59/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 204.2451 - val_loss: 88.0471\n",
      "Epoch 60/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 26875.3535 - val_loss: 1047.6486\n",
      "Epoch 61/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 511.2896 - val_loss: 127.6736\n",
      "Epoch 62/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 107.5274 - val_loss: 37.9668\n",
      "Epoch 63/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 54939.6055 - val_loss: 1335.5046\n",
      "Epoch 64/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 882.8709 - val_loss: 290.1628\n",
      "Epoch 65/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 250.7520 - val_loss: 66.2327\n",
      "Epoch 66/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 87.2551 - val_loss: 20.5410\n",
      "Epoch 67/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 24.1789 - val_loss: 16.6265\n",
      "Epoch 68/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 73987.7188 - val_loss: 487.3746\n",
      "Epoch 69/69\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 385.5890 - val_loss: 176.3582\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a69000f7dfe54aa3af4610bb13a59504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='2.543 MB of 2.543 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▃▁▁▁▄▁▁▁▁█▁▇▁▆▁▆▁▁▅▁▅▁▃▁▁▁▆▁▁▁▁▁▁▂▁▃▁▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.84332</td></tr><tr><td>epoch</td><td>68</td></tr><tr><td>loss</td><td>385.58899</td></tr><tr><td>val_loss</td><td>176.35817</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">silver-sweep-74</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/imhfgrov\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/imhfgrov</a><br/>Synced 6 W&B file(s), 1 media file(s), 5 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_091536-imhfgrov/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: th1olyvq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.13448093132227368\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 38\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001599630672571495\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 178\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 87\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 209\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 194\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091932-th1olyvq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/th1olyvq\" target=\"_blank\">trim-sweep-75</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/38\n",
      "2286/2291 [============================>.] - ETA: 0s - loss: 0.8172INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091932-th1olyvq/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091932-th1olyvq/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 0.8172 - val_loss: 0.7923\n",
      "Epoch 2/38\n",
      "2255/2291 [============================>.] - ETA: 0s - loss: 0.7556INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091932-th1olyvq/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091932-th1olyvq/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 0.7551 - val_loss: 0.7122\n",
      "Epoch 3/38\n",
      "2281/2291 [============================>.] - ETA: 0s - loss: 0.7290INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091932-th1olyvq/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091932-th1olyvq/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 0.7285 - val_loss: 0.6933\n",
      "Epoch 4/38\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 0.7122 - val_loss: 0.7087\n",
      "Epoch 5/38\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 0.7086 - val_loss: 0.7056\n",
      "Epoch 6/38\n",
      "2265/2291 [============================>.] - ETA: 0s - loss: 0.6994INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091932-th1olyvq/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091932-th1olyvq/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 0.6991 - val_loss: 0.6801\n",
      "Epoch 7/38\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.6944 - val_loss: 0.7976\n",
      "Epoch 8/38\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 0.6900 - val_loss: 0.6821\n",
      "Epoch 9/38\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 0.6844 - val_loss: 0.7208\n",
      "Epoch 10/38\n",
      "2264/2291 [============================>.] - ETA: 0s - loss: 0.6826INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091932-th1olyvq/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091932-th1olyvq/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 0.6818 - val_loss: 0.6725\n",
      "Epoch 11/38\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.6811 - val_loss: 0.6830\n",
      "Epoch 12/38\n",
      "2260/2291 [============================>.] - ETA: 0s - loss: 0.6774INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091932-th1olyvq/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091932-th1olyvq/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 0.6776 - val_loss: 0.6710\n",
      "Epoch 13/38\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 0.6756 - val_loss: 0.6836\n",
      "Epoch 14/38\n",
      "2287/2291 [============================>.] - ETA: 0s - loss: 0.6755INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091932-th1olyvq/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091932-th1olyvq/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 0.6755 - val_loss: 0.6680\n",
      "Epoch 15/38\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 0.6711 - val_loss: 0.6806\n",
      "Epoch 16/38\n",
      "2285/2291 [============================>.] - ETA: 0s - loss: 0.6716INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091932-th1olyvq/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091932-th1olyvq/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 0.6715 - val_loss: 0.6610\n",
      "Epoch 17/38\n",
      "2260/2291 [============================>.] - ETA: 0s - loss: 0.6679INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091932-th1olyvq/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091932-th1olyvq/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 0.6678 - val_loss: 0.6595\n",
      "Epoch 18/38\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.6707 - val_loss: 0.6767\n",
      "Epoch 19/38\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.6659 - val_loss: 0.7231\n",
      "Epoch 20/38\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.6638 - val_loss: 0.7039\n",
      "Epoch 21/38\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 0.6645 - val_loss: 0.6722\n",
      "Epoch 22/38\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 0.6627 - val_loss: 0.6714\n",
      "Epoch 23/38\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 0.6650 - val_loss: 0.6830\n",
      "Epoch 24/38\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 0.6633 - val_loss: 0.6795\n",
      "Epoch 25/38\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 0.6623 - val_loss: 0.6906\n",
      "Epoch 26/38\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 0.6611 - val_loss: 0.7140\n",
      "Epoch 27/38\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 0.6589 - val_loss: 0.6765\n",
      "Epoch 28/38\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.6614 - val_loss: 0.6704\n",
      "Epoch 29/38\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 0.6565 - val_loss: 0.6619\n",
      "Epoch 30/38\n",
      "2256/2291 [============================>.] - ETA: 0s - loss: 0.6563INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091932-th1olyvq/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091932-th1olyvq/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 0.6559 - val_loss: 0.6572\n",
      "Epoch 31/38\n",
      "2261/2291 [============================>.] - ETA: 0s - loss: 0.6564INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091932-th1olyvq/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_091932-th1olyvq/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 0.6570 - val_loss: 0.6524\n",
      "Epoch 32/38\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.6567 - val_loss: 0.6739\n",
      "Epoch 33/38\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 0.6575 - val_loss: 0.6536\n",
      "Epoch 34/38\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 0.6562 - val_loss: 0.6843\n",
      "Epoch 35/38\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 0.6562 - val_loss: 0.6706\n",
      "Epoch 36/38\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 0.6527 - val_loss: 0.6898\n",
      "Epoch 37/38\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.6593 - val_loss: 0.6606\n",
      "Epoch 38/38\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 0.6532 - val_loss: 0.6798\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fe3b42cf794468a88c39eee94f17483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='18.934 MB of 18.934 MB uploaded (0.016 MB deduped)\\r'), FloatProgress(value=1.0, m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▄▃▄▄▂█▂▄▂▂▂▃▂▂▁▁▂▄▃▂▂▂▂▃▄▂▂▁▁▁▂▁▃▂▃▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>30</td></tr><tr><td>best_val_loss</td><td>0.65243</td></tr><tr><td>epoch</td><td>37</td></tr><tr><td>loss</td><td>0.65315</td></tr><tr><td>val_loss</td><td>0.67976</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">trim-sweep-75</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/th1olyvq\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/th1olyvq</a><br/>Synced 6 W&B file(s), 1 media file(s), 45 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_091932-th1olyvq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: de5mk3n4 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.012085155391357547\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 69\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0702146982943237\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 108\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 147\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 152\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 197\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 126\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_092201-de5mk3n4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/de5mk3n4\" target=\"_blank\">silvery-sweep-76</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/69\n",
      "1138/1146 [============================>.] - ETA: 0s - loss: 1056.7072INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_092201-de5mk3n4/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_092201-de5mk3n4/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 3ms/step - loss: 1050.2061 - val_loss: 1.5120\n",
      "Epoch 2/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1.2575 - val_loss: 2.9612\n",
      "Epoch 3/69\n",
      "1142/1146 [============================>.] - ETA: 0s - loss: 1.0108INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_092201-de5mk3n4/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_092201-de5mk3n4/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 2ms/step - loss: 1.0107 - val_loss: 0.8736\n",
      "Epoch 4/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 160597376.0000 - val_loss: 525116.0625\n",
      "Epoch 5/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 188633.2188 - val_loss: 160771.8594\n",
      "Epoch 6/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 94269.7734 - val_loss: 786020.8125\n",
      "Epoch 7/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 67181.1250 - val_loss: 53710.6211\n",
      "Epoch 8/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 5599072.0000 - val_loss: 100612.2422\n",
      "Epoch 9/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 49238.8945 - val_loss: 24007.0898\n",
      "Epoch 10/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 12172.2314 - val_loss: 20808.9941\n",
      "Epoch 11/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 7508.4736 - val_loss: 6802.4302\n",
      "Epoch 12/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 10374.0391 - val_loss: 1362.0192\n",
      "Epoch 13/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1770.9541 - val_loss: 1377.4010\n",
      "Epoch 14/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 59487448.0000 - val_loss: 918086.9375\n",
      "Epoch 15/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 290689.3750 - val_loss: 94514.4609\n",
      "Epoch 16/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 83391.9219 - val_loss: 103665.7266\n",
      "Epoch 17/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 44092.9180 - val_loss: 439054.9688\n",
      "Epoch 18/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 31147.1973 - val_loss: 19534.1992\n",
      "Epoch 19/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 11521.4004 - val_loss: 6636.6543\n",
      "Epoch 20/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 7893.4990 - val_loss: 25837.2617\n",
      "Epoch 21/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 392809408.0000 - val_loss: 6455219.0000\n",
      "Epoch 22/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2200913.0000 - val_loss: 960739.6875\n",
      "Epoch 23/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1644961.2500 - val_loss: 266670.8125\n",
      "Epoch 24/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 314657.0938 - val_loss: 234386.6406\n",
      "Epoch 25/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 199792.9219 - val_loss: 133972.5156\n",
      "Epoch 26/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 288061504.0000 - val_loss: 5065680.0000\n",
      "Epoch 27/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1898239.0000 - val_loss: 4028945.5000\n",
      "Epoch 28/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 729905.0625 - val_loss: 1667820.7500\n",
      "Epoch 29/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 482854.8125 - val_loss: 398062.9062\n",
      "Epoch 30/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 273444.0312 - val_loss: 384628.4375\n",
      "Epoch 31/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 192550.0781 - val_loss: 1051608.2500\n",
      "Epoch 32/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1018132.6875 - val_loss: 48617.6484\n",
      "Epoch 33/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 30624.0430 - val_loss: 33070.3516\n",
      "Epoch 34/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 18703.7754 - val_loss: 15120.9951\n",
      "Epoch 35/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 637454720.0000 - val_loss: 3942116.0000\n",
      "Epoch 36/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1610407.2500 - val_loss: 1119221.3750\n",
      "Epoch 37/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 782090.3750 - val_loss: 421574.6562\n",
      "Epoch 38/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 508761.7188 - val_loss: 1187907.0000\n",
      "Epoch 39/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 392319.3125 - val_loss: 160775.7344\n",
      "Epoch 40/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 181614.9375 - val_loss: 88534.5078\n",
      "Epoch 41/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 115230.9922 - val_loss: 141336.1406\n",
      "Epoch 42/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 384707840.0000 - val_loss: 5952754.0000\n",
      "Epoch 43/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2217786.7500 - val_loss: 1753007.8750\n",
      "Epoch 44/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 891433.5625 - val_loss: 1057842.8750\n",
      "Epoch 45/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 497229.6875 - val_loss: 187899.8906\n",
      "Epoch 46/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 330635776.0000 - val_loss: 3897093.2500\n",
      "Epoch 47/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2002006.6250 - val_loss: 1665831.5000\n",
      "Epoch 48/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 968000.0000 - val_loss: 535619.3750\n",
      "Epoch 49/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 569515.1875 - val_loss: 400197.5000\n",
      "Epoch 50/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 396319.4375 - val_loss: 254606.4688\n",
      "Epoch 51/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 284182304.0000 - val_loss: 3267789.7500\n",
      "Epoch 52/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1691215.3750 - val_loss: 1678359.0000\n",
      "Epoch 53/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 726280.3125 - val_loss: 533897.6875\n",
      "Epoch 54/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 427520.5000 - val_loss: 306571.4375\n",
      "Epoch 55/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 271914.3438 - val_loss: 169248.1406\n",
      "Epoch 56/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 414266944.0000 - val_loss: 20836090.0000\n",
      "Epoch 57/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2896671.7500 - val_loss: 1338685.7500\n",
      "Epoch 58/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1317959.6250 - val_loss: 1931544.0000\n",
      "Epoch 59/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 690595.6250 - val_loss: 4898093.5000\n",
      "Epoch 60/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 461173.5938 - val_loss: 207318.4219\n",
      "Epoch 61/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 211784.4688 - val_loss: 447145.0625\n",
      "Epoch 62/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 349824.6875 - val_loss: 79886.9141\n",
      "Epoch 63/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 62387.0586 - val_loss: 103512.3672\n",
      "Epoch 64/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 381761376.0000 - val_loss: 2751757.2500\n",
      "Epoch 65/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1793347.8750 - val_loss: 889578.2500\n",
      "Epoch 66/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 657934.4375 - val_loss: 2346461.2500\n",
      "Epoch 67/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 494966.9375 - val_loss: 1191463.5000\n",
      "Epoch 68/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 15152859.0000 - val_loss: 225797.2656\n",
      "Epoch 69/69\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 198732.7188 - val_loss: 114860.4844\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▃▁▁▁▁▁▂▁▁▁▅▁▁▁▁▁▁▁█▁▁▁▅▁▅▁▁▄▁▁▆▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▃▁▁▂▂▁▁▁▂▁▁▁▃▁▂▁▁▂▁▁█▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>2</td></tr><tr><td>best_val_loss</td><td>0.87363</td></tr><tr><td>epoch</td><td>68</td></tr><tr><td>loss</td><td>198732.71875</td></tr><tr><td>val_loss</td><td>114860.48438</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">silvery-sweep-76</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/de5mk3n4\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/de5mk3n4</a><br/>Synced 6 W&B file(s), 1 media file(s), 9 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_092201-de5mk3n4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lw7kxtu8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5426051846986268\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 78\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.048422365560993136\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 97\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 86\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 188\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 82\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 103\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_092445-lw7kxtu8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/lw7kxtu8\" target=\"_blank\">magic-sweep-77</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/78\n",
      "2258/2291 [============================>.] - ETA: 0s - loss: 3.4173INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_092445-lw7kxtu8/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_092445-lw7kxtu8/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 3.3815 - val_loss: 0.8511\n",
      "Epoch 2/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 644775.9375 - val_loss: 8935.4326\n",
      "Epoch 3/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3958.7734 - val_loss: 1367.6013\n",
      "Epoch 4/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 898.9719 - val_loss: 297.8658\n",
      "Epoch 5/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2330900.7500 - val_loss: 14101.7158\n",
      "Epoch 6/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 8708.4814 - val_loss: 2694.2661\n",
      "Epoch 7/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 9058.9502 - val_loss: 1387.7610\n",
      "Epoch 8/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 603.6575 - val_loss: 230.1842\n",
      "Epoch 9/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 721203.4375 - val_loss: 5283.3960\n",
      "Epoch 10/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 4510.3647 - val_loss: 1305.0670\n",
      "Epoch 11/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1217.2518 - val_loss: 371.8930\n",
      "Epoch 12/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 373.0697 - val_loss: 146.5123\n",
      "Epoch 13/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 690450.9375 - val_loss: 2142.4045\n",
      "Epoch 14/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2386.0049 - val_loss: 1113.0481\n",
      "Epoch 15/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 896621.6250 - val_loss: 38791.9531\n",
      "Epoch 16/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 12601.0938 - val_loss: 3316.0713\n",
      "Epoch 17/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2890.1792 - val_loss: 1239.9999\n",
      "Epoch 18/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 850.0751 - val_loss: 321.4232\n",
      "Epoch 19/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1282873.8750 - val_loss: 118899.7422\n",
      "Epoch 20/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 22126.3242 - val_loss: 5194.0967\n",
      "Epoch 21/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 4243.0410 - val_loss: 1775.1415\n",
      "Epoch 22/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1458.9270 - val_loss: 520.6978\n",
      "Epoch 23/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 777228.6875 - val_loss: 3117.5623\n",
      "Epoch 24/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3896.5229 - val_loss: 1372.8402\n",
      "Epoch 25/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1269.8740 - val_loss: 521.7642\n",
      "Epoch 26/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1793421.6250 - val_loss: 37116.3906\n",
      "Epoch 27/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 16847.9727 - val_loss: 4349.7642\n",
      "Epoch 28/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 380418.9062 - val_loss: 4970.3311\n",
      "Epoch 29/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 4113.6567 - val_loss: 1551.4520\n",
      "Epoch 30/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1197.9908 - val_loss: 307.2630\n",
      "Epoch 31/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 344.6880 - val_loss: 150.7107\n",
      "Epoch 32/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 102.4654 - val_loss: 39.5773\n",
      "Epoch 33/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 827509.9375 - val_loss: 4903.8711\n",
      "Epoch 34/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 4334.7349 - val_loss: 1760.7961\n",
      "Epoch 35/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1305.7263 - val_loss: 460.7150\n",
      "Epoch 36/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 368.0723 - val_loss: 148.1940\n",
      "Epoch 37/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 185.1456 - val_loss: 112.3082\n",
      "Epoch 38/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1231182.5000 - val_loss: 7520.1958\n",
      "Epoch 39/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 6468.8467 - val_loss: 1408.0576\n",
      "Epoch 40/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1555.8928 - val_loss: 555.9314\n",
      "Epoch 41/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1167522.8750 - val_loss: 9564.7578\n",
      "Epoch 42/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 10376.9170 - val_loss: 3410.0291\n",
      "Epoch 43/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3160.2158 - val_loss: 827.7886\n",
      "Epoch 44/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 614807.3750 - val_loss: 101388.2109\n",
      "Epoch 45/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 14188.4434 - val_loss: 2974.0396\n",
      "Epoch 46/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2545.3301 - val_loss: 798.7110\n",
      "Epoch 47/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1676087.5000 - val_loss: 80492.6875\n",
      "Epoch 48/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 27818.9102 - val_loss: 9039.8496\n",
      "Epoch 49/78\n",
      "2291/2291 [==============================] - 2s 1ms/step - loss: 5394.3975 - val_loss: 2280.7244\n",
      "Epoch 50/78\n",
      "2291/2291 [==============================] - 2s 1ms/step - loss: 1816.8486 - val_loss: 745.4617\n",
      "Epoch 51/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1293229.5000 - val_loss: 134435.7656\n",
      "Epoch 52/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 28451.5273 - val_loss: 5630.4258\n",
      "Epoch 53/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 5705.4780 - val_loss: 1596.3851\n",
      "Epoch 54/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 605871.4375 - val_loss: 18518.7109\n",
      "Epoch 55/78\n",
      "2291/2291 [==============================] - 2s 1ms/step - loss: 9431.3066 - val_loss: 3514.2002\n",
      "Epoch 56/78\n",
      "2291/2291 [==============================] - 2s 1ms/step - loss: 2422.2146 - val_loss: 779.5300\n",
      "Epoch 57/78\n",
      "2291/2291 [==============================] - 2s 966us/step - loss: 619.0115 - val_loss: 228.8873\n",
      "Epoch 58/78\n",
      "2291/2291 [==============================] - 2s 1ms/step - loss: 307.2791 - val_loss: 131.6250\n",
      "Epoch 59/78\n",
      "2291/2291 [==============================] - 2s 1000us/step - loss: 935362.2500 - val_loss: 5827.9980\n",
      "Epoch 60/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 4340.2114 - val_loss: 1288.6313\n",
      "Epoch 61/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1351.1805 - val_loss: 516.0511\n",
      "Epoch 62/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2496344.2500 - val_loss: 79960.3594\n",
      "Epoch 63/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 27615.5996 - val_loss: 10512.5283\n",
      "Epoch 64/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 7970.9346 - val_loss: 3158.0132\n",
      "Epoch 65/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2608586.7500 - val_loss: 28748.7500\n",
      "Epoch 66/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 26588.1387 - val_loss: 8701.4053\n",
      "Epoch 67/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 8738.2900 - val_loss: 2699.8428\n",
      "Epoch 68/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2881.8494 - val_loss: 1197.2687\n",
      "Epoch 69/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2326484.2500 - val_loss: 20496614.0000\n",
      "Epoch 70/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 127271.5000 - val_loss: 9424.9746\n",
      "Epoch 71/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 9719.4033 - val_loss: 3419.6621\n",
      "Epoch 72/78\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3124.9861 - val_loss: 1070.9625\n",
      "Epoch 73/78\n",
      "2291/2291 [==============================] - 2s 1ms/step - loss: 997265.3125 - val_loss: 74713.1562\n",
      "Epoch 74/78\n",
      "2291/2291 [==============================] - 2s 1ms/step - loss: 21888.2754 - val_loss: 3659.0576\n",
      "Epoch 75/78\n",
      "2291/2291 [==============================] - 2s 1ms/step - loss: 4127.3335 - val_loss: 1154.3083\n",
      "Epoch 76/78\n",
      "2291/2291 [==============================] - 2s 1ms/step - loss: 1324.0203 - val_loss: 552.1765\n",
      "Epoch 77/78\n",
      "2291/2291 [==============================] - 2s 1ms/step - loss: 2703158.7500 - val_loss: 269017.3750\n",
      "Epoch 78/78\n",
      "2291/2291 [==============================] - 2s 1ms/step - loss: 59129.5078 - val_loss: 13018.4785\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▃▁▁▁▁▁▁▁▁▁▁▁▆▂▁▁▁▁▄▁▁▃▁▁▁▁▃▁▁▁█▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▁▂▁▁▁▁▁▁▁▁▁▁▁▄▁▁▁▁▁▂▁▁█▁▂▁▁▂▁▁▁▇▁▂▁▂▁▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.85107</td></tr><tr><td>epoch</td><td>77</td></tr><tr><td>loss</td><td>59129.50781</td></tr><tr><td>val_loss</td><td>13018.47852</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">magic-sweep-77</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/lw7kxtu8\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/lw7kxtu8</a><br/>Synced 6 W&B file(s), 1 media file(s), 5 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_092445-lw7kxtu8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7mfo7h5j with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5856833965379119\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 77\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.07357526546896133\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 114\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 79\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 213\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 141\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 251\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_092826-7mfo7h5j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/7mfo7h5j\" target=\"_blank\">visionary-sweep-78</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/77\n",
      "1490/1527 [============================>.] - ETA: 0s - loss: 1145.6531INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_092826-7mfo7h5j/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_092826-7mfo7h5j/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1118.1191 - val_loss: 1.3182\n",
      "Epoch 2/77\n",
      "1520/1527 [============================>.] - ETA: 0s - loss: 1.4494INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_092826-7mfo7h5j/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_092826-7mfo7h5j/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1.4487 - val_loss: 0.8095\n",
      "Epoch 3/77\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 1.0851 - val_loss: 0.8979\n",
      "Epoch 4/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 229159440.0000 - val_loss: 458301.6875\n",
      "Epoch 5/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 465017.3438 - val_loss: 259023.4062\n",
      "Epoch 6/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 195856.7031 - val_loss: 75525.9297\n",
      "Epoch 7/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 80393.6953 - val_loss: 48448.6641\n",
      "Epoch 8/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 233246880.0000 - val_loss: 201822464.0000\n",
      "Epoch 9/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 5170920.5000 - val_loss: 637058.2500\n",
      "Epoch 10/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 677048.5625 - val_loss: 386403.6562\n",
      "Epoch 11/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 316296.0000 - val_loss: 90437.0469\n",
      "Epoch 12/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 138027.2812 - val_loss: 84823.1953\n",
      "Epoch 13/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 164263536.0000 - val_loss: 1309102.3750\n",
      "Epoch 14/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 881126.1250 - val_loss: 353367.7188\n",
      "Epoch 15/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 390593.7500 - val_loss: 179983.7344\n",
      "Epoch 16/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 167497.3281 - val_loss: 79069.2422\n",
      "Epoch 17/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 66616.3125 - val_loss: 24774.6680\n",
      "Epoch 18/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 194163600.0000 - val_loss: 10896816.0000\n",
      "Epoch 19/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 2527868.7500 - val_loss: 516844.9062\n",
      "Epoch 20/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 635283.9375 - val_loss: 268433.1875\n",
      "Epoch 21/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 317146.4375 - val_loss: 177925.4375\n",
      "Epoch 22/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 154997.5156 - val_loss: 152999.0781\n",
      "Epoch 23/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 78390680.0000 - val_loss: 725394.4375\n",
      "Epoch 24/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 505971.8438 - val_loss: 174903.2500\n",
      "Epoch 25/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 231737.7500 - val_loss: 88205.6562\n",
      "Epoch 26/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 109187.4922 - val_loss: 41224.4766\n",
      "Epoch 27/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 152372032.0000 - val_loss: 1330910.5000\n",
      "Epoch 28/77\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 1256699.8750 - val_loss: 439032.3438\n",
      "Epoch 29/77\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 417589.3750 - val_loss: 173000.5625\n",
      "Epoch 30/77\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 233609.6406 - val_loss: 118426.0078\n",
      "Epoch 31/77\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 926562176.0000 - val_loss: 3983563.7500\n",
      "Epoch 32/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 4733631.5000 - val_loss: 4434398.5000\n",
      "Epoch 33/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 2045574.1250 - val_loss: 1225278.3750\n",
      "Epoch 34/77\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 973159.4375 - val_loss: 507389.4688\n",
      "Epoch 35/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 553984.8125 - val_loss: 242857.7969\n",
      "Epoch 36/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 480860864.0000 - val_loss: 1598305.3750\n",
      "Epoch 37/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 2129319.2500 - val_loss: 1222227.2500\n",
      "Epoch 38/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 943800.7500 - val_loss: 410508.0312\n",
      "Epoch 39/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 428267.4062 - val_loss: 216563.5312\n",
      "Epoch 40/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 294222.5312 - val_loss: 74845.4688\n",
      "Epoch 41/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 386468736.0000 - val_loss: 2654926.0000\n",
      "Epoch 42/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 2030172.0000 - val_loss: 823697.4375\n",
      "Epoch 43/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 899916.5625 - val_loss: 437789.8438\n",
      "Epoch 44/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 444999.3125 - val_loss: 243317.3750\n",
      "Epoch 45/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 238022.0469 - val_loss: 73728.3828\n",
      "Epoch 46/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 287192896.0000 - val_loss: 2076976.2500\n",
      "Epoch 47/77\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 2587764.2500 - val_loss: 1402774.3750\n",
      "Epoch 48/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 997759.9375 - val_loss: 305336.6562\n",
      "Epoch 49/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 455336.1562 - val_loss: 184449.4688\n",
      "Epoch 50/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 241257.1875 - val_loss: 104989.5859\n",
      "Epoch 51/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 216637056.0000 - val_loss: 1790705.1250\n",
      "Epoch 52/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1878543.7500 - val_loss: 817374.3125\n",
      "Epoch 53/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 833861.1250 - val_loss: 366572.8750\n",
      "Epoch 54/77\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 435225.4688 - val_loss: 161972.7500\n",
      "Epoch 55/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 311696256.0000 - val_loss: 7769271.0000\n",
      "Epoch 56/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 3742173.7500 - val_loss: 770516.9375\n",
      "Epoch 57/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1283673.2500 - val_loss: 647973.3750\n",
      "Epoch 58/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 614963.7500 - val_loss: 318487.9688\n",
      "Epoch 59/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 290071.0625 - val_loss: 147824.4062\n",
      "Epoch 60/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 136872.0625 - val_loss: 54721.2070\n",
      "Epoch 61/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 64178.3555 - val_loss: 36294.5547\n",
      "Epoch 62/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 168875888.0000 - val_loss: 1309748.8750\n",
      "Epoch 63/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 921824.0000 - val_loss: 426240.1875\n",
      "Epoch 64/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 492167.7812 - val_loss: 245906.8906\n",
      "Epoch 65/77\n",
      "1527/1527 [==============================] - 2s 2ms/step - loss: 262988.5312 - val_loss: 389895.6875\n",
      "Epoch 66/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 141484.3594 - val_loss: 57375.9297\n",
      "Epoch 67/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 56907.1406 - val_loss: 20493.5879\n",
      "Epoch 68/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 260359712.0000 - val_loss: 1765295.7500\n",
      "Epoch 69/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1530204.0000 - val_loss: 628569.8750\n",
      "Epoch 70/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 752191.3125 - val_loss: 340904.5625\n",
      "Epoch 71/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 412809.8438 - val_loss: 202662.3906\n",
      "Epoch 72/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 195375.6719 - val_loss: 111899.9531\n",
      "Epoch 73/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 182407808.0000 - val_loss: 2013602.1250\n",
      "Epoch 74/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1592939.3750 - val_loss: 773168.1875\n",
      "Epoch 75/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 655302.8125 - val_loss: 386675.0625\n",
      "Epoch 76/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 321838.4375 - val_loss: 140060.9375\n",
      "Epoch 77/77\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 152182.1875 - val_loss: 58050.6602\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▄▁▄▁▁▁▁▄▁▁▁▁▁▁▁▁█▁▁▇▁▁▁▁▄▁▆▁▁▁▁▁▁▁▁▄▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>1</td></tr><tr><td>best_val_loss</td><td>0.80946</td></tr><tr><td>epoch</td><td>76</td></tr><tr><td>loss</td><td>152182.1875</td></tr><tr><td>val_loss</td><td>58050.66016</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">visionary-sweep-78</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/7mfo7h5j\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/7mfo7h5j</a><br/>Synced 6 W&B file(s), 1 media file(s), 9 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_092826-7mfo7h5j/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9uwpj2ce with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.02852155927740965\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 56\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0948918947764631\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 253\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 181\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 98\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_093157-9uwpj2ce</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/9uwpj2ce\" target=\"_blank\">kind-sweep-79</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/56\n",
      "1127/1146 [============================>.] - ETA: 0s - loss: 6108.9038INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_093157-9uwpj2ce/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_093157-9uwpj2ce/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 2ms/step - loss: 6012.6240 - val_loss: 3.3281\n",
      "Epoch 2/56\n",
      "1121/1146 [============================>.] - ETA: 0s - loss: 2.8317INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_093157-9uwpj2ce/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_093157-9uwpj2ce/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 3ms/step - loss: 2.8077 - val_loss: 2.2343\n",
      "Epoch 3/56\n",
      "1134/1146 [============================>.] - ETA: 0s - loss: 1.6509INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_093157-9uwpj2ce/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_093157-9uwpj2ce/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 2ms/step - loss: 1.6482 - val_loss: 1.5816\n",
      "Epoch 4/56\n",
      "1133/1146 [============================>.] - ETA: 0s - loss: 1.2579INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_093157-9uwpj2ce/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_093157-9uwpj2ce/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 2ms/step - loss: 1.2564 - val_loss: 1.0548\n",
      "Epoch 5/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1.7423 - val_loss: 1.2805\n",
      "Epoch 6/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 0.9158 - val_loss: 1.1059\n",
      "Epoch 7/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1750030720.0000 - val_loss: 22245312.0000\n",
      "Epoch 8/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 5265717.5000 - val_loss: 1049028.3750\n",
      "Epoch 9/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1646854.0000 - val_loss: 900877.8750\n",
      "Epoch 10/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 697172.4375 - val_loss: 1202331.2500\n",
      "Epoch 11/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 494754.0625 - val_loss: 223559.7031\n",
      "Epoch 12/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 262695.4375 - val_loss: 1037376.5625\n",
      "Epoch 13/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 219368.0156 - val_loss: 145078.1406\n",
      "Epoch 14/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1674546688.0000 - val_loss: 10788419.0000\n",
      "Epoch 15/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 4264688.5000 - val_loss: 1983725.3750\n",
      "Epoch 16/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1529255.2500 - val_loss: 1281360.6250\n",
      "Epoch 17/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1045626.5625 - val_loss: 498431.2812\n",
      "Epoch 18/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 580190.4375 - val_loss: 532394.5625\n",
      "Epoch 19/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 330363.4375 - val_loss: 283271.4062\n",
      "Epoch 20/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2907196416.0000 - val_loss: 74192880.0000\n",
      "Epoch 21/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 25621096.0000 - val_loss: 42622208.0000\n",
      "Epoch 22/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 6781356.5000 - val_loss: 3509797.2500\n",
      "Epoch 23/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 3992991.7500 - val_loss: 1862024.1250\n",
      "Epoch 24/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2045611.2500 - val_loss: 979121.3750\n",
      "Epoch 25/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1825540736.0000 - val_loss: 13076502.0000\n",
      "Epoch 26/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 6905996.0000 - val_loss: 5470532.5000\n",
      "Epoch 27/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 3373898.0000 - val_loss: 1791427.8750\n",
      "Epoch 28/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1577773.3750 - val_loss: 1101544.3750\n",
      "Epoch 29/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1076894.5000 - val_loss: 567492.0000\n",
      "Epoch 30/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 701827456.0000 - val_loss: 12828964864.0000\n",
      "Epoch 31/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 107665608.0000 - val_loss: 1756386.2500\n",
      "Epoch 32/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1985753.2500 - val_loss: 1245894.0000\n",
      "Epoch 33/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1251980.3750 - val_loss: 1103315.5000\n",
      "Epoch 34/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 790117.3125 - val_loss: 573820.2500\n",
      "Epoch 35/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 452039.2812 - val_loss: 229377.8438\n",
      "Epoch 36/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 283689.6250 - val_loss: 264411.4062\n",
      "Epoch 37/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1330597888.0000 - val_loss: 55840568.0000\n",
      "Epoch 38/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 11765692.0000 - val_loss: 3204405.5000\n",
      "Epoch 39/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 3192294.7500 - val_loss: 9674235.0000\n",
      "Epoch 40/56\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 1802092.5000 - val_loss: 2912873.7500\n",
      "Epoch 41/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1023751.6875 - val_loss: 855360.5000\n",
      "Epoch 42/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 695521.3125 - val_loss: 444169.9375\n",
      "Epoch 43/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 910189248.0000 - val_loss: 23801682.0000\n",
      "Epoch 44/56\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 6975414.5000 - val_loss: 2508859.0000\n",
      "Epoch 45/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2067112.0000 - val_loss: 1949136.8750\n",
      "Epoch 46/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1613421.8750 - val_loss: 690657.5000\n",
      "Epoch 47/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1053736.5000 - val_loss: 1719368.5000\n",
      "Epoch 48/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 595021.2500 - val_loss: 1429292.7500\n",
      "Epoch 49/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2113064576.0000 - val_loss: 30703150.0000\n",
      "Epoch 50/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 11324324.0000 - val_loss: 3814998.0000\n",
      "Epoch 51/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 5877051.0000 - val_loss: 2417304.2500\n",
      "Epoch 52/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 3388529.5000 - val_loss: 1284991.1250\n",
      "Epoch 53/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 3163561216.0000 - val_loss: 66495448.0000\n",
      "Epoch 54/56\n",
      "1146/1146 [==============================] - 2s 1ms/step - loss: 22782830.0000 - val_loss: 11519493.0000\n",
      "Epoch 55/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 11142378.0000 - val_loss: 8071092.5000\n",
      "Epoch 56/56\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 5123977.0000 - val_loss: 11056169.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d5525abcd54abc88688dc5778420d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='5.613 MB of 5.613 MB uploaded (0.016 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▇▁▁▁▁▁▁▃▁▁▁▁▄▁▁▁▃▁▁▁▁▁▁█▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>3</td></tr><tr><td>best_val_loss</td><td>1.05484</td></tr><tr><td>epoch</td><td>55</td></tr><tr><td>loss</td><td>5123977.0</td></tr><tr><td>val_loss</td><td>11056169.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">kind-sweep-79</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/9uwpj2ce\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/9uwpj2ce</a><br/>Synced 6 W&B file(s), 1 media file(s), 17 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_093157-9uwpj2ce/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: uvbv6j19 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4060593649425672\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.07690561124934722\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 253\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 166\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 233\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 230\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 182\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_093355-uvbv6j19</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/uvbv6j19\" target=\"_blank\">snowy-sweep-80</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "4545/4581 [============================>.] - ETA: 0s - loss: 476096224.0000INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_093355-uvbv6j19/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_093355-uvbv6j19/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4581/4581 [==============================] - 7s 2ms/step - loss: 472477216.0000 - val_loss: 4612171.0000\n",
      "Epoch 2/75\n",
      "4560/4581 [============================>.] - ETA: 0s - loss: 2236939.5000INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_093355-uvbv6j19/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_093355-uvbv6j19/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4581/4581 [==============================] - 7s 2ms/step - loss: 2229166.0000 - val_loss: 434708.9062\n",
      "Epoch 3/75\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 678199936.0000 - val_loss: 6588383.5000\n",
      "Epoch 4/75\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 3879749.2500 - val_loss: 443022.4062\n",
      "Epoch 5/75\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 186964224.0000 - val_loss: 1514383.8750\n",
      "Epoch 6/75\n",
      "4547/4581 [============================>.] - ETA: 0s - loss: 722097.3750INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_093355-uvbv6j19/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_093355-uvbv6j19/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4581/4581 [==============================] - 7s 2ms/step - loss: 718640.5000 - val_loss: 137614.0938\n",
      "Epoch 7/75\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 954407296.0000 - val_loss: 25825272.0000\n",
      "Epoch 8/75\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 11190235.0000 - val_loss: 2895102.7500\n",
      "Epoch 9/75\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1582790.2500 - val_loss: 238880.0938\n",
      "Epoch 10/75\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1087097728.0000 - val_loss: 9801663.0000\n",
      "Epoch 11/75\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 5829186.5000 - val_loss: 1576178.3750\n",
      "Epoch 12/75\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 595576832.0000 - val_loss: 21503082.0000\n",
      "Epoch 13/75\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 6929893.5000 - val_loss: 1035815.0625\n",
      "Epoch 14/75\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 736339264.0000 - val_loss: 5260963.5000\n",
      "Epoch 15/75\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 3346022.7500 - val_loss: 1394111.7500\n",
      "Epoch 16/75\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 669404736.0000 - val_loss: 2229514.0000\n",
      "Epoch 17/75\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 915590272.0000 - val_loss: 6607882.5000\n",
      "Epoch 18/75\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 5185362.0000 - val_loss: 1043663.7500\n",
      "Epoch 19/75\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 487463584.0000 - val_loss: 2450874.2500\n",
      "Epoch 20/75\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 577780416.0000 - val_loss: 28064514.0000\n",
      "Epoch 21/75\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 4734101.0000 - val_loss: 987683.9375\n",
      "Epoch 22/75\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 870267328.0000 - val_loss: 17985236.0000\n",
      "Epoch 23/75\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 6839106.5000 - val_loss: 1112890.2500\n",
      "Epoch 24/75\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 254329488.0000 - val_loss: 2890576.5000\n",
      "Epoch 25/75\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2036236.7500 - val_loss: 590312.5625\n",
      "Epoch 26/75\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 552615424.0000 - val_loss: 6214585.0000\n",
      "Epoch 27/75\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 3754921.2500 - val_loss: 1542492.3750\n",
      "Epoch 28/75\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 506556096.0000 - val_loss: 6921529.0000\n",
      "Epoch 29/75\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 4234542.5000 - val_loss: 1381062.2500\n",
      "Epoch 30/75\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1089531.2500 - val_loss: 393511.4688\n",
      "Epoch 31/75\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 684944640.0000 - val_loss: 1608457.1250\n",
      "Epoch 32/75\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 148545200.0000 - val_loss: 1204358.2500\n",
      "Epoch 33/75\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1004203.2500 - val_loss: 146913.3594\n",
      "Epoch 34/75\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 589908224.0000 - val_loss: 2849895.7500\n",
      "Epoch 35/75\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1505238.7500 - val_loss: 409687.9375\n",
      "Epoch 36/75\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 235420112.0000 - val_loss: 1320718.8750\n",
      "Epoch 37/75\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 646449664.0000 - val_loss: 5134298.0000\n",
      "Epoch 38/75\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 3874449.7500 - val_loss: 717234.1875\n",
      "Epoch 39/75\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1124760448.0000 - val_loss: 5468102.5000\n",
      "Epoch 40/75\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 3519948.2500 - val_loss: 633386.8125\n",
      "Epoch 41/75\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 676308608.0000 - val_loss: 4916970.0000\n",
      "Epoch 42/75\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1436042624.0000 - val_loss: 54346888.0000\n",
      "Epoch 43/75\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 20511900.0000 - val_loss: 3418604.5000\n",
      "Epoch 44/75\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 3872970.7500 - val_loss: 857776.4375\n",
      "Epoch 45/75\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1172311296.0000 - val_loss: 4204436.5000\n",
      "Epoch 46/75\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 5829991.0000 - val_loss: 999155.8125\n",
      "Epoch 47/75\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 594122048.0000 - val_loss: 5341546.0000\n",
      "Epoch 48/75\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 735181888.0000 - val_loss: 31457620.0000\n",
      "Epoch 49/75\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 12618941.0000 - val_loss: 2603243.5000\n",
      "Epoch 50/75\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 693034752.0000 - val_loss: 5214402.5000\n",
      "Epoch 51/75\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 2705244.2500 - val_loss: 684729.0000\n",
      "Epoch 52/75\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 641015488.0000 - val_loss: 2295612.5000\n",
      "Epoch 53/75\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 663909184.0000 - val_loss: 2809719.5000\n",
      "Epoch 54/75\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1538314752.0000 - val_loss: 21769332.0000\n",
      "Epoch 55/75\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 66266780.0000 - val_loss: 2880699.7500\n",
      "Epoch 56/75\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1742730.7500 - val_loss: 1252907.0000\n",
      "Epoch 57/75\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 719641600.0000 - val_loss: 5384808.0000\n",
      "Epoch 58/75\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 361308256.0000 - val_loss: 6671070.5000\n",
      "Epoch 59/75\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 4020835.0000 - val_loss: 1306693.7500\n",
      "Epoch 60/75\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 899370752.0000 - val_loss: 12296445.0000\n",
      "Epoch 61/75\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 8181911.0000 - val_loss: 2384037.2500\n",
      "Epoch 62/75\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 661419968.0000 - val_loss: 9217074.0000\n",
      "Epoch 63/75\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 5194104.0000 - val_loss: 1122301.3750\n",
      "Epoch 64/75\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 526385952.0000 - val_loss: 5580691.5000\n",
      "Epoch 65/75\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 34905848.0000 - val_loss: 1284424.0000\n",
      "Epoch 66/75\n",
      "4558/4581 [============================>.] - ETA: 0s - loss: 606788.8125INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_093355-uvbv6j19/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_093355-uvbv6j19/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4581/4581 [==============================] - 7s 1ms/step - loss: 604400.3750 - val_loss: 110404.5547\n",
      "Epoch 67/75\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 575493312.0000 - val_loss: 4041220.0000\n",
      "Epoch 68/75\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1019985536.0000 - val_loss: 10529704.0000\n",
      "Epoch 69/75\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 7362764.5000 - val_loss: 2823769.0000\n",
      "Epoch 70/75\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 819310464.0000 - val_loss: 4165996.2500\n",
      "Epoch 71/75\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 462523936.0000 - val_loss: 35715412.0000\n",
      "Epoch 72/75\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 10822573.0000 - val_loss: 3113847.5000\n",
      "Epoch 73/75\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 238258560.0000 - val_loss: 5403573.0000\n",
      "Epoch 74/75\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 3251500.2500 - val_loss: 650656.4375\n",
      "Epoch 75/75\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 669290816.0000 - val_loss: 4952326.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b7b40f68a8e421a84c8d32346e3c091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='11.528 MB of 11.528 MB uploaded (0.016 MB deduped)\\r'), FloatProgress(value=1.0, m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▃▁▁▁▁▆▄▄▄▁▃▁▁▁▁▁▄▁▁▄▁▁█▁▁▄▄▄█▁▄▁▁▁▁▄▁▃▂▄</td></tr><tr><td>val_loss</td><td>▂▁▁▁▁▂▄▂▁▁▁▁▁▁▁▁▁▁▁▂▁▁█▁▁▅▂▁▄▁▂▁▁▁▁▂▁▆▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>65</td></tr><tr><td>best_val_loss</td><td>110404.55469</td></tr><tr><td>epoch</td><td>74</td></tr><tr><td>loss</td><td>669290816.0</td></tr><tr><td>val_loss</td><td>4952326.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">snowy-sweep-80</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/uvbv6j19\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/uvbv6j19</a><br/>Synced 6 W&B file(s), 1 media file(s), 17 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_093355-uvbv6j19/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: crra9r00 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1526554187878432\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 92\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.08752965316183127\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 127\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 115\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 214\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 175\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 198\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_094126-crra9r00</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/crra9r00\" target=\"_blank\">frosty-sweep-81</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/92\n",
      "2261/2291 [============================>.] - ETA: 0s - loss: 4785.7417INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_094126-crra9r00/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_094126-crra9r00/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 5s 2ms/step - loss: 4724.9482 - val_loss: 3.2265\n",
      "Epoch 2/92\n",
      "2257/2291 [============================>.] - ETA: 0s - loss: 2.1786INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_094126-crra9r00/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_094126-crra9r00/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 2.1664 - val_loss: 0.9861\n",
      "Epoch 3/92\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 982278528.0000 - val_loss: 5268414.5000\n",
      "Epoch 4/92\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 2521028.7500 - val_loss: 488613.8750\n",
      "Epoch 5/92\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 249130496.0000 - val_loss: 3045315.0000\n",
      "Epoch 6/92\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1180629.2500 - val_loss: 637372.8750\n",
      "Epoch 7/92\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1476717312.0000 - val_loss: 30254234.0000\n",
      "Epoch 8/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 11366627.0000 - val_loss: 2699511.5000\n",
      "Epoch 9/92\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 2900142.0000 - val_loss: 1584206.2500\n",
      "Epoch 10/92\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1205961728.0000 - val_loss: 13308819.0000\n",
      "Epoch 11/92\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 4908249.0000 - val_loss: 2248768.0000\n",
      "Epoch 12/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1802212.0000 - val_loss: 827377.9375\n",
      "Epoch 13/92\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 552276544.0000 - val_loss: 5074752.5000\n",
      "Epoch 14/92\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 2910649.2500 - val_loss: 985711.4375\n",
      "Epoch 15/92\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 918598.0625 - val_loss: 354135.0625\n",
      "Epoch 16/92\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 859091264.0000 - val_loss: 7488021.5000\n",
      "Epoch 17/92\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 6045978.5000 - val_loss: 10063096.0000\n",
      "Epoch 18/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1998144.8750 - val_loss: 687711.1875\n",
      "Epoch 19/92\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1665161088.0000 - val_loss: 642500672.0000\n",
      "Epoch 20/92\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 41113628.0000 - val_loss: 9009279.0000\n",
      "Epoch 21/92\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 6078004.0000 - val_loss: 4488918.0000\n",
      "Epoch 22/92\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 938328640.0000 - val_loss: 7315328.5000\n",
      "Epoch 23/92\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 6182172.5000 - val_loss: 3577460.0000\n",
      "Epoch 24/92\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1019828736.0000 - val_loss: 28179906.0000\n",
      "Epoch 25/92\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 9966886.0000 - val_loss: 3124431.7500\n",
      "Epoch 26/92\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 3007591.5000 - val_loss: 1285030.3750\n",
      "Epoch 27/92\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1231189.0000 - val_loss: 689323.6875\n",
      "Epoch 28/92\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 930742784.0000 - val_loss: 11199346.0000\n",
      "Epoch 29/92\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 6749354.5000 - val_loss: 3381635.0000\n",
      "Epoch 30/92\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 2496477.7500 - val_loss: 2557514.7500\n",
      "Epoch 31/92\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 695385856.0000 - val_loss: 11335848.0000\n",
      "Epoch 32/92\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 4453158.0000 - val_loss: 2220882.0000\n",
      "Epoch 33/92\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1333236608.0000 - val_loss: 48059040.0000\n",
      "Epoch 34/92\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 16543537.0000 - val_loss: 5099527.5000\n",
      "Epoch 35/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 4927606.5000 - val_loss: 2806934.5000\n",
      "Epoch 36/92\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 880095488.0000 - val_loss: 30852440.0000\n",
      "Epoch 37/92\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 9103853.0000 - val_loss: 2889573.2500\n",
      "Epoch 38/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2604579.2500 - val_loss: 1351806.8750\n",
      "Epoch 39/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1460593.3750 - val_loss: 2065538.7500\n",
      "Epoch 40/92\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 981250944.0000 - val_loss: 5209761.0000\n",
      "Epoch 41/92\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 4343766.0000 - val_loss: 1448068.8750\n",
      "Epoch 42/92\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1631614.8750 - val_loss: 857972.8750\n",
      "Epoch 43/92\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 781395.3125 - val_loss: 423335.1875\n",
      "Epoch 44/92\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1370042368.0000 - val_loss: 4991064.5000\n",
      "Epoch 45/92\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 4510450.0000 - val_loss: 2235271.0000\n",
      "Epoch 46/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2536581.5000 - val_loss: 1120685.1250\n",
      "Epoch 47/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1531511040.0000 - val_loss: 23814568.0000\n",
      "Epoch 48/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 6519533.5000 - val_loss: 2281821.2500\n",
      "Epoch 49/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2421829.7500 - val_loss: 1283892.8750\n",
      "Epoch 50/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 864939008.0000 - val_loss: 12761502.0000\n",
      "Epoch 51/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 6340195.5000 - val_loss: 3778601.5000\n",
      "Epoch 52/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2611608.5000 - val_loss: 1323748.7500\n",
      "Epoch 53/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1005807872.0000 - val_loss: 27215026.0000\n",
      "Epoch 54/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 7847235.0000 - val_loss: 3728071.2500\n",
      "Epoch 55/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1323819008.0000 - val_loss: 18113280.0000\n",
      "Epoch 56/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 12811571.0000 - val_loss: 6080443.5000\n",
      "Epoch 57/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 4543397.0000 - val_loss: 2086375.5000\n",
      "Epoch 58/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1808041.7500 - val_loss: 805103.6875\n",
      "Epoch 59/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1530864896.0000 - val_loss: 41136528.0000\n",
      "Epoch 60/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 14415066.0000 - val_loss: 7529358.0000\n",
      "Epoch 61/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 4759693.5000 - val_loss: 2704469.0000\n",
      "Epoch 62/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2028774.8750 - val_loss: 1981760.0000\n",
      "Epoch 63/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 995678.3125 - val_loss: 658656.0625\n",
      "Epoch 64/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1531538176.0000 - val_loss: 16069682.0000\n",
      "Epoch 65/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 8197154.0000 - val_loss: 3954569.5000\n",
      "Epoch 66/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3140837.5000 - val_loss: 2417816.7500\n",
      "Epoch 67/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 870078784.0000 - val_loss: 8726375.0000\n",
      "Epoch 68/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 7796791.0000 - val_loss: 2716610.5000\n",
      "Epoch 69/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2506407.0000 - val_loss: 1661628.3750\n",
      "Epoch 70/92\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 1012189.7500 - val_loss: 667165.2500\n",
      "Epoch 71/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 804410944.0000 - val_loss: 16252905.0000\n",
      "Epoch 72/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 9887813.0000 - val_loss: 4278751.0000\n",
      "Epoch 73/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 3238341.2500 - val_loss: 1479148.6250\n",
      "Epoch 74/92\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1325990.6250 - val_loss: 554951.5625\n",
      "Epoch 75/92\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 1507906688.0000 - val_loss: 8397400.0000\n",
      "Epoch 76/92\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 8033399.0000 - val_loss: 2876313.0000\n",
      "Epoch 77/92\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 3132180.5000 - val_loss: 2406486.2500\n",
      "Epoch 78/92\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1265520768.0000 - val_loss: 30737142.0000\n",
      "Epoch 79/92\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 14518475.0000 - val_loss: 5848595.5000\n",
      "Epoch 80/92\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 2697121536.0000 - val_loss: 66156868.0000\n",
      "Epoch 81/92\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 31038248.0000 - val_loss: 14200504.0000\n",
      "Epoch 82/92\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 9459466.0000 - val_loss: 6217797.0000\n",
      "Epoch 83/92\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 3833268.7500 - val_loss: 3561628.7500\n",
      "Epoch 84/92\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1731407616.0000 - val_loss: 36678052.0000\n",
      "Epoch 85/92\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 11862423.0000 - val_loss: 4867061.0000\n",
      "Epoch 86/92\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 4420897.0000 - val_loss: 1957249.0000\n",
      "Epoch 87/92\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 2322319360.0000 - val_loss: 26976074.0000\n",
      "Epoch 88/92\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 14754582.0000 - val_loss: 6794690.0000\n",
      "Epoch 89/92\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 5709092.5000 - val_loss: 4890207.5000\n",
      "Epoch 90/92\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 3512027648.0000 - val_loss: 204070128.0000\n",
      "Epoch 91/92\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 80787592.0000 - val_loss: 28487198.0000\n",
      "Epoch 92/92\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 15143940.0000 - val_loss: 5606873.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c027be7ccd54e0290a0527ff536d210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='4.556 MB of 4.556 MB uploaded (0.016 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▄▂▁▄▁▁▁▅▃▄▁▁▃▄▃▁▄▁▁▅▃▁▁▁▅▁▅▁▁▃▁▅▄█▁▁▇▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁█▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>1</td></tr><tr><td>best_val_loss</td><td>0.98612</td></tr><tr><td>epoch</td><td>91</td></tr><tr><td>loss</td><td>15143940.0</td></tr><tr><td>val_loss</td><td>5606873.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">frosty-sweep-81</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/crra9r00\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/crra9r00</a><br/>Synced 6 W&B file(s), 1 media file(s), 9 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_094126-crra9r00/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: biotdw3p with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.21798999550026\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 54\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.09159415984248676\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 147\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 86\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 230\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 78\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 115\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_094654-biotdw3p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/biotdw3p\" target=\"_blank\">restful-sweep-82</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/54\n",
      "1133/1146 [============================>.] - ETA: 0s - loss: 2593.8699INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_094654-biotdw3p/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_094654-biotdw3p/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 2ms/step - loss: 2566.5808 - val_loss: 2.4692\n",
      "Epoch 2/54\n",
      "1133/1146 [============================>.] - ETA: 0s - loss: 1.7126INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_094654-biotdw3p/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_094654-biotdw3p/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 3s 3ms/step - loss: 1.7069 - val_loss: 1.9711\n",
      "Epoch 3/54\n",
      "1117/1146 [============================>.] - ETA: 0s - loss: 1.4154INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_094654-biotdw3p/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_094654-biotdw3p/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1.4058 - val_loss: 0.9029\n",
      "Epoch 4/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 852430080.0000 - val_loss: 982030.8125\n",
      "Epoch 5/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 625759.1250 - val_loss: 510902.1562\n",
      "Epoch 6/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 333381.6250 - val_loss: 358646.8750\n",
      "Epoch 7/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 204005.9844 - val_loss: 486539.0625\n",
      "Epoch 8/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 134045.3125 - val_loss: 311224.1875\n",
      "Epoch 9/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 76501.0391 - val_loss: 72408.5625\n",
      "Epoch 10/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 210231264.0000 - val_loss: 831755.7500\n",
      "Epoch 11/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 461605.2500 - val_loss: 657284.0000\n",
      "Epoch 12/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 221266.7969 - val_loss: 122887.8281\n",
      "Epoch 13/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 147434.0938 - val_loss: 58626.3672\n",
      "Epoch 14/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 89293.0234 - val_loss: 43193.5820\n",
      "Epoch 15/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 52115.8672 - val_loss: 36554.6367\n",
      "Epoch 16/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 23340.6348 - val_loss: 10090.7822\n",
      "Epoch 17/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 912722112.0000 - val_loss: 12415671.0000\n",
      "Epoch 18/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 7283836.5000 - val_loss: 4604749.5000\n",
      "Epoch 19/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2665932.0000 - val_loss: 1232018.2500\n",
      "Epoch 20/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1212548.8750 - val_loss: 678539.9375\n",
      "Epoch 21/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 666804.8125 - val_loss: 352515.0938\n",
      "Epoch 22/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 340414.7188 - val_loss: 126177.3281\n",
      "Epoch 23/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 195734.4844 - val_loss: 155161.8594\n",
      "Epoch 24/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 299246432.0000 - val_loss: 2134777.5000\n",
      "Epoch 25/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1161110.7500 - val_loss: 2954145.2500\n",
      "Epoch 26/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 591798.3750 - val_loss: 520376.5625\n",
      "Epoch 27/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 312051.8750 - val_loss: 259806.7344\n",
      "Epoch 28/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 175049.5469 - val_loss: 103437.2422\n",
      "Epoch 29/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 108640.5156 - val_loss: 62374.4336\n",
      "Epoch 30/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 431456384.0000 - val_loss: 3604859.7500\n",
      "Epoch 31/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2337065.0000 - val_loss: 2121875.2500\n",
      "Epoch 32/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1101634.8750 - val_loss: 1545180.1250\n",
      "Epoch 33/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 616667.1875 - val_loss: 470070.0625\n",
      "Epoch 34/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 354750.5938 - val_loss: 373094.1250\n",
      "Epoch 35/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 204177.4062 - val_loss: 149277.7969\n",
      "Epoch 36/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1544496384.0000 - val_loss: 302845440.0000\n",
      "Epoch 37/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 26786530.0000 - val_loss: 11345250.0000\n",
      "Epoch 38/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 7558575.5000 - val_loss: 11108168.0000\n",
      "Epoch 39/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 4388229.0000 - val_loss: 2866124.2500\n",
      "Epoch 40/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1985285.3750 - val_loss: 1572630.8750\n",
      "Epoch 41/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1120056.2500 - val_loss: 495866.4375\n",
      "Epoch 42/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 600559.9375 - val_loss: 362481.6875\n",
      "Epoch 43/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 401312.3125 - val_loss: 140769.9531\n",
      "Epoch 44/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 865155776.0000 - val_loss: 3030705.2500\n",
      "Epoch 45/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 3253981.2500 - val_loss: 2318367.5000\n",
      "Epoch 46/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1815531.1250 - val_loss: 992658.5625\n",
      "Epoch 47/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1112529.3750 - val_loss: 679962.6875\n",
      "Epoch 48/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 694457.5000 - val_loss: 663714.0000\n",
      "Epoch 49/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 543190912.0000 - val_loss: 4799288.5000\n",
      "Epoch 50/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 2535798.5000 - val_loss: 1979850.5000\n",
      "Epoch 51/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 1193854.1250 - val_loss: 1111660.6250\n",
      "Epoch 52/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 669525.7500 - val_loss: 343214.8125\n",
      "Epoch 53/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 376858.3125 - val_loss: 397505.6875\n",
      "Epoch 54/54\n",
      "1146/1146 [==============================] - 2s 2ms/step - loss: 231755.7188 - val_loss: 88859.9766\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f1ee9decc744f6eb78be09da6f2d3e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.668 MB of 3.668 MB uploaded (0.016 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▁▁▁▁▁▂▁▁▁▁▅▁▁▁▁▂▁▁▁▁▃▁▁▁█▁▁▁▁▁▅▁▁▁▃▁▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>2</td></tr><tr><td>best_val_loss</td><td>0.90289</td></tr><tr><td>epoch</td><td>53</td></tr><tr><td>loss</td><td>231755.71875</td></tr><tr><td>val_loss</td><td>88859.97656</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">restful-sweep-82</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/biotdw3p\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/biotdw3p</a><br/>Synced 6 W&B file(s), 1 media file(s), 13 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_094654-biotdw3p/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 232m92q6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.24235138748376336\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.04847993876664633\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 191\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 220\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 145\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 255\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 186\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_094846-232m92q6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/232m92q6\" target=\"_blank\">solar-sweep-83</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/99\n",
      "2262/2291 [============================>.] - ETA: 0s - loss: 370.2036INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_094846-232m92q6/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_094846-232m92q6/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 5s 2ms/step - loss: 365.6728 - val_loss: 1.0015\n",
      "Epoch 2/99\n",
      "2280/2291 [============================>.] - ETA: 0s - loss: 0.9673INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_094846-232m92q6/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_094846-232m92q6/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 5s 2ms/step - loss: 0.9677 - val_loss: 0.7970\n",
      "Epoch 3/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 0.8742 - val_loss: 0.8523\n",
      "Epoch 4/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 0.8292 - val_loss: 0.8842\n",
      "Epoch 5/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 25444802.0000 - val_loss: 133011.4531\n",
      "Epoch 6/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 71041.5938 - val_loss: 144438.2188\n",
      "Epoch 7/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 27101.8066 - val_loss: 12993.8223\n",
      "Epoch 8/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 7815.0859 - val_loss: 3442.8525\n",
      "Epoch 9/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 39295648.0000 - val_loss: 139639.2031\n",
      "Epoch 10/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 92680.3359 - val_loss: 35350.9844\n",
      "Epoch 11/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 32630110.0000 - val_loss: 627167.9375\n",
      "Epoch 12/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 252312.9531 - val_loss: 86477.7656\n",
      "Epoch 13/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 69348.0469 - val_loss: 27043.0586\n",
      "Epoch 14/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 23512.3594 - val_loss: 6805.1289\n",
      "Epoch 15/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 41574720.0000 - val_loss: 12559222.0000\n",
      "Epoch 16/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 677049.8750 - val_loss: 247972.8281\n",
      "Epoch 17/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 103071.6641 - val_loss: 50369.8320\n",
      "Epoch 18/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 36496.7344 - val_loss: 13702.9102\n",
      "Epoch 19/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 58990428.0000 - val_loss: 3523923.0000\n",
      "Epoch 20/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 703072.6875 - val_loss: 334016.1562\n",
      "Epoch 21/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 158933.0312 - val_loss: 61072.8086\n",
      "Epoch 22/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 67201272.0000 - val_loss: 1917721.0000\n",
      "Epoch 23/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 756920.2500 - val_loss: 417708.6562\n",
      "Epoch 24/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 163149.5469 - val_loss: 117324.6016\n",
      "Epoch 25/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 67173.3750 - val_loss: 49061.1953\n",
      "Epoch 26/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 32981906.0000 - val_loss: 218048.2812\n",
      "Epoch 27/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 191308.2031 - val_loss: 97831.0938\n",
      "Epoch 28/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 47419168.0000 - val_loss: 480172.3750\n",
      "Epoch 29/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 431117.9062 - val_loss: 208860.1250\n",
      "Epoch 30/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 133419.5156 - val_loss: 83931.0156\n",
      "Epoch 31/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 57679.1289 - val_loss: 3456585.2500\n",
      "Epoch 32/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 90025176.0000 - val_loss: 966271.5625\n",
      "Epoch 33/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 377656.0938 - val_loss: 163483.9844\n",
      "Epoch 34/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 128471.5000 - val_loss: 55212.8984\n",
      "Epoch 35/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 50530.0742 - val_loss: 23916.6914\n",
      "Epoch 36/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 20191.6094 - val_loss: 8389.8838\n",
      "Epoch 37/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 65594704.0000 - val_loss: 315874.5000\n",
      "Epoch 38/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 275635.4062 - val_loss: 95439.4375\n",
      "Epoch 39/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 5142210.0000 - val_loss: 103593.2656\n",
      "Epoch 40/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 71105.4844 - val_loss: 33395.0742\n",
      "Epoch 41/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 24847.2109 - val_loss: 13788.2803\n",
      "Epoch 42/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 52628156.0000 - val_loss: 720900.9375\n",
      "Epoch 43/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 365494.4375 - val_loss: 171534.5625\n",
      "Epoch 44/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 118170.8750 - val_loss: 65856.3438\n",
      "Epoch 45/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 37130200.0000 - val_loss: 1388639.6250\n",
      "Epoch 46/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 403337.6875 - val_loss: 144166.6875\n",
      "Epoch 47/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 121947.3047 - val_loss: 53016.1367\n",
      "Epoch 48/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 34009620.0000 - val_loss: 399239.1562\n",
      "Epoch 49/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 262572.1250 - val_loss: 124978.3984\n",
      "Epoch 50/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 93246.6797 - val_loss: 47885.0117\n",
      "Epoch 51/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 40643.2070 - val_loss: 32201.4902\n",
      "Epoch 52/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 57452812.0000 - val_loss: 715313.2500\n",
      "Epoch 53/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 485719.6875 - val_loss: 171006.7188\n",
      "Epoch 54/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 154289.7812 - val_loss: 59923.5430\n",
      "Epoch 55/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 65152.8281 - val_loss: 27703.7422\n",
      "Epoch 56/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 92958960.0000 - val_loss: 776069.1875\n",
      "Epoch 57/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 522582.5000 - val_loss: 308012.3750\n",
      "Epoch 58/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 201906.8750 - val_loss: 341747.8438\n",
      "Epoch 59/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 97623.1719 - val_loss: 47946.3828\n",
      "Epoch 60/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 78503648.0000 - val_loss: 459524.0000\n",
      "Epoch 61/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 314299.0938 - val_loss: 166474.4688\n",
      "Epoch 62/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 32836000.0000 - val_loss: 442830.1875\n",
      "Epoch 63/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 285990.2188 - val_loss: 138924.0312\n",
      "Epoch 64/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 102393.9531 - val_loss: 55239.2461\n",
      "Epoch 65/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 40393388.0000 - val_loss: 4849749.0000\n",
      "Epoch 66/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 674442.5000 - val_loss: 165958.8594\n",
      "Epoch 67/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 161868.2031 - val_loss: 89924.2031\n",
      "Epoch 68/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 66756.6250 - val_loss: 32393.2461\n",
      "Epoch 69/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 33610304.0000 - val_loss: 152878.1562\n",
      "Epoch 70/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 152613.1562 - val_loss: 60079.8281\n",
      "Epoch 71/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 57690.4297 - val_loss: 29218.4043\n",
      "Epoch 72/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 31459712.0000 - val_loss: 283684.5938\n",
      "Epoch 73/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 188287.3125 - val_loss: 80641.5859\n",
      "Epoch 74/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 80114.1406 - val_loss: 28375.6738\n",
      "Epoch 75/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 36229.3320 - val_loss: 11903.5000\n",
      "Epoch 76/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 27234780.0000 - val_loss: 432787.4062\n",
      "Epoch 77/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 267080.7188 - val_loss: 105578.6250\n",
      "Epoch 78/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 87464.3203 - val_loss: 45197.4297\n",
      "Epoch 79/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 35504.1250 - val_loss: 17307.4199\n",
      "Epoch 80/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 60438396.0000 - val_loss: 1002922.7500\n",
      "Epoch 81/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 579526.1250 - val_loss: 376531.5312\n",
      "Epoch 82/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 179470.5625 - val_loss: 63170.5273\n",
      "Epoch 83/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 65249.3008 - val_loss: 36006.2344\n",
      "Epoch 84/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 56588744.0000 - val_loss: 653633.7500\n",
      "Epoch 85/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 353527.2188 - val_loss: 189213.3750\n",
      "Epoch 86/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 164673.7812 - val_loss: 61933.6523\n",
      "Epoch 87/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 42032620.0000 - val_loss: 1663564.7500\n",
      "Epoch 88/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 490988.0000 - val_loss: 264916.1250\n",
      "Epoch 89/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 211976.4844 - val_loss: 140820.1562\n",
      "Epoch 90/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 62222324.0000 - val_loss: 3238304.5000\n",
      "Epoch 91/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 869201.5000 - val_loss: 330290.8438\n",
      "Epoch 92/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 271368.1875 - val_loss: 262140.8750\n",
      "Epoch 93/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 44339956.0000 - val_loss: 898729.4375\n",
      "Epoch 94/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 547892.0000 - val_loss: 189550.7031\n",
      "Epoch 95/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 173284.7500 - val_loss: 73953.7578\n",
      "Epoch 96/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 73766.1328 - val_loss: 34869.8672\n",
      "Epoch 97/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 66878276.0000 - val_loss: 282361.6562\n",
      "Epoch 98/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 228847.6875 - val_loss: 110051.2422\n",
      "Epoch 99/99\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 122493.5703 - val_loss: 38749.2773\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▁▁▃▁▁▁▁▁▃▅▁▁▁▁▁▁▁▄▁▁█▁▁▁▁▁▁▁▃▁▁▁▁▁▁▄▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▂▁▂▁▁▂▁▂█▁▁▁▁▁▁▂▁▁▃▂▁▁▁▁▁▁▂▁▂▁▁▂▂▃▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>1</td></tr><tr><td>best_val_loss</td><td>0.79695</td></tr><tr><td>epoch</td><td>98</td></tr><tr><td>loss</td><td>122493.57031</td></tr><tr><td>val_loss</td><td>38749.27734</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">solar-sweep-83</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/232m92q6\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/232m92q6</a><br/>Synced 6 W&B file(s), 1 media file(s), 9 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_094846-232m92q6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xewivbsx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3904151216922881\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 66\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.09477430098425982\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 232\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 150\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 143\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 255\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_095531-xewivbsx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/xewivbsx\" target=\"_blank\">crimson-sweep-84</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/66\n",
      "4558/4581 [============================>.] - ETA: 0s - loss: 370938912.0000INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_095531-xewivbsx/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_095531-xewivbsx/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4581/4581 [==============================] - 7s 1ms/step - loss: 369166112.0000 - val_loss: 4556312.5000\n",
      "Epoch 2/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 229032944.0000 - val_loss: 4745609.0000\n",
      "Epoch 3/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 397091456.0000 - val_loss: 5309344.0000\n",
      "Epoch 4/66\n",
      "4544/4581 [============================>.] - ETA: 0s - loss: 2323484.5000INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_095531-xewivbsx/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_095531-xewivbsx/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4581/4581 [==============================] - 6s 1ms/step - loss: 2308982.2500 - val_loss: 275755.4062\n",
      "Epoch 5/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 835217216.0000 - val_loss: 2345927.2500\n",
      "Epoch 6/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1476998.6250 - val_loss: 575595.6875\n",
      "Epoch 7/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1281389184.0000 - val_loss: 21384592.0000\n",
      "Epoch 8/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1374324864.0000 - val_loss: 12514271.0000\n",
      "Epoch 9/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 7687084.5000 - val_loss: 1020979.1250\n",
      "Epoch 10/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 726302144.0000 - val_loss: 13396348.0000\n",
      "Epoch 11/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 6838877.5000 - val_loss: 1608042.8750\n",
      "Epoch 12/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1406406272.0000 - val_loss: 28551208.0000\n",
      "Epoch 13/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 11729023.0000 - val_loss: 2295869.5000\n",
      "Epoch 14/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 438481280.0000 - val_loss: 1900629.3750\n",
      "Epoch 15/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1327202.5000 - val_loss: 396379.6562\n",
      "Epoch 16/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 834626944.0000 - val_loss: 7268932.5000\n",
      "Epoch 17/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 3992709.0000 - val_loss: 981972.5625\n",
      "Epoch 18/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 884166272.0000 - val_loss: 3512885.5000\n",
      "Epoch 19/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1970516.1250 - val_loss: 381923.0938\n",
      "Epoch 20/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1074570752.0000 - val_loss: 17909578.0000\n",
      "Epoch 21/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 11481438.0000 - val_loss: 5518767.5000\n",
      "Epoch 22/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 2358944768.0000 - val_loss: 13308973.0000\n",
      "Epoch 23/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 11109312.0000 - val_loss: 3139981.5000\n",
      "Epoch 24/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1745655936.0000 - val_loss: 433045440.0000\n",
      "Epoch 25/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 51862672.0000 - val_loss: 4543678.0000\n",
      "Epoch 26/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 3352401664.0000 - val_loss: 15506483.0000\n",
      "Epoch 27/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 965826432.0000 - val_loss: 161219168.0000\n",
      "Epoch 28/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 27642260.0000 - val_loss: 3921055.2500\n",
      "Epoch 29/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 3135333.2500 - val_loss: 345224.5312\n",
      "Epoch 30/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1600036864.0000 - val_loss: 9574401.0000\n",
      "Epoch 31/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 6526379.5000 - val_loss: 3842298.5000\n",
      "Epoch 32/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1777718784.0000 - val_loss: 7608482.5000\n",
      "Epoch 33/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 8292938.0000 - val_loss: 2279157.5000\n",
      "Epoch 34/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 2963074304.0000 - val_loss: 13302711.0000\n",
      "Epoch 35/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1048438208.0000 - val_loss: 17649684.0000\n",
      "Epoch 36/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1790478592.0000 - val_loss: 105434312.0000\n",
      "Epoch 37/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 37260832.0000 - val_loss: 8499990.0000\n",
      "Epoch 38/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1304969728.0000 - val_loss: 29172048.0000\n",
      "Epoch 39/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 18719984.0000 - val_loss: 4342310.0000\n",
      "Epoch 40/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1799266048.0000 - val_loss: 259882848.0000\n",
      "Epoch 41/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 44897352.0000 - val_loss: 5999408.0000\n",
      "Epoch 42/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1651145344.0000 - val_loss: 44564848.0000\n",
      "Epoch 43/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 18519894.0000 - val_loss: 4852334.0000\n",
      "Epoch 44/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 824723008.0000 - val_loss: 8700692.0000\n",
      "Epoch 45/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 6132814.0000 - val_loss: 1564493.7500\n",
      "Epoch 46/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1703171072.0000 - val_loss: 9472632.0000\n",
      "Epoch 47/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 8022899.0000 - val_loss: 2269949.0000\n",
      "Epoch 48/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 2090867200.0000 - val_loss: 7932794.5000\n",
      "Epoch 49/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 3532585728.0000 - val_loss: 50107548.0000\n",
      "Epoch 50/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 26304240.0000 - val_loss: 5185199.0000\n",
      "Epoch 51/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1732825728.0000 - val_loss: 30990780.0000\n",
      "Epoch 52/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 18744370.0000 - val_loss: 5663591.5000\n",
      "Epoch 53/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 736091328.0000 - val_loss: 13018585.0000\n",
      "Epoch 54/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 7781955.0000 - val_loss: 3164288768.0000\n",
      "Epoch 55/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1260025216.0000 - val_loss: 7363083.0000\n",
      "Epoch 56/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 4650474496.0000 - val_loss: 49809240.0000\n",
      "Epoch 57/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 23895032.0000 - val_loss: 5883935.0000\n",
      "Epoch 58/66\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2604479232.0000 - val_loss: 10548458.0000\n",
      "Epoch 59/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 745030080.0000 - val_loss: 30172576.0000\n",
      "Epoch 60/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 15344786.0000 - val_loss: 4155713.7500\n",
      "Epoch 61/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 845334400.0000 - val_loss: 9867666.0000\n",
      "Epoch 62/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 6588764.0000 - val_loss: 1884426.0000\n",
      "Epoch 63/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 961573376.0000 - val_loss: 5493234.5000\n",
      "Epoch 64/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 849226240.0000 - val_loss: 108014448.0000\n",
      "Epoch 65/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 23982242.0000 - val_loss: 8429114.0000\n",
      "Epoch 66/66\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 2972805.7500 - val_loss: 921617.5625\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37f4352653834ba39bb3ebfbb1fb600f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='4.264 MB of 4.264 MB uploaded (0.016 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▂▁▁▁▃▁▁▃▂▂▁▁▁▅▄▆▂▁▁▄▅▄▁▁▁▃▂▄▁▆▄▁▁█▁▂▂▁▂▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>3</td></tr><tr><td>best_val_loss</td><td>275755.40625</td></tr><tr><td>epoch</td><td>65</td></tr><tr><td>loss</td><td>2972805.75</td></tr><tr><td>val_loss</td><td>921617.5625</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">crimson-sweep-84</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/xewivbsx\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/xewivbsx</a><br/>Synced 6 W&B file(s), 1 media file(s), 9 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_095531-xewivbsx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: b0hoxmdu with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.13146222242369965\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 56\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.02681174938738099\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 131\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 240\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 195\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 230\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 119\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_100151-b0hoxmdu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/b0hoxmdu\" target=\"_blank\">olive-sweep-85</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/56\n",
      "1515/1527 [============================>.] - ETA: 0s - loss: 5.7156INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_100151-b0hoxmdu/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_100151-b0hoxmdu/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 4s 3ms/step - loss: 5.6774 - val_loss: 0.7582\n",
      "Epoch 2/56\n",
      "1502/1527 [============================>.] - ETA: 0s - loss: 0.7810INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_100151-b0hoxmdu/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_100151-b0hoxmdu/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 4s 2ms/step - loss: 0.7807 - val_loss: 0.7308\n",
      "Epoch 3/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.7881 - val_loss: 0.7640\n",
      "Epoch 4/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.8311 - val_loss: 0.9151\n",
      "Epoch 5/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 771928.6250 - val_loss: 14748.3271\n",
      "Epoch 6/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 5110.0371 - val_loss: 1413.3682\n",
      "Epoch 7/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1618.1306 - val_loss: 629.0374\n",
      "Epoch 8/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 736.3693 - val_loss: 253.4356\n",
      "Epoch 9/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 104788.2422 - val_loss: 1926.9612\n",
      "Epoch 10/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 988.0812 - val_loss: 451.1520\n",
      "Epoch 11/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 299.4462 - val_loss: 165.8530\n",
      "Epoch 12/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 144.0673 - val_loss: 58.4469\n",
      "Epoch 13/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 73.8377 - val_loss: 43.3769\n",
      "Epoch 14/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 470787.4375 - val_loss: 1673.1976\n",
      "Epoch 15/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1280.2263 - val_loss: 786.6373\n",
      "Epoch 16/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 673.3376 - val_loss: 355.8397\n",
      "Epoch 17/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 325.1613 - val_loss: 147.0422\n",
      "Epoch 18/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 239.2024 - val_loss: 107.1665\n",
      "Epoch 19/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 423741.6250 - val_loss: 5618.0049\n",
      "Epoch 20/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 3486.0696 - val_loss: 10573.2754\n",
      "Epoch 21/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1549.5111 - val_loss: 514.6290\n",
      "Epoch 22/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 536.6431 - val_loss: 217.6597\n",
      "Epoch 23/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 252.3962 - val_loss: 81.0651\n",
      "Epoch 24/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1068711.6250 - val_loss: 19696.0234\n",
      "Epoch 25/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 6438.1758 - val_loss: 3217.5562\n",
      "Epoch 26/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 2758.6887 - val_loss: 1169.1249\n",
      "Epoch 27/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1353.9797 - val_loss: 523.9032\n",
      "Epoch 28/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 778.2917 - val_loss: 345.1637\n",
      "Epoch 29/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 454124.6250 - val_loss: 5496.4312\n",
      "Epoch 30/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 2954.5278 - val_loss: 1127.2576\n",
      "Epoch 31/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1275.0223 - val_loss: 534.2317\n",
      "Epoch 32/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 654.0898 - val_loss: 380.9040\n",
      "Epoch 33/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 393.8572 - val_loss: 155.1613\n",
      "Epoch 34/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 961867.3750 - val_loss: 4423.7324\n",
      "Epoch 35/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 4086.2629 - val_loss: 2175.8718\n",
      "Epoch 36/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1971.1956 - val_loss: 916.3298\n",
      "Epoch 37/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1190.2207 - val_loss: 532.8574\n",
      "Epoch 38/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 585.8285 - val_loss: 301.4431\n",
      "Epoch 39/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1825255.0000 - val_loss: 19983.3535\n",
      "Epoch 40/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 13150.4736 - val_loss: 3977.2471\n",
      "Epoch 41/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 5496.1172 - val_loss: 2875.4587\n",
      "Epoch 42/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 3007.1108 - val_loss: 1424.6740\n",
      "Epoch 43/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1406.9927 - val_loss: 575.7243\n",
      "Epoch 44/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 848.2884 - val_loss: 335.1396\n",
      "Epoch 45/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1865895.0000 - val_loss: 272960.3438\n",
      "Epoch 46/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 35658.2031 - val_loss: 13239.0420\n",
      "Epoch 47/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 7995.2227 - val_loss: 4695.1138\n",
      "Epoch 48/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 3775.8196 - val_loss: 1666.8040\n",
      "Epoch 49/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1960.8044 - val_loss: 871.9584\n",
      "Epoch 50/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 871.0900 - val_loss: 411.9359\n",
      "Epoch 51/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 417.6937 - val_loss: 224.8359\n",
      "Epoch 52/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1679689.8750 - val_loss: 20999.0996\n",
      "Epoch 53/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 13364.3252 - val_loss: 6566.4097\n",
      "Epoch 54/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 5630.2114 - val_loss: 3838.4114\n",
      "Epoch 55/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 2831.9375 - val_loss: 1309.3502\n",
      "Epoch 56/56\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 883684.2500 - val_loss: 7819.5688\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▁▄▁▁▁▁▁▁▁▁▁▃▁▁▁▅▁▁▃▁▁▁▅▁▁█▁▁▁▁▁▁▁▁▁▁▁▄</td></tr><tr><td>val_loss</td><td>▁▁▁▆▁▁▂▁▁▁▁▁▁▃▅▁▁█▁▁▃▁▁▁▃▁▁█▂▂▁▁▆▃▂▁▁▃▂▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>1</td></tr><tr><td>best_val_loss</td><td>0.73078</td></tr><tr><td>epoch</td><td>55</td></tr><tr><td>loss</td><td>883684.25</td></tr><tr><td>val_loss</td><td>7819.56885</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">olive-sweep-85</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/b0hoxmdu\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/b0hoxmdu</a><br/>Synced 6 W&B file(s), 1 media file(s), 9 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_100151-b0hoxmdu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 15d2vbg3 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.38644248746476817\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 61\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.022722558011026184\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 163\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 145\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 118\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 155\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 130\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_100455-15d2vbg3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/15d2vbg3\" target=\"_blank\">autumn-sweep-86</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/61\n",
      "2254/2291 [============================>.] - ETA: 0s - loss: 1.2986INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_100455-15d2vbg3/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_100455-15d2vbg3/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1.2917 - val_loss: 0.8377\n",
      "Epoch 2/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 30370.7617 - val_loss: 428.8279\n",
      "Epoch 3/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 207.3045 - val_loss: 137.0755\n",
      "Epoch 4/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 56.8022 - val_loss: 40.0397\n",
      "Epoch 5/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 17.6349 - val_loss: 28.8875\n",
      "Epoch 6/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 10160.1602 - val_loss: 82.7464\n",
      "Epoch 7/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 53.0592 - val_loss: 25.2475\n",
      "Epoch 8/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 18.2193 - val_loss: 6.1893\n",
      "Epoch 9/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 20126.6191 - val_loss: 68.0730\n",
      "Epoch 10/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 76.1734 - val_loss: 28.0490\n",
      "Epoch 11/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 76710.4297 - val_loss: 1754.3700\n",
      "Epoch 12/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 928.1037 - val_loss: 390.0712\n",
      "Epoch 13/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 197.8900 - val_loss: 60.6542\n",
      "Epoch 14/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 63.4373 - val_loss: 22.9095\n",
      "Epoch 15/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 33224.1719 - val_loss: 163.0111\n",
      "Epoch 16/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 172.9969 - val_loss: 73.6104\n",
      "Epoch 17/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 14207.2148 - val_loss: 874.3432\n",
      "Epoch 18/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 232.9822 - val_loss: 63.5002\n",
      "Epoch 19/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 54.9012 - val_loss: 18.5242\n",
      "Epoch 20/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 25530.6660 - val_loss: 52950.2930\n",
      "Epoch 21/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 835.8531 - val_loss: 127.4593\n",
      "Epoch 22/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 100.1012 - val_loss: 35.2639\n",
      "Epoch 23/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 50711.5352 - val_loss: 1569.5310\n",
      "Epoch 24/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 476.5864 - val_loss: 243.8175\n",
      "Epoch 25/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 134.8916 - val_loss: 42.7710\n",
      "Epoch 26/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 24900.1816 - val_loss: 544.6934\n",
      "Epoch 27/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 290.0583 - val_loss: 88.2534\n",
      "Epoch 28/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 89.6504 - val_loss: 34.3284\n",
      "Epoch 29/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 36.6129 - val_loss: 13.9267\n",
      "Epoch 30/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 43049.0977 - val_loss: 388.9552\n",
      "Epoch 31/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 296.5417 - val_loss: 169.5088\n",
      "Epoch 32/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 99.5098 - val_loss: 39.4699\n",
      "Epoch 33/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 43915.3047 - val_loss: 16092.9258\n",
      "Epoch 34/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1123.6615 - val_loss: 197.6489\n",
      "Epoch 35/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 220.3936 - val_loss: 60.8474\n",
      "Epoch 36/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 74.1714 - val_loss: 29.6876\n",
      "Epoch 37/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 90021.7109 - val_loss: 478.3227\n",
      "Epoch 38/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 418.2357 - val_loss: 132.4408\n",
      "Epoch 39/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 149.0199 - val_loss: 78.8470\n",
      "Epoch 40/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 74783.1953 - val_loss: 997.1609\n",
      "Epoch 41/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 606.1091 - val_loss: 357.5816\n",
      "Epoch 42/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 197.4433 - val_loss: 81.2747\n",
      "Epoch 43/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 63.2962 - val_loss: 19.4360\n",
      "Epoch 44/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 51102.3438 - val_loss: 556.7108\n",
      "Epoch 45/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 482.8510 - val_loss: 158.3401\n",
      "Epoch 46/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 158.9466 - val_loss: 63.4256\n",
      "Epoch 47/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 33321.0742 - val_loss: 582.2880\n",
      "Epoch 48/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 345.4313 - val_loss: 107.2477\n",
      "Epoch 49/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 122.6356 - val_loss: 46.0721\n",
      "Epoch 50/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 43.0885 - val_loss: 18.9378\n",
      "Epoch 51/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 14.8424 - val_loss: 15.6864\n",
      "Epoch 52/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 31787.0195 - val_loss: 191.5681\n",
      "Epoch 53/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 173.3743 - val_loss: 71.1373\n",
      "Epoch 54/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 68.4056 - val_loss: 27.9250\n",
      "Epoch 55/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 17817.5898 - val_loss: 1663.3231\n",
      "Epoch 56/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 527.0631 - val_loss: 162.4906\n",
      "Epoch 57/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 110.5997 - val_loss: 47.5266\n",
      "Epoch 58/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 40.7825 - val_loss: 17.8693\n",
      "Epoch 59/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 32409.4043 - val_loss: 336.1869\n",
      "Epoch 60/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 272.3598 - val_loss: 107.1027\n",
      "Epoch 61/61\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 88.7042 - val_loss: 37.0674\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▃▁▁▁▁▁▇▁▁▁▂▁▁▁▁▁▁▁▄▁▄▁▁█▁▁▁▅▁▄▁▁▁▁▁▁▁▄▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.83774</td></tr><tr><td>epoch</td><td>60</td></tr><tr><td>loss</td><td>88.70416</td></tr><tr><td>val_loss</td><td>37.06736</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">autumn-sweep-86</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/15d2vbg3\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/15d2vbg3</a><br/>Synced 6 W&B file(s), 1 media file(s), 5 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_100455-15d2vbg3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6g5a0rkm with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5153252837029537\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 85\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.06753061409635364\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 66\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 209\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 176\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 242\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 109\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_100815-6g5a0rkm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/6g5a0rkm\" target=\"_blank\">deep-sweep-87</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/85\n",
      "2255/2291 [============================>.] - ETA: 0s - loss: 283.5810INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_100815-6g5a0rkm/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_100815-6g5a0rkm/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 5s 2ms/step - loss: 279.2479 - val_loss: 0.9634\n",
      "Epoch 2/85\n",
      "2273/2291 [============================>.] - ETA: 0s - loss: 0.9290INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_100815-6g5a0rkm/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_100815-6g5a0rkm/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 0.9285 - val_loss: 0.8462\n",
      "Epoch 3/85\n",
      "2252/2291 [============================>.] - ETA: 0s - loss: 0.8554INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_100815-6g5a0rkm/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_100815-6g5a0rkm/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 0.8554 - val_loss: 0.8010\n",
      "Epoch 4/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 52861936.0000 - val_loss: 449368.2188\n",
      "Epoch 5/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 208865.8750 - val_loss: 64672.1094\n",
      "Epoch 6/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 56451.8789 - val_loss: 21437.3477\n",
      "Epoch 7/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 16911.3574 - val_loss: 4391.1646\n",
      "Epoch 8/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 94990608.0000 - val_loss: 788475.6250\n",
      "Epoch 9/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 582839.5000 - val_loss: 116741.9141\n",
      "Epoch 10/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 171013.1250 - val_loss: 66948.4609\n",
      "Epoch 11/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 354748928.0000 - val_loss: 21044464.0000\n",
      "Epoch 12/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 5354129.0000 - val_loss: 1111922.7500\n",
      "Epoch 13/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1076161.1250 - val_loss: 356482.9688\n",
      "Epoch 14/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 353596.5000 - val_loss: 122593.4844\n",
      "Epoch 15/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 149972352.0000 - val_loss: 2203803.2500\n",
      "Epoch 16/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1568328.3750 - val_loss: 430826.7188\n",
      "Epoch 17/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 394161.0938 - val_loss: 161655.3906\n",
      "Epoch 18/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 116523.8281 - val_loss: 40618.2461\n",
      "Epoch 19/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 109970720.0000 - val_loss: 2710192.7500\n",
      "Epoch 20/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1069574.3750 - val_loss: 362545.2188\n",
      "Epoch 21/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 291671.4688 - val_loss: 155650.0156\n",
      "Epoch 22/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 66685764.0000 - val_loss: 13831573.0000\n",
      "Epoch 23/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1719620.3750 - val_loss: 333229.4688\n",
      "Epoch 24/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 265657.9688 - val_loss: 85719.8828\n",
      "Epoch 25/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 79617.2734 - val_loss: 33007.4297\n",
      "Epoch 26/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 67605320.0000 - val_loss: 401433.5000\n",
      "Epoch 27/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 399089.8438 - val_loss: 137535.7188\n",
      "Epoch 28/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 16884704.0000 - val_loss: 300029.4375\n",
      "Epoch 29/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 174151.4375 - val_loss: 53262.1914\n",
      "Epoch 30/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 46879.4141 - val_loss: 23361.1523\n",
      "Epoch 31/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 32771776.0000 - val_loss: 459391.9062\n",
      "Epoch 32/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 363250.2812 - val_loss: 168093.5469\n",
      "Epoch 33/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 105168.3906 - val_loss: 43460.5078\n",
      "Epoch 34/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 42180.6406 - val_loss: 10540.4512\n",
      "Epoch 35/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 103233472.0000 - val_loss: 1086770.8750\n",
      "Epoch 36/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 570279.9375 - val_loss: 123442.6797\n",
      "Epoch 37/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 161490.1094 - val_loss: 67337.7578\n",
      "Epoch 38/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 68455592.0000 - val_loss: 930457.3125\n",
      "Epoch 39/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 603282.5625 - val_loss: 199615.6719\n",
      "Epoch 40/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 213145.1250 - val_loss: 70900.6172\n",
      "Epoch 41/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 69652.1719 - val_loss: 29780.0996\n",
      "Epoch 42/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 55239712.0000 - val_loss: 2709089.2500\n",
      "Epoch 43/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 849701.0625 - val_loss: 239201.0625\n",
      "Epoch 44/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 151754.6406 - val_loss: 98433.3594\n",
      "Epoch 45/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 59427996.0000 - val_loss: 390896.2188\n",
      "Epoch 46/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 310169.8438 - val_loss: 94273.6719\n",
      "Epoch 47/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 93211.1016 - val_loss: 39510.8633\n",
      "Epoch 48/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 94493192.0000 - val_loss: 3193274.0000\n",
      "Epoch 49/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1137584.7500 - val_loss: 236159.5469\n",
      "Epoch 50/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 270371.2500 - val_loss: 76640.3828\n",
      "Epoch 51/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 102804.6875 - val_loss: 33306.7344\n",
      "Epoch 52/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 61116264.0000 - val_loss: 355361.5312\n",
      "Epoch 53/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 347418.5312 - val_loss: 114663.8125\n",
      "Epoch 54/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 134746.4219 - val_loss: 48506.4570\n",
      "Epoch 55/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 56705.1055 - val_loss: 13149.5391\n",
      "Epoch 56/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 93115232.0000 - val_loss: 488929.5625\n",
      "Epoch 57/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 555988.1875 - val_loss: 189953.2031\n",
      "Epoch 58/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 191378.1562 - val_loss: 209592.5312\n",
      "Epoch 59/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 92950360.0000 - val_loss: 447481.0000\n",
      "Epoch 60/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 448124.5938 - val_loss: 112317.4766\n",
      "Epoch 61/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 138651.6875 - val_loss: 45451.6133\n",
      "Epoch 62/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 92922088.0000 - val_loss: 1090372.2500\n",
      "Epoch 63/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 625270.3750 - val_loss: 202507.5156\n",
      "Epoch 64/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 210363.0312 - val_loss: 98182.3750\n",
      "Epoch 65/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 64685280.0000 - val_loss: 825355.6875\n",
      "Epoch 66/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 536982.9375 - val_loss: 164824.0469\n",
      "Epoch 67/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 169978.9062 - val_loss: 75479.5703\n",
      "Epoch 68/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 62522.7070 - val_loss: 37540.2383\n",
      "Epoch 69/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 46053928.0000 - val_loss: 464415.0625\n",
      "Epoch 70/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 361983.8125 - val_loss: 164345.0469\n",
      "Epoch 71/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 120944.6250 - val_loss: 45879.3555\n",
      "Epoch 72/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 41409220.0000 - val_loss: 502324.4062\n",
      "Epoch 73/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 414499.7500 - val_loss: 103340.9297\n",
      "Epoch 74/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 131008.8438 - val_loss: 50799.3789\n",
      "Epoch 75/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 65284984.0000 - val_loss: 1278956.2500\n",
      "Epoch 76/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 474396.1562 - val_loss: 214012.0469\n",
      "Epoch 77/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 160011.0625 - val_loss: 79291.3438\n",
      "Epoch 78/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 131766184.0000 - val_loss: 928023.5000\n",
      "Epoch 79/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 632993.6250 - val_loss: 215333.9688\n",
      "Epoch 80/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 225051.9531 - val_loss: 107356.1016\n",
      "Epoch 81/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 374896256.0000 - val_loss: 3466397.0000\n",
      "Epoch 82/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2152276.7500 - val_loss: 681179.0625\n",
      "Epoch 83/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 633675.3750 - val_loss: 205590.7656\n",
      "Epoch 84/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 86825184.0000 - val_loss: 1772578.1250\n",
      "Epoch 85/85\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1327585.2500 - val_loss: 688800.8125\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbd1264949cd4afd9d41a06387795f9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='6.345 MB of 6.345 MB uploaded (0.016 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▁▁▁█▁▁▁▁▂▁▂▁▂▁▃▁▁▁▁▁▃▁▂▁▁▃▁▁▂▁▂▂▁▁▄▁▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁█▁▁▁▁▆▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>2</td></tr><tr><td>best_val_loss</td><td>0.80103</td></tr><tr><td>epoch</td><td>84</td></tr><tr><td>loss</td><td>1327585.25</td></tr><tr><td>val_loss</td><td>688800.8125</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">deep-sweep-87</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/6g5a0rkm\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/6g5a0rkm</a><br/>Synced 6 W&B file(s), 1 media file(s), 13 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_100815-6g5a0rkm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rnkrsde6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2150990638020296\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 66\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.024082357332360072\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 198\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 143\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 68\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 254\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 98\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_101313-rnkrsde6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/rnkrsde6\" target=\"_blank\">magic-sweep-88</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/66\n",
      "2276/2291 [============================>.] - ETA: 0s - loss: 1.2355INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_101313-rnkrsde6/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_101313-rnkrsde6/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1.2333 - val_loss: 0.7999\n",
      "Epoch 2/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 0.9075 - val_loss: 1.5474\n",
      "Epoch 3/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 33005.2578 - val_loss: 93.6746\n",
      "Epoch 4/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 68.1246 - val_loss: 19.8628\n",
      "Epoch 5/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 20.1215 - val_loss: 10.7037\n",
      "Epoch 6/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 77353.6250 - val_loss: 461.2166\n",
      "Epoch 7/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 312.8696 - val_loss: 125.0601\n",
      "Epoch 8/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 99.4599 - val_loss: 89.3524\n",
      "Epoch 9/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 22439.6016 - val_loss: 122.7239\n",
      "Epoch 10/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 116.2480 - val_loss: 60.0641\n",
      "Epoch 11/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 35.1219 - val_loss: 16.5303\n",
      "Epoch 12/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 12.0168 - val_loss: 9.0047\n",
      "Epoch 13/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 33077.0625 - val_loss: 209.7508\n",
      "Epoch 14/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 159.0055 - val_loss: 46.1822\n",
      "Epoch 15/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 64.0493 - val_loss: 24.1263\n",
      "Epoch 16/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 60528.0977 - val_loss: 638.5267\n",
      "Epoch 17/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 324.2577 - val_loss: 114.3386\n",
      "Epoch 18/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 68932.8672 - val_loss: 553.1948\n",
      "Epoch 19/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 280.9920 - val_loss: 106.9469\n",
      "Epoch 20/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 247925.1875 - val_loss: 2022.0409\n",
      "Epoch 21/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 1758.6001 - val_loss: 780.1375\n",
      "Epoch 22/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 556.1813 - val_loss: 419.8069\n",
      "Epoch 23/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 195.9430 - val_loss: 75.7863\n",
      "Epoch 24/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 60214.6211 - val_loss: 1497.4108\n",
      "Epoch 25/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 597.8234 - val_loss: 426.6179\n",
      "Epoch 26/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 183.8478 - val_loss: 62.5239\n",
      "Epoch 27/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 45716.3750 - val_loss: 802.4818\n",
      "Epoch 28/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 450.2650 - val_loss: 206.4601\n",
      "Epoch 29/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 151.8161 - val_loss: 87.3274\n",
      "Epoch 30/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 61.2698 - val_loss: 27.7843\n",
      "Epoch 31/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 24288.0898 - val_loss: 206.6361\n",
      "Epoch 32/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 154.6066 - val_loss: 70.2346\n",
      "Epoch 33/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 49.5271 - val_loss: 27.6720\n",
      "Epoch 34/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 30100.9551 - val_loss: 187.5847\n",
      "Epoch 35/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 142.4480 - val_loss: 88.6726\n",
      "Epoch 36/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 46.8761 - val_loss: 31.1524\n",
      "Epoch 37/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 33983.4688 - val_loss: 1351.0265\n",
      "Epoch 38/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 502.9006 - val_loss: 152.9883\n",
      "Epoch 39/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 148.0594 - val_loss: 67.6313\n",
      "Epoch 40/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 21330.2969 - val_loss: 424.4481\n",
      "Epoch 41/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 240.4212 - val_loss: 98.5146\n",
      "Epoch 42/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 83.3382 - val_loss: 62.1033\n",
      "Epoch 43/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 38058.7148 - val_loss: 303.9783\n",
      "Epoch 44/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 223.2958 - val_loss: 72.3358\n",
      "Epoch 45/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 77.0984 - val_loss: 54.3073\n",
      "Epoch 46/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 34.1991 - val_loss: 11.2381\n",
      "Epoch 47/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 57923.9531 - val_loss: 476.9051\n",
      "Epoch 48/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 395.4411 - val_loss: 157.0030\n",
      "Epoch 49/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 141.3553 - val_loss: 77.1220\n",
      "Epoch 50/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 60.1989 - val_loss: 22.6424\n",
      "Epoch 51/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 18873.1348 - val_loss: 144.4277\n",
      "Epoch 52/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 116.2751 - val_loss: 51.4665\n",
      "Epoch 53/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 41.4955 - val_loss: 19.4556\n",
      "Epoch 54/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 103629.1719 - val_loss: 1065.4332\n",
      "Epoch 55/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 781.2589 - val_loss: 348.7608\n",
      "Epoch 56/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 267.2954 - val_loss: 112.7126\n",
      "Epoch 57/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 42233.3477 - val_loss: 321.2811\n",
      "Epoch 58/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 243.8265 - val_loss: 160.2530\n",
      "Epoch 59/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 86.4244 - val_loss: 168.5313\n",
      "Epoch 60/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 35.4185 - val_loss: 19.1910\n",
      "Epoch 61/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 75279.0000 - val_loss: 877.7549\n",
      "Epoch 62/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 481.3922 - val_loss: 162.8728\n",
      "Epoch 63/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 154.5475 - val_loss: 81.0961\n",
      "Epoch 64/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 64.6569 - val_loss: 67.2353\n",
      "Epoch 65/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 25743.0078 - val_loss: 171.9934\n",
      "Epoch 66/66\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 111.9903 - val_loss: 42.8758\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▁▆▁▃▁▁▁▅▁▁▁▁▅▁▄▁▃▁▃▁▃▁▁▁▁▁▅▁▂▁█▁▄▁▆▁▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▃▂▂▁▁▁▄▂▁▅▃█▁▅▁▂▁▂▁▇▁▁▁▁▁▃▁▂▁▆▂▂▂▅▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.79994</td></tr><tr><td>epoch</td><td>65</td></tr><tr><td>loss</td><td>111.99029</td></tr><tr><td>val_loss</td><td>42.8758</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">magic-sweep-88</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/rnkrsde6\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/rnkrsde6</a><br/>Synced 6 W&B file(s), 1 media file(s), 5 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_101313-rnkrsde6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wewf0gkz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.28689169051128594\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 38\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.011731546890345746\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 117\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 214\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 212\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 150\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 126\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_101648-wewf0gkz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/wewf0gkz\" target=\"_blank\">young-sweep-89</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/38\n",
      "4550/4581 [============================>.] - ETA: 0s - loss: 152.1809INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_101648-wewf0gkz/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_101648-wewf0gkz/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4581/4581 [==============================] - 7s 1ms/step - loss: 151.1878 - val_loss: 1.3081\n",
      "Epoch 2/38\n",
      "4564/4581 [============================>.] - ETA: 0s - loss: 1.2582INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_101648-wewf0gkz/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_101648-wewf0gkz/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1.2572 - val_loss: 0.8603\n",
      "Epoch 3/38\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 0.8598 - val_loss: 0.8784\n",
      "Epoch 4/38\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 489.0178 - val_loss: 2.2382\n",
      "Epoch 5/38\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1.5653 - val_loss: 0.8759\n",
      "Epoch 6/38\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 222.4797 - val_loss: 1.8838\n",
      "Epoch 7/38\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1.5426 - val_loss: 0.8907\n",
      "Epoch 8/38\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 287.6874 - val_loss: 2.8304\n",
      "Epoch 9/38\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2.1988 - val_loss: 0.9605\n",
      "Epoch 10/38\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 424.1372 - val_loss: 3.6984\n",
      "Epoch 11/38\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 122.4964 - val_loss: 238.5790\n",
      "Epoch 12/38\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 6.2951 - val_loss: 1.0360\n",
      "Epoch 13/38\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 174.2331 - val_loss: 2.2451\n",
      "Epoch 14/38\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1.5081 - val_loss: 1.3504\n",
      "Epoch 15/38\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 651.9028 - val_loss: 3.0582\n",
      "Epoch 16/38\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2.2830 - val_loss: 0.8881\n",
      "Epoch 17/38\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 265.0132 - val_loss: 1.5739\n",
      "Epoch 18/38\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 470.0325 - val_loss: 12.7427\n",
      "Epoch 19/38\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 5.9162 - val_loss: 1.3462\n",
      "Epoch 20/38\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1.4826 - val_loss: 0.9634\n",
      "Epoch 21/38\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 359.1361 - val_loss: 2.1971\n",
      "Epoch 22/38\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1.7661 - val_loss: 0.9027\n",
      "Epoch 23/38\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 364.3651 - val_loss: 2.2646\n",
      "Epoch 24/38\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 136.6923 - val_loss: 10.5472\n",
      "Epoch 25/38\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2.7627 - val_loss: 1.1011\n",
      "Epoch 26/38\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1.2318 - val_loss: 0.9631\n",
      "Epoch 27/38\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 287.6930 - val_loss: 1.9966\n",
      "Epoch 28/38\n",
      "4569/4581 [============================>.] - ETA: 0s - loss: 1.3777INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_101648-wewf0gkz/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_101648-wewf0gkz/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1.3773 - val_loss: 0.8144\n",
      "Epoch 29/38\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 449.2594 - val_loss: 2.7873\n",
      "Epoch 30/38\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 271.2157 - val_loss: 10.0317\n",
      "Epoch 31/38\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 4.1977 - val_loss: 2.2623\n",
      "Epoch 32/38\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 190.4996 - val_loss: 3.2297\n",
      "Epoch 33/38\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2.1820 - val_loss: 3.6435\n",
      "Epoch 34/38\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 520.8332 - val_loss: 5.1949\n",
      "Epoch 35/38\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 259.5858 - val_loss: 9.4860\n",
      "Epoch 36/38\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 4.8979 - val_loss: 1.3290\n",
      "Epoch 37/38\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1041.0764 - val_loss: 24.4339\n",
      "Epoch 38/38\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 8.4846 - val_loss: 1.9275\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd3b6d37af1343ba9778a42c8fbc2a4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='6.482 MB of 6.503 MB uploaded (0.016 MB deduped)\\r'), FloatProgress(value=0.996875…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▂▁▁▄▁▂▁▃▁▄▂▁▂▁▅▁▃▄▁▁▃▁▃▂▁▁▃▁▄▃▁▂▁▄▃▁█▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>27</td></tr><tr><td>best_val_loss</td><td>0.81445</td></tr><tr><td>epoch</td><td>37</td></tr><tr><td>loss</td><td>8.48463</td></tr><tr><td>val_loss</td><td>1.92755</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">young-sweep-89</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/wewf0gkz\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/wewf0gkz</a><br/>Synced 6 W&B file(s), 1 media file(s), 13 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_101648-wewf0gkz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cpqrpxi7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.06747318842269497\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.095767106475226\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 225\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 129\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 215\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 102\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 210\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_102023-cpqrpxi7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/cpqrpxi7\" target=\"_blank\">sweepy-sweep-90</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/95\n",
      "4552/4581 [============================>.] - ETA: 0s - loss: 2349.8411INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_102023-cpqrpxi7/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_102023-cpqrpxi7/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4581/4581 [==============================] - 6s 1ms/step - loss: 2335.3774 - val_loss: 1.6210\n",
      "Epoch 2/95\n",
      "4581/4581 [==============================] - ETA: 0s - loss: 1.2145INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_102023-cpqrpxi7/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_102023-cpqrpxi7/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1.2145 - val_loss: 0.9314\n",
      "Epoch 3/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 409289344.0000 - val_loss: 406290.1562\n",
      "Epoch 4/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 930450240.0000 - val_loss: 5540190.0000\n",
      "Epoch 5/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1989923.1250 - val_loss: 299921.3125\n",
      "Epoch 6/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1764843520.0000 - val_loss: 16342051.0000\n",
      "Epoch 7/95\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 5825110.0000 - val_loss: 1167973.0000\n",
      "Epoch 8/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1444854272.0000 - val_loss: 7050501.0000\n",
      "Epoch 9/95\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 2485900800.0000 - val_loss: 78087816.0000\n",
      "Epoch 10/95\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 27045310.0000 - val_loss: 6063753.5000\n",
      "Epoch 11/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 8972783.0000 - val_loss: 474034.9375\n",
      "Epoch 12/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 3063688448.0000 - val_loss: 14033902.0000\n",
      "Epoch 13/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1737729792.0000 - val_loss: 24034042.0000\n",
      "Epoch 14/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 11732583.0000 - val_loss: 7644432.5000\n",
      "Epoch 15/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 233162608.0000 - val_loss: 1287004.7500\n",
      "Epoch 16/95\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 787112.5000 - val_loss: 128047.2188\n",
      "Epoch 17/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1067245760.0000 - val_loss: 3589962.0000\n",
      "Epoch 18/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 586221888.0000 - val_loss: 11630161.0000\n",
      "Epoch 19/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 3313522176.0000 - val_loss: 210424688.0000\n",
      "Epoch 20/95\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 50664796.0000 - val_loss: 10474214.0000\n",
      "Epoch 21/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2158003968.0000 - val_loss: 63506228.0000\n",
      "Epoch 22/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 27509226.0000 - val_loss: 8674705.0000\n",
      "Epoch 23/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1307842176.0000 - val_loss: 15008501.0000\n",
      "Epoch 24/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 8745289.0000 - val_loss: 3327064.5000\n",
      "Epoch 25/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 939244736.0000 - val_loss: 6390473.5000\n",
      "Epoch 26/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1336224256.0000 - val_loss: 510093344.0000\n",
      "Epoch 27/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 35716152.0000 - val_loss: 6497254.0000\n",
      "Epoch 28/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 800394368.0000 - val_loss: 21908672.0000\n",
      "Epoch 29/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 9221841.0000 - val_loss: 2279504.5000\n",
      "Epoch 30/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1616016768.0000 - val_loss: 46572088.0000\n",
      "Epoch 31/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 15740480.0000 - val_loss: 4637049.5000\n",
      "Epoch 32/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 590161984.0000 - val_loss: 5848324.5000\n",
      "Epoch 33/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2418281984.0000 - val_loss: 82517384.0000\n",
      "Epoch 34/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 33939924.0000 - val_loss: 10730283.0000\n",
      "Epoch 35/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2644472064.0000 - val_loss: 43734840.0000\n",
      "Epoch 36/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 27957676.0000 - val_loss: 9062149.0000\n",
      "Epoch 37/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1415520256.0000 - val_loss: 6900301.5000\n",
      "Epoch 38/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1172014080.0000 - val_loss: 45124752.0000\n",
      "Epoch 39/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 17759190.0000 - val_loss: 6181892.0000\n",
      "Epoch 40/95\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1210823680.0000 - val_loss: 14967563.0000\n",
      "Epoch 41/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 6761046.0000 - val_loss: 1490595.7500\n",
      "Epoch 42/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 3327659264.0000 - val_loss: 19071106.0000\n",
      "Epoch 43/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2940249088.0000 - val_loss: 63944428.0000\n",
      "Epoch 44/95\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 28174762.0000 - val_loss: 11285278.0000\n",
      "Epoch 45/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1862336896.0000 - val_loss: 46773356.0000\n",
      "Epoch 46/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 16151493.0000 - val_loss: 3317787.2500\n",
      "Epoch 47/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 881888512.0000 - val_loss: 4928520.0000\n",
      "Epoch 48/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1092378112.0000 - val_loss: 24430135296.0000\n",
      "Epoch 49/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 157248192.0000 - val_loss: 8081222.0000\n",
      "Epoch 50/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1140474240.0000 - val_loss: 9048276.0000\n",
      "Epoch 51/95\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1604683392.0000 - val_loss: 22676014.0000\n",
      "Epoch 52/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 14342567.0000 - val_loss: 4018900.2500\n",
      "Epoch 53/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 488395648.0000 - val_loss: 2262331.2500\n",
      "Epoch 54/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1637994496.0000 - val_loss: 62664148.0000\n",
      "Epoch 55/95\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 25375560.0000 - val_loss: 5740634.5000\n",
      "Epoch 56/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2979007488.0000 - val_loss: 38474744.0000\n",
      "Epoch 57/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 975980160.0000 - val_loss: 38893992.0000\n",
      "Epoch 58/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 15980816.0000 - val_loss: 3764321.2500\n",
      "Epoch 59/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1187892608.0000 - val_loss: 23184864.0000\n",
      "Epoch 60/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1488817664.0000 - val_loss: 6942387712.0000\n",
      "Epoch 61/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 70917136.0000 - val_loss: 4668043.0000\n",
      "Epoch 62/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1927868032.0000 - val_loss: 3658912256.0000\n",
      "Epoch 63/95\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 57374196.0000 - val_loss: 11045993.0000\n",
      "Epoch 64/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1385224704.0000 - val_loss: 6237238.5000\n",
      "Epoch 65/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1556496384.0000 - val_loss: 237957968.0000\n",
      "Epoch 66/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 41030968.0000 - val_loss: 25988208.0000\n",
      "Epoch 67/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 560059584.0000 - val_loss: 3716601.7500\n",
      "Epoch 68/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1404621312.0000 - val_loss: 10487583.0000\n",
      "Epoch 69/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 536576800.0000 - val_loss: 21244762.0000\n",
      "Epoch 70/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 8269892.5000 - val_loss: 2150637.5000\n",
      "Epoch 71/95\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1480195072.0000 - val_loss: 25349582.0000\n",
      "Epoch 72/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 16170595.0000 - val_loss: 3488153.0000\n",
      "Epoch 73/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1423064192.0000 - val_loss: 11589195.0000\n",
      "Epoch 74/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 7121831.0000 - val_loss: 4500732.0000\n",
      "Epoch 75/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1649547776.0000 - val_loss: 7718324.5000\n",
      "Epoch 76/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1514845440.0000 - val_loss: 39768692.0000\n",
      "Epoch 77/95\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 18586868.0000 - val_loss: 6036330.0000\n",
      "Epoch 78/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1638015232.0000 - val_loss: 16064118.0000\n",
      "Epoch 79/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 10602059.0000 - val_loss: 2835156.2500\n",
      "Epoch 80/95\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1277760640.0000 - val_loss: 7583871.0000\n",
      "Epoch 81/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 641950976.0000 - val_loss: 8487768.0000\n",
      "Epoch 82/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1387820416.0000 - val_loss: 39922172.0000\n",
      "Epoch 83/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 18366156.0000 - val_loss: 5265764.5000\n",
      "Epoch 84/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 757655360.0000 - val_loss: 19618722.0000\n",
      "Epoch 85/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 9396754.0000 - val_loss: 2406679.2500\n",
      "Epoch 86/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1460851200.0000 - val_loss: 21259044.0000\n",
      "Epoch 87/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 604242240.0000 - val_loss: 10588016.0000\n",
      "Epoch 88/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 5439811.5000 - val_loss: 1754271.1250\n",
      "Epoch 89/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2852761600.0000 - val_loss: 17778738.0000\n",
      "Epoch 90/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 3088614656.0000 - val_loss: 33417144.0000\n",
      "Epoch 91/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 22133264.0000 - val_loss: 4885832.5000\n",
      "Epoch 92/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2438206720.0000 - val_loss: 133182800.0000\n",
      "Epoch 93/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 37158332.0000 - val_loss: 11831224.0000\n",
      "Epoch 94/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2840236288.0000 - val_loss: 47842632.0000\n",
      "Epoch 95/95\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 22047376.0000 - val_loss: 7456537.5000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▂▁▄▁▅▂▃▁▁▃▁▁▂▁▄▁▁▁▁▁▅▅█▁▁▁▁▄▁▄▅▅▄▄▁▂█▇▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▂▁▁▂▁▁▁▁▁▂▁▁▁▂▁▁▂▄▃▁▁▂▂▂▁▂▁▂▁▃▁▂▃█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>1</td></tr><tr><td>best_val_loss</td><td>0.93145</td></tr><tr><td>epoch</td><td>94</td></tr><tr><td>loss</td><td>22047376.0</td></tr><tr><td>val_loss</td><td>7456537.5</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">sweepy-sweep-90</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/cpqrpxi7\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/cpqrpxi7</a><br/>Synced 6 W&B file(s), 1 media file(s), 9 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_102023-cpqrpxi7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3sur61vq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.06382995818100769\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 55\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0955393874846632\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 181\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 135\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 111\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 120\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_102911-3sur61vq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/3sur61vq\" target=\"_blank\">eternal-sweep-91</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/55\n",
      "4571/4581 [============================>.] - ETA: 0s - loss: 506072640.0000INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_102911-3sur61vq/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_102911-3sur61vq/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4581/4581 [==============================] - 7s 1ms/step - loss: 505062688.0000 - val_loss: 2069914.6250\n",
      "Epoch 2/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 224660032.0000 - val_loss: 14731153.0000\n",
      "Epoch 3/55\n",
      "4531/4581 [============================>.] - ETA: 0s - loss: 2488155.5000INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_102911-3sur61vq/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_102911-3sur61vq/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4581/4581 [==============================] - 6s 1ms/step - loss: 2466039.0000 - val_loss: 335747.0938\n",
      "Epoch 4/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 698101312.0000 - val_loss: 12283065.0000\n",
      "Epoch 5/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 3522770.5000 - val_loss: 602210.7500\n",
      "Epoch 6/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 608075520.0000 - val_loss: 3260250.5000\n",
      "Epoch 7/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 740425856.0000 - val_loss: 4253966.0000\n",
      "Epoch 8/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 664388160.0000 - val_loss: 8433940.0000\n",
      "Epoch 9/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 5354646.5000 - val_loss: 1021441.6875\n",
      "Epoch 10/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1348895744.0000 - val_loss: 10374676.0000\n",
      "Epoch 11/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 5698867.0000 - val_loss: 1452210.2500\n",
      "Epoch 12/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 561692608.0000 - val_loss: 2903226.0000\n",
      "Epoch 13/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2075790.1250 - val_loss: 425216.4688\n",
      "Epoch 14/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1617332736.0000 - val_loss: 7236003.5000\n",
      "Epoch 15/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 621541696.0000 - val_loss: 21359246.0000\n",
      "Epoch 16/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 4749149.0000 - val_loss: 1717045.6250\n",
      "Epoch 17/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1795848064.0000 - val_loss: 12402438.0000\n",
      "Epoch 18/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 676394624.0000 - val_loss: 5504692.0000\n",
      "Epoch 19/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 5059783.5000 - val_loss: 774428.0625\n",
      "Epoch 20/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 525473504.0000 - val_loss: 3146698.7500\n",
      "Epoch 21/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 686636096.0000 - val_loss: 17642640.0000\n",
      "Epoch 22/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 6706381.5000 - val_loss: 1608594.7500\n",
      "Epoch 23/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 617278080.0000 - val_loss: 3651311.7500\n",
      "Epoch 24/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2998164.2500 - val_loss: 416540.7500\n",
      "Epoch 25/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 584373632.0000 - val_loss: 3733610.5000\n",
      "Epoch 26/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 899494464.0000 - val_loss: 10576075.0000\n",
      "Epoch 27/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 6171359.5000 - val_loss: 1548149.6250\n",
      "Epoch 28/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 450403168.0000 - val_loss: 3544244.5000\n",
      "Epoch 29/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2171372.0000 - val_loss: 2399088.2500\n",
      "Epoch 30/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 584104448.0000 - val_loss: 4361004.0000\n",
      "Epoch 31/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1037941632.0000 - val_loss: 37399596.0000\n",
      "Epoch 32/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 16519767.0000 - val_loss: 3997447.0000\n",
      "Epoch 33/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 608918720.0000 - val_loss: 16968932.0000\n",
      "Epoch 34/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 7432377.0000 - val_loss: 2813627.7500\n",
      "Epoch 35/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 448903136.0000 - val_loss: 7278207.0000\n",
      "Epoch 36/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 4423953.5000 - val_loss: 1222695.6250\n",
      "Epoch 37/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 517056992.0000 - val_loss: 4351813.0000\n",
      "Epoch 38/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 2133755.7500 - val_loss: 439609.3438\n",
      "Epoch 39/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 697226112.0000 - val_loss: 4761235.5000\n",
      "Epoch 40/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 580336768.0000 - val_loss: 19865370.0000\n",
      "Epoch 41/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 8906028.0000 - val_loss: 2134657.7500\n",
      "Epoch 42/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 600444800.0000 - val_loss: 6132282.0000\n",
      "Epoch 43/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 799024320.0000 - val_loss: 8674796.0000\n",
      "Epoch 44/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 7044869.5000 - val_loss: 2277139.2500\n",
      "Epoch 45/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 591149760.0000 - val_loss: 6771408.0000\n",
      "Epoch 46/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1573191168.0000 - val_loss: 78493352.0000\n",
      "Epoch 47/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 29188180.0000 - val_loss: 5434780.5000\n",
      "Epoch 48/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 998085888.0000 - val_loss: 16785570.0000\n",
      "Epoch 49/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 12520183.0000 - val_loss: 2436576.5000\n",
      "Epoch 50/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 674428416.0000 - val_loss: 6571111.0000\n",
      "Epoch 51/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 4361045.5000 - val_loss: 978697.9375\n",
      "Epoch 52/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 745736896.0000 - val_loss: 22707024.0000\n",
      "Epoch 53/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 9796174.0000 - val_loss: 2798171.7500\n",
      "Epoch 54/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 562381952.0000 - val_loss: 6008676.0000\n",
      "Epoch 55/55\n",
      "4581/4581 [==============================] - 5s 1ms/step - loss: 1152930304.0000 - val_loss: 41660544.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▃▂▁▁▃▄▁▆▃▁▇▁█▁▃▄▃▁▃▁▃▃▅▁▁▃▃▁▄▁▃▄▃▇▅▁▄▄▁▅</td></tr><tr><td>val_loss</td><td>▁▂▁▁▁▁▁▂▁▁▂▁▂▁▁▃▁▁▁▁▁▁▄▁▁▂▁▁▁▁▂▂▂█▂▁▂▃▁▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>2</td></tr><tr><td>best_val_loss</td><td>335747.09375</td></tr><tr><td>epoch</td><td>54</td></tr><tr><td>loss</td><td>1152930304.0</td></tr><tr><td>val_loss</td><td>41660544.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">eternal-sweep-91</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/3sur61vq\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/3sur61vq</a><br/>Synced 6 W&B file(s), 1 media file(s), 9 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_102911-3sur61vq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0p3ynakj with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4114091212354859\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 44\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.032468829124221076\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 117\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 240\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 134\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 95\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_103403-0p3ynakj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/0p3ynakj\" target=\"_blank\">trim-sweep-92</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/44\n",
      "1502/1527 [============================>.] - ETA: 0s - loss: 3.3696INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_103403-0p3ynakj/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_103403-0p3ynakj/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 3s 2ms/step - loss: 3.3284 - val_loss: 0.7725\n",
      "Epoch 2/44\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 0.8069 - val_loss: 0.7932\n",
      "Epoch 3/44\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 0.8399 - val_loss: 0.8285\n",
      "Epoch 4/44\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 0.8835 - val_loss: 0.8356\n",
      "Epoch 5/44\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 351356.2812 - val_loss: 645.9467\n",
      "Epoch 6/44\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 411.8564 - val_loss: 148.7140\n",
      "Epoch 7/44\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 191.8824 - val_loss: 86.5970\n",
      "Epoch 8/44\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 108.5862 - val_loss: 60.5722\n",
      "Epoch 9/44\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 52.0343 - val_loss: 18.7389\n",
      "Epoch 10/44\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 496531.5000 - val_loss: 2457.0251\n",
      "Epoch 11/44\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 1588.9855 - val_loss: 586.2397\n",
      "Epoch 12/44\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 724.7404 - val_loss: 416.7081\n",
      "Epoch 13/44\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 337457.1875 - val_loss: 760.2434\n",
      "Epoch 14/44\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 1324.0664 - val_loss: 1042.1921\n",
      "Epoch 15/44\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 599.5280 - val_loss: 460.7544\n",
      "Epoch 16/44\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 268.5789 - val_loss: 102.9992\n",
      "Epoch 17/44\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 128.8021 - val_loss: 44.3329\n",
      "Epoch 18/44\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 223797.3906 - val_loss: 1381.3888\n",
      "Epoch 19/44\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 1528.2427 - val_loss: 838.8555\n",
      "Epoch 20/44\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 545.8074 - val_loss: 192.1867\n",
      "Epoch 21/44\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 257.4094 - val_loss: 153.0452\n",
      "Epoch 22/44\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 145.9301 - val_loss: 44.2178\n",
      "Epoch 23/44\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 1456115.7500 - val_loss: 9015.7344\n",
      "Epoch 24/44\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 6030.0034 - val_loss: 2151.5818\n",
      "Epoch 25/44\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 2541.4521 - val_loss: 1347.7640\n",
      "Epoch 26/44\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 1289.7283 - val_loss: 513.7352\n",
      "Epoch 27/44\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 616.7012 - val_loss: 237.3845\n",
      "Epoch 28/44\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 346.2715 - val_loss: 256.5827\n",
      "Epoch 29/44\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 917826.2500 - val_loss: 3391.2078\n",
      "Epoch 30/44\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 3653.1909 - val_loss: 2094.4612\n",
      "Epoch 31/44\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 1528.3253 - val_loss: 1013.6682\n",
      "Epoch 32/44\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 663.6625 - val_loss: 283.4859\n",
      "Epoch 33/44\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 507993.4688 - val_loss: 20745.5645\n",
      "Epoch 34/44\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 9730.6582 - val_loss: 2425.9509\n",
      "Epoch 35/44\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 2067.9258 - val_loss: 1073.7386\n",
      "Epoch 36/44\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 990.5795 - val_loss: 568.6273\n",
      "Epoch 37/44\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 488.0234 - val_loss: 396.8943\n",
      "Epoch 38/44\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 213104.5000 - val_loss: 4990.8276\n",
      "Epoch 39/44\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 2820.6199 - val_loss: 924.4837\n",
      "Epoch 40/44\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 1000.8894 - val_loss: 393.1692\n",
      "Epoch 41/44\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 498.9887 - val_loss: 241.2714\n",
      "Epoch 42/44\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 271.3061 - val_loss: 128.6808\n",
      "Epoch 43/44\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 134051.9531 - val_loss: 3829.2617\n",
      "Epoch 44/44\n",
      "1527/1527 [==============================] - 2s 1ms/step - loss: 1190.5831 - val_loss: 476.8856\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▁▁▃▁▁▁▁▃▁▃▁▁▁▁▂▁▁▁█▁▁▁▁▁▅▁▁▁▁▁▁▁▂▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▂▁▁▁▁▃▁▂▂▁▁▁▂▂▁▁█▃▂▁▁▁▄▃▂▁▃▂▁▁▅▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.77251</td></tr><tr><td>epoch</td><td>43</td></tr><tr><td>loss</td><td>1190.58313</td></tr><tr><td>val_loss</td><td>476.88559</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">trim-sweep-92</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/0p3ynakj\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/0p3ynakj</a><br/>Synced 6 W&B file(s), 1 media file(s), 5 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_103403-0p3ynakj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 82hz4oh3 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.21549509663716773\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 35\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0778827484052459\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 70\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 195\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 192\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 191\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 173\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_103550-82hz4oh3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/82hz4oh3\" target=\"_blank\">glad-sweep-93</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "2278/2291 [============================>.] - ETA: 0s - loss: 843.2753INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_103550-82hz4oh3/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_103550-82hz4oh3/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 7s 3ms/step - loss: 838.8252 - val_loss: 1.1569\n",
      "Epoch 2/35\n",
      "2256/2291 [============================>.] - ETA: 0s - loss: 1.3794INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_103550-82hz4oh3/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_103550-82hz4oh3/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1.3746 - val_loss: 1.1479\n",
      "Epoch 3/35\n",
      "2269/2291 [============================>.] - ETA: 0s - loss: 1.0005INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_103550-82hz4oh3/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_103550-82hz4oh3/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 5s 2ms/step - loss: 0.9998 - val_loss: 0.9824\n",
      "Epoch 4/35\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 469389440.0000 - val_loss: 1407200.8750\n",
      "Epoch 5/35\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 1070052.5000 - val_loss: 307577.0000\n",
      "Epoch 6/35\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 216119.7656 - val_loss: 121579.3594\n",
      "Epoch 7/35\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 10840438.0000 - val_loss: 72536.3750\n",
      "Epoch 8/35\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 37722.6562 - val_loss: 8970.4287\n",
      "Epoch 9/35\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 168092000.0000 - val_loss: 2484417.5000\n",
      "Epoch 10/35\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1213257.8750 - val_loss: 290786.0938\n",
      "Epoch 11/35\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 247376.2500 - val_loss: 87807.4609\n",
      "Epoch 12/35\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 145384256.0000 - val_loss: 2255359.7500\n",
      "Epoch 13/35\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 863820.6250 - val_loss: 302429.6250\n",
      "Epoch 14/35\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 303866.7188 - val_loss: 121362.1641\n",
      "Epoch 15/35\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 322448000.0000 - val_loss: 7850221.0000\n",
      "Epoch 16/35\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 2984785.0000 - val_loss: 677901.9375\n",
      "Epoch 17/35\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 744366.1875 - val_loss: 297918.4688\n",
      "Epoch 18/35\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 621107840.0000 - val_loss: 13467318.0000\n",
      "Epoch 19/35\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 5716374.0000 - val_loss: 1446874.6250\n",
      "Epoch 20/35\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1582531.1250 - val_loss: 651370.9375\n",
      "Epoch 21/35\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 615478.3750 - val_loss: 331867.5938\n",
      "Epoch 22/35\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 796447040.0000 - val_loss: 7130690.5000\n",
      "Epoch 23/35\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 2710910.7500 - val_loss: 1828642.3750\n",
      "Epoch 24/35\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1345935.2500 - val_loss: 1051399.5000\n",
      "Epoch 25/35\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 461485120.0000 - val_loss: 2744029.0000\n",
      "Epoch 26/35\n",
      "2291/2291 [==============================] - 3s 1ms/step - loss: 2695712.7500 - val_loss: 915029.1250\n",
      "Epoch 27/35\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 911554.0000 - val_loss: 355470.8750\n",
      "Epoch 28/35\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 50464436.0000 - val_loss: 4931295232.0000\n",
      "Epoch 29/35\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 164850560.0000 - val_loss: 754578.5000\n",
      "Epoch 30/35\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 787039.1875 - val_loss: 278206.3125\n",
      "Epoch 31/35\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 349071.0312 - val_loss: 184908.2812\n",
      "Epoch 32/35\n",
      "2291/2291 [==============================] - 3s 2ms/step - loss: 399216928.0000 - val_loss: 7445452.5000\n",
      "Epoch 33/35\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 2480037.0000 - val_loss: 1133309.0000\n",
      "Epoch 34/35\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 850724.5000 - val_loss: 378367.4062\n",
      "Epoch 35/35\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 314555.0312 - val_loss: 295122.4062\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98d073a74fd145c8bbb530ff38b44b5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='6.465 MB of 6.465 MB uploaded (0.016 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▁▅▁▁▁▁▂▁▁▂▁▁▄▁▁▆▁▁▁█▁▁▅▁▁▁▂▁▁▅▁▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>2</td></tr><tr><td>best_val_loss</td><td>0.98244</td></tr><tr><td>epoch</td><td>34</td></tr><tr><td>loss</td><td>314555.03125</td></tr><tr><td>val_loss</td><td>295122.40625</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">glad-sweep-93</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/82hz4oh3\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/82hz4oh3</a><br/>Synced 6 W&B file(s), 1 media file(s), 13 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_103550-82hz4oh3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: habj0bz4 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.21069936834034103\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.06685203359378906\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 122\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 215\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 221\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 215\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 229\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_103809-habj0bz4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/habj0bz4\" target=\"_blank\">usual-sweep-94</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/96\n",
      "2269/2291 [============================>.] - ETA: 0s - loss: 2192.5090INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_103809-habj0bz4/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_103809-habj0bz4/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 5s 2ms/step - loss: 2172.3140 - val_loss: 1.3690\n",
      "Epoch 2/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 553885632.0000 - val_loss: 3512450.2500\n",
      "Epoch 3/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1818203.0000 - val_loss: 1510504.0000\n",
      "Epoch 4/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 356470.0312 - val_loss: 112609.7109\n",
      "Epoch 5/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 131417.2031 - val_loss: 105699.0547\n",
      "Epoch 6/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 762409728.0000 - val_loss: 3732482.2500\n",
      "Epoch 7/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 2180317.5000 - val_loss: 507365.0938\n",
      "Epoch 8/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 140395232.0000 - val_loss: 675570.8125\n",
      "Epoch 9/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 522606.6875 - val_loss: 349618.3438\n",
      "Epoch 10/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 211901024.0000 - val_loss: 12827298.0000\n",
      "Epoch 11/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1834535.1250 - val_loss: 571317.2500\n",
      "Epoch 12/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 451523.0625 - val_loss: 166900.6094\n",
      "Epoch 13/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 428879168.0000 - val_loss: 10494687.0000\n",
      "Epoch 14/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 5291361.0000 - val_loss: 2404786.2500\n",
      "Epoch 15/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1281181.8750 - val_loss: 567639.1250\n",
      "Epoch 16/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 686049792.0000 - val_loss: 25617144.0000\n",
      "Epoch 17/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 6468504.0000 - val_loss: 2790364.5000\n",
      "Epoch 18/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1631814.2500 - val_loss: 959222.8125\n",
      "Epoch 19/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 654028.5625 - val_loss: 369217.7500\n",
      "Epoch 20/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 542169920.0000 - val_loss: 2461060.5000\n",
      "Epoch 21/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 2057545.5000 - val_loss: 754615.3125\n",
      "Epoch 22/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 675034.8125 - val_loss: 252578.5938\n",
      "Epoch 23/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 217366.8125 - val_loss: 93148.7500\n",
      "Epoch 24/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 699703488.0000 - val_loss: 2790250.5000\n",
      "Epoch 25/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 3103177.5000 - val_loss: 958110.0000\n",
      "Epoch 26/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1163465.8750 - val_loss: 348403.0625\n",
      "Epoch 27/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 388929.9688 - val_loss: 168056.5000\n",
      "Epoch 28/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1311245824.0000 - val_loss: 5656074.5000\n",
      "Epoch 29/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 4775062.0000 - val_loss: 2063066.7500\n",
      "Epoch 30/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1823549.7500 - val_loss: 711004.3750\n",
      "Epoch 31/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 319204384.0000 - val_loss: 13033499.0000\n",
      "Epoch 32/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 4091447.5000 - val_loss: 2415133.0000\n",
      "Epoch 33/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1162667.6250 - val_loss: 694112.0625\n",
      "Epoch 34/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 103188520.0000 - val_loss: 1675554.8750\n",
      "Epoch 35/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 886692.3750 - val_loss: 251618.8125\n",
      "Epoch 36/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 344699.6250 - val_loss: 186893.5000\n",
      "Epoch 37/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 386699456.0000 - val_loss: 2715325.5000\n",
      "Epoch 38/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 2052824.1250 - val_loss: 814138.2500\n",
      "Epoch 39/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 670555.6875 - val_loss: 262060.4375\n",
      "Epoch 40/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 256525.7188 - val_loss: 147361.4219\n",
      "Epoch 41/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 514733216.0000 - val_loss: 4697624.0000\n",
      "Epoch 42/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 2977957.0000 - val_loss: 964767.8750\n",
      "Epoch 43/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1062481.0000 - val_loss: 357924.4375\n",
      "Epoch 44/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 257838304.0000 - val_loss: 2904000.5000\n",
      "Epoch 45/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1585673.5000 - val_loss: 624721.1250\n",
      "Epoch 46/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 619527.0625 - val_loss: 327298.3750\n",
      "Epoch 47/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 291739.8438 - val_loss: 260883.2969\n",
      "Epoch 48/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 173749184.0000 - val_loss: 1064569.1250\n",
      "Epoch 49/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 806740.8125 - val_loss: 309919.0000\n",
      "Epoch 50/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 610356416.0000 - val_loss: 11896991.0000\n",
      "Epoch 51/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 4462021.5000 - val_loss: 2246054.7500\n",
      "Epoch 52/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1573415.5000 - val_loss: 867502.3750\n",
      "Epoch 53/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 225182688.0000 - val_loss: 7013253.5000\n",
      "Epoch 54/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 3488076.7500 - val_loss: 1153104.6250\n",
      "Epoch 55/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 926101.4375 - val_loss: 670371.2500\n",
      "Epoch 56/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 400663.4062 - val_loss: 185857.3594\n",
      "Epoch 57/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 329404320.0000 - val_loss: 1718667.7500\n",
      "Epoch 58/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1597164.7500 - val_loss: 667839.5625\n",
      "Epoch 59/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 510568.0625 - val_loss: 209880.9844\n",
      "Epoch 60/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 225335.9688 - val_loss: 501668.4375\n",
      "Epoch 61/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 281262688.0000 - val_loss: 2152404.0000\n",
      "Epoch 62/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1185298.6250 - val_loss: 622094.6250\n",
      "Epoch 63/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 530244.1250 - val_loss: 279102.6562\n",
      "Epoch 64/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 288198112.0000 - val_loss: 1826523.8750\n",
      "Epoch 65/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1827415.2500 - val_loss: 699049.1875\n",
      "Epoch 66/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 687070.1875 - val_loss: 349245.9688\n",
      "Epoch 67/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 314339168.0000 - val_loss: 4555669.0000\n",
      "Epoch 68/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 2395079.7500 - val_loss: 1040238.8125\n",
      "Epoch 69/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 866319.2500 - val_loss: 548219.2500\n",
      "Epoch 70/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 660739392.0000 - val_loss: 20737618.0000\n",
      "Epoch 71/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 10108696.0000 - val_loss: 2709162.7500\n",
      "Epoch 72/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 2450865.5000 - val_loss: 786077.0000\n",
      "Epoch 73/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1004245.5000 - val_loss: 360508.4062\n",
      "Epoch 74/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 351649696.0000 - val_loss: 2864492.0000\n",
      "Epoch 75/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 2446820.5000 - val_loss: 1010583.1875\n",
      "Epoch 76/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1009870.1875 - val_loss: 542000.3125\n",
      "Epoch 77/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 305366560.0000 - val_loss: 5103343.0000\n",
      "Epoch 78/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 2651837.5000 - val_loss: 999727.5000\n",
      "Epoch 79/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1045816.5625 - val_loss: 552220.9375\n",
      "Epoch 80/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 468380.2500 - val_loss: 210706.4375\n",
      "Epoch 81/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 365528384.0000 - val_loss: 4310643.5000\n",
      "Epoch 82/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1979481.8750 - val_loss: 1009368.2500\n",
      "Epoch 83/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 820975.0625 - val_loss: 435156.4375\n",
      "Epoch 84/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 318365.7188 - val_loss: 354394.4375\n",
      "Epoch 85/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 593714752.0000 - val_loss: 14590396.0000\n",
      "Epoch 86/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 7003131.0000 - val_loss: 2448143.7500\n",
      "Epoch 87/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 2187086.5000 - val_loss: 1432659.0000\n",
      "Epoch 88/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1021959.5625 - val_loss: 436465.0625\n",
      "Epoch 89/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 493076352.0000 - val_loss: 2875500.2500\n",
      "Epoch 90/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 2167087.7500 - val_loss: 866104.0625\n",
      "Epoch 91/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 959607.1875 - val_loss: 357455.6562\n",
      "Epoch 92/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 378472.9688 - val_loss: 199101.8594\n",
      "Epoch 93/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 494213824.0000 - val_loss: 2904360.5000\n",
      "Epoch 94/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1996975.1250 - val_loss: 849256.6875\n",
      "Epoch 95/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 735082.9375 - val_loss: 361113.0312\n",
      "Epoch 96/96\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 362937760.0000 - val_loss: 4357280.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▁▃▄▇▁▁█▁▁▁▁▁▁▆▁▁▄▁▁▁▁▅▁▅▅▁▁▁▆▁▁▆▁▁▁▁▇▁</td></tr><tr><td>val_loss</td><td>▁▂▁▁█▇▁▂▂▁▂▁▁▂▁▂▁▂▃▁▁▁▂▂▁▂▂▁▁▂▃▁▂▃▁▂▁▁▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>1.36897</td></tr><tr><td>epoch</td><td>95</td></tr><tr><td>loss</td><td>362937760.0</td></tr><tr><td>val_loss</td><td>4357280.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">usual-sweep-94</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/habj0bz4\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/habj0bz4</a><br/>Synced 6 W&B file(s), 1 media file(s), 5 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_103809-habj0bz4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6674jvnx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.25198327632875084\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 66\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.06222180068151413\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 215\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 195\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 243\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 203\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 140\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_104505-6674jvnx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/6674jvnx\" target=\"_blank\">quiet-sweep-95</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/66\n",
      "2261/2291 [============================>.] - ETA: 0s - loss: 327.9640INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_104505-6674jvnx/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_104505-6674jvnx/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 6s 3ms/step - loss: 323.8087 - val_loss: 0.9767\n",
      "Epoch 2/66\n",
      "2278/2291 [============================>.] - ETA: 0s - loss: 0.9515INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_104505-6674jvnx/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_104505-6674jvnx/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291/2291 [==============================] - 5s 2ms/step - loss: 0.9514 - val_loss: 0.9413\n",
      "Epoch 3/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 163984400.0000 - val_loss: 533291.1250\n",
      "Epoch 4/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 264302.0938 - val_loss: 111313.9062\n",
      "Epoch 5/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 42498104.0000 - val_loss: 658516.5000\n",
      "Epoch 6/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 245258.6406 - val_loss: 63600.9453\n",
      "Epoch 7/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 69498.9844 - val_loss: 18625.5117\n",
      "Epoch 8/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 100393248.0000 - val_loss: 1631450.1250\n",
      "Epoch 9/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1048083.5000 - val_loss: 215152.1719\n",
      "Epoch 10/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 235816.2656 - val_loss: 76897.5781\n",
      "Epoch 11/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 72309.7344 - val_loss: 60037.5898\n",
      "Epoch 12/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 912614592.0000 - val_loss: 5853967.5000\n",
      "Epoch 13/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 4669636.5000 - val_loss: 1224273.1250\n",
      "Epoch 14/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1382692.8750 - val_loss: 408532.7812\n",
      "Epoch 15/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 135851696.0000 - val_loss: 2819240.5000\n",
      "Epoch 16/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1886415.7500 - val_loss: 775142.2500\n",
      "Epoch 17/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 507700.7812 - val_loss: 205747.0938\n",
      "Epoch 18/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 176580.0625 - val_loss: 59234.4453\n",
      "Epoch 19/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 218115456.0000 - val_loss: 5716893.5000\n",
      "Epoch 20/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 2364612.5000 - val_loss: 666815.6875\n",
      "Epoch 21/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 673898.9375 - val_loss: 189515.1406\n",
      "Epoch 22/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 196883824.0000 - val_loss: 1406891.6250\n",
      "Epoch 23/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1114447.7500 - val_loss: 374640.7500\n",
      "Epoch 24/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 407699.7812 - val_loss: 199483.0000\n",
      "Epoch 25/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 164575.7500 - val_loss: 59976.3047\n",
      "Epoch 26/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 350624448.0000 - val_loss: 1837052.6250\n",
      "Epoch 27/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 2186770.0000 - val_loss: 904905.6875\n",
      "Epoch 28/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 644953.0000 - val_loss: 184822.4531\n",
      "Epoch 29/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 315639200.0000 - val_loss: 1646949.0000\n",
      "Epoch 30/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1803341.1250 - val_loss: 1194445.5000\n",
      "Epoch 31/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 408175808.0000 - val_loss: 25550784.0000\n",
      "Epoch 32/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 7566972.0000 - val_loss: 2467227.7500\n",
      "Epoch 33/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1771279.1250 - val_loss: 780233.6250\n",
      "Epoch 34/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 664429.0000 - val_loss: 313522.9062\n",
      "Epoch 35/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 336153792.0000 - val_loss: 2289456.0000\n",
      "Epoch 36/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1918175.3750 - val_loss: 1107384.2500\n",
      "Epoch 37/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 795766.1250 - val_loss: 348370.3438\n",
      "Epoch 38/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 197525728.0000 - val_loss: 2634946.7500\n",
      "Epoch 39/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1345695.2500 - val_loss: 940550.1250\n",
      "Epoch 40/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 526784.3750 - val_loss: 178160.2656\n",
      "Epoch 41/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 228079520.0000 - val_loss: 2124531.0000\n",
      "Epoch 42/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1535420.5000 - val_loss: 1033506.1250\n",
      "Epoch 43/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 580560.9375 - val_loss: 214125.1562\n",
      "Epoch 44/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 148122512.0000 - val_loss: 1643415.3750\n",
      "Epoch 45/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1015982.6250 - val_loss: 442047.9375\n",
      "Epoch 46/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 360497.2500 - val_loss: 157369.8750\n",
      "Epoch 47/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 141014.9531 - val_loss: 44071.1406\n",
      "Epoch 48/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 294014496.0000 - val_loss: 3340883.2500\n",
      "Epoch 49/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 2122070.2500 - val_loss: 540761.3125\n",
      "Epoch 50/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 827161.5000 - val_loss: 435583.5625\n",
      "Epoch 51/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 114919640.0000 - val_loss: 2328656640.0000\n",
      "Epoch 52/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 11879551.0000 - val_loss: 1115352.7500\n",
      "Epoch 53/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 559345.0000 - val_loss: 223973.2344\n",
      "Epoch 54/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 241790.6562 - val_loss: 67354.5938\n",
      "Epoch 55/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 216492352.0000 - val_loss: 1701343.0000\n",
      "Epoch 56/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1153873.2500 - val_loss: 850494.0625\n",
      "Epoch 57/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 428208.2500 - val_loss: 223758.4531\n",
      "Epoch 58/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 168909.6250 - val_loss: 54818.8711\n",
      "Epoch 59/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 581507968.0000 - val_loss: 15296475.0000\n",
      "Epoch 60/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 4844291.5000 - val_loss: 1624820.6250\n",
      "Epoch 61/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 1443471.7500 - val_loss: 527452.5000\n",
      "Epoch 62/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 393419616.0000 - val_loss: 140673248.0000\n",
      "Epoch 63/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 10300686.0000 - val_loss: 1766852.5000\n",
      "Epoch 64/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 2006093.0000 - val_loss: 910527.5625\n",
      "Epoch 65/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 738109.6875 - val_loss: 291797.6875\n",
      "Epoch 66/66\n",
      "2291/2291 [==============================] - 4s 2ms/step - loss: 255143360.0000 - val_loss: 3137476.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a050b22726934f539e23ec4408344da3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='6.504 MB of 6.504 MB uploaded (0.016 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▁▁▁▁▁█▁▁▁▃▁▃▁▄▁▃▄▁▁▁▁▁▃▁▂▁▁▁▂▁▁▁▁▅▁▄▁▃</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>1</td></tr><tr><td>best_val_loss</td><td>0.94133</td></tr><tr><td>epoch</td><td>65</td></tr><tr><td>loss</td><td>255143360.0</td></tr><tr><td>val_loss</td><td>3137476.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">quiet-sweep-95</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/6674jvnx\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/6674jvnx</a><br/>Synced 6 W&B file(s), 1 media file(s), 9 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_104505-6674jvnx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kqyroz4g with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.05992285898358826\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 36\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.022605799200762045\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 181\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 245\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 158\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 222\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 222\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfb8ff039bf543eebc2133ae6642bd4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016668447200027005, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_104947-kqyroz4g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/kqyroz4g\" target=\"_blank\">cool-sweep-96</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/36\n",
      "4568/4581 [============================>.] - ETA: 0s - loss: 2.4133INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_104947-kqyroz4g/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_104947-kqyroz4g/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4581/4581 [==============================] - 8s 2ms/step - loss: 2.4090 - val_loss: 1.0231\n",
      "Epoch 2/36\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 103966.4531 - val_loss: 951.2625\n",
      "Epoch 3/36\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 37959.3320 - val_loss: 381.5412\n",
      "Epoch 4/36\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 197.2479 - val_loss: 68.3839\n",
      "Epoch 5/36\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 71268.5078 - val_loss: 310.5985\n",
      "Epoch 6/36\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 71035.1875 - val_loss: 795.9673\n",
      "Epoch 7/36\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 443.7234 - val_loss: 100.8657\n",
      "Epoch 8/36\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 228146.5938 - val_loss: 1942.1637\n",
      "Epoch 9/36\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 975.2951 - val_loss: 148.9102\n",
      "Epoch 10/36\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 105775.5938 - val_loss: 687.7029\n",
      "Epoch 11/36\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 452.3111 - val_loss: 98.2530\n",
      "Epoch 12/36\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 54638.0312 - val_loss: 287.0249\n",
      "Epoch 13/36\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 274257.8750 - val_loss: 10854.6943\n",
      "Epoch 14/36\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 2569.7207 - val_loss: 502.0043\n",
      "Epoch 15/36\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 156949.5938 - val_loss: 1554.9648\n",
      "Epoch 16/36\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1332.2703 - val_loss: 19925.3496\n",
      "Epoch 17/36\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 290.2792 - val_loss: 24.8551\n",
      "Epoch 18/36\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 138249.1562 - val_loss: 606.0737\n",
      "Epoch 19/36\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 197222.0312 - val_loss: 4576.7046\n",
      "Epoch 20/36\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 1970.1343 - val_loss: 1110.6902\n",
      "Epoch 21/36\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 75737.0156 - val_loss: 882.5259\n",
      "Epoch 22/36\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 471586.4375 - val_loss: 16876.1230\n",
      "Epoch 23/36\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 5264.3906 - val_loss: 886.6037\n",
      "Epoch 24/36\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 92662.5078 - val_loss: 462.4722\n",
      "Epoch 25/36\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 191770.2500 - val_loss: 17023.6973\n",
      "Epoch 26/36\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 2852.6111 - val_loss: 392.9750\n",
      "Epoch 27/36\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 147630.9375 - val_loss: 6300.2969\n",
      "Epoch 28/36\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 2573.3484 - val_loss: 756.0555\n",
      "Epoch 29/36\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 93421.7500 - val_loss: 725.4755\n",
      "Epoch 30/36\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 428.1027 - val_loss: 113.6699\n",
      "Epoch 31/36\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 110250.1953 - val_loss: 637.5886\n",
      "Epoch 32/36\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 479.8531 - val_loss: 165.5921\n",
      "Epoch 33/36\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 164289.0469 - val_loss: 645.8264\n",
      "Epoch 34/36\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 528.3717 - val_loss: 265.9092\n",
      "Epoch 35/36\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 293440.3125 - val_loss: 1537.8153\n",
      "Epoch 36/36\n",
      "4581/4581 [==============================] - 6s 1ms/step - loss: 975.1241 - val_loss: 539.8170\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▃▂▁▂▂▁▄▁▃▁▂▅▁▃▁▁▃▄▁▂█▁▂▄▁▃▁▂▁▃▁▃▁▅▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▂▁▁▁▁▅▁▂█▁▁▃▁▁▇▁▁▇▁▃▁▁▁▁▁▁▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>1.02309</td></tr><tr><td>epoch</td><td>35</td></tr><tr><td>loss</td><td>975.12408</td></tr><tr><td>val_loss</td><td>539.81696</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">cool-sweep-96</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/kqyroz4g\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/kqyroz4g</a><br/>Synced 6 W&B file(s), 1 media file(s), 5 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_104947-kqyroz4g/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: weuh7jrt with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.26942475712861064\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 35\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.09038198091658298\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 249\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 221\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 221\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 229\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 206\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_105354-weuh7jrt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/weuh7jrt\" target=\"_blank\">sage-sweep-97</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "1514/1527 [============================>.] - ETA: 0s - loss: 25397.7227INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_105354-weuh7jrt/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_105354-weuh7jrt/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 5s 3ms/step - loss: 25185.9785 - val_loss: 17.9694\n",
      "Epoch 2/35\n",
      "1507/1527 [============================>.] - ETA: 0s - loss: 13.4742INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_105354-weuh7jrt/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_105354-weuh7jrt/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 4s 3ms/step - loss: 13.3760 - val_loss: 8.0074\n",
      "Epoch 3/35\n",
      "1527/1527 [==============================] - 4s 2ms/step - loss: 2780094208.0000 - val_loss: 66425132.0000\n",
      "Epoch 4/35\n",
      "1527/1527 [==============================] - 4s 2ms/step - loss: 25678702.0000 - val_loss: 3885017.0000\n",
      "Epoch 5/35\n",
      "1527/1527 [==============================] - 4s 2ms/step - loss: 5122089.5000 - val_loss: 7927207.0000\n",
      "Epoch 6/35\n",
      "1527/1527 [==============================] - 4s 2ms/step - loss: 1951512.3750 - val_loss: 2281771.5000\n",
      "Epoch 7/35\n",
      "1527/1527 [==============================] - 4s 2ms/step - loss: 982908.6250 - val_loss: 284852.2812\n",
      "Epoch 8/35\n",
      "1527/1527 [==============================] - 4s 2ms/step - loss: 303109.1875 - val_loss: 73117.6328\n",
      "Epoch 9/35\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 134985.2656 - val_loss: 53135.5430\n",
      "Epoch 10/35\n",
      "1527/1527 [==============================] - 4s 2ms/step - loss: 18560149504.0000 - val_loss: 102838256.0000\n",
      "Epoch 11/35\n",
      "1527/1527 [==============================] - 4s 2ms/step - loss: 88376632.0000 - val_loss: 27218882.0000\n",
      "Epoch 12/35\n",
      "1527/1527 [==============================] - 4s 2ms/step - loss: 37024056.0000 - val_loss: 15332813.0000\n",
      "Epoch 13/35\n",
      "1527/1527 [==============================] - 4s 2ms/step - loss: 14989468.0000 - val_loss: 7441747.0000\n",
      "Epoch 14/35\n",
      "1527/1527 [==============================] - 4s 2ms/step - loss: 6662860.5000 - val_loss: 3091075.2500\n",
      "Epoch 15/35\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 27178522624.0000 - val_loss: 144556896.0000\n",
      "Epoch 16/35\n",
      "1527/1527 [==============================] - 4s 2ms/step - loss: 120178400.0000 - val_loss: 73557200.0000\n",
      "Epoch 17/35\n",
      "1527/1527 [==============================] - 4s 2ms/step - loss: 59365200.0000 - val_loss: 21033308.0000\n",
      "Epoch 18/35\n",
      "1527/1527 [==============================] - 4s 2ms/step - loss: 23457218.0000 - val_loss: 9344604.0000\n",
      "Epoch 19/35\n",
      "1527/1527 [==============================] - 4s 2ms/step - loss: 11032542.0000 - val_loss: 4522798.0000\n",
      "Epoch 20/35\n",
      "1527/1527 [==============================] - 4s 2ms/step - loss: 24669685760.0000 - val_loss: 1264323712.0000\n",
      "Epoch 21/35\n",
      "1527/1527 [==============================] - 4s 2ms/step - loss: 474041056.0000 - val_loss: 104367736.0000\n",
      "Epoch 22/35\n",
      "1527/1527 [==============================] - 4s 2ms/step - loss: 126728720.0000 - val_loss: 55472940.0000\n",
      "Epoch 23/35\n",
      "1527/1527 [==============================] - 4s 2ms/step - loss: 44501396.0000 - val_loss: 61364652.0000\n",
      "Epoch 24/35\n",
      "1527/1527 [==============================] - 4s 2ms/step - loss: 19291252.0000 - val_loss: 4938277.5000\n",
      "Epoch 25/35\n",
      "1527/1527 [==============================] - 4s 2ms/step - loss: 8257700.5000 - val_loss: 6367084.0000\n",
      "Epoch 26/35\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 39613349888.0000 - val_loss: 145660000.0000\n",
      "Epoch 27/35\n",
      "1527/1527 [==============================] - 4s 2ms/step - loss: 195358192.0000 - val_loss: 121976888.0000\n",
      "Epoch 28/35\n",
      "1527/1527 [==============================] - 4s 2ms/step - loss: 69945496.0000 - val_loss: 26808298.0000\n",
      "Epoch 29/35\n",
      "1527/1527 [==============================] - 4s 2ms/step - loss: 37276096.0000 - val_loss: 18302848.0000\n",
      "Epoch 30/35\n",
      "1527/1527 [==============================] - 4s 2ms/step - loss: 47936204800.0000 - val_loss: 1648299264.0000\n",
      "Epoch 31/35\n",
      "1527/1527 [==============================] - 4s 2ms/step - loss: 658181376.0000 - val_loss: 258969088.0000\n",
      "Epoch 32/35\n",
      "1527/1527 [==============================] - 4s 2ms/step - loss: 146146944.0000 - val_loss: 73980536.0000\n",
      "Epoch 33/35\n",
      "1527/1527 [==============================] - 4s 2ms/step - loss: 72980096.0000 - val_loss: 38574072.0000\n",
      "Epoch 34/35\n",
      "1527/1527 [==============================] - 4s 2ms/step - loss: 38356032.0000 - val_loss: 24034640.0000\n",
      "Epoch 35/35\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 20590468.0000 - val_loss: 7546601.5000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29aeb3c727254290a3c679630047150f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='7.766 MB of 7.786 MB uploaded (0.016 MB deduped)\\r'), FloatProgress(value=0.997431…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▁▁▁▁▁▁▁▄▁▁▁▁▅▁▁▁▁▅▁▁▁▁▁▇▁▁▁█▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▆▁▁▁▁▁▂▂▁▁█▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>1</td></tr><tr><td>best_val_loss</td><td>8.00738</td></tr><tr><td>epoch</td><td>34</td></tr><tr><td>loss</td><td>20590468.0</td></tr><tr><td>val_loss</td><td>7546601.5</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">sage-sweep-97</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/weuh7jrt\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/weuh7jrt</a><br/>Synced 6 W&B file(s), 1 media file(s), 9 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_105354-weuh7jrt/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: js7eruzy with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1740940877345769\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 80\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.07813452249817666\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 153\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 180\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 205\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 212\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 208\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_105610-js7eruzy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/js7eruzy\" target=\"_blank\">ethereal-sweep-98</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "1521/1527 [============================>.] - ETA: 0s - loss: 3664.4956INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_105610-js7eruzy/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_105610-js7eruzy/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 4s 3ms/step - loss: 3650.7329 - val_loss: 1.7099\n",
      "Epoch 2/80\n",
      "1502/1527 [============================>.] - ETA: 0s - loss: 1.7511INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_105610-js7eruzy/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_105610-js7eruzy/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 4s 2ms/step - loss: 1.7471 - val_loss: 1.3553\n",
      "Epoch 3/80\n",
      "1517/1527 [============================>.] - ETA: 0s - loss: 1.5733INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_105610-js7eruzy/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_105610-js7eruzy/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 4s 3ms/step - loss: 1.5701 - val_loss: 0.8713\n",
      "Epoch 4/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 3366100480.0000 - val_loss: 21947556.0000\n",
      "Epoch 5/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 16187810.0000 - val_loss: 8920335.0000\n",
      "Epoch 6/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 6743200.5000 - val_loss: 4030246.2500\n",
      "Epoch 7/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 3400988.5000 - val_loss: 992067.6875\n",
      "Epoch 8/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1372907.2500 - val_loss: 402965.3438\n",
      "Epoch 9/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 2294290944.0000 - val_loss: 43158900.0000\n",
      "Epoch 10/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 15680252.0000 - val_loss: 4766388.0000\n",
      "Epoch 11/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 5211546.5000 - val_loss: 2520541.5000\n",
      "Epoch 12/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 2588939.0000 - val_loss: 1080554.7500\n",
      "Epoch 13/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1178719.2500 - val_loss: 463109.0312\n",
      "Epoch 14/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 938685952.0000 - val_loss: 15668607.0000\n",
      "Epoch 15/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 8557867.0000 - val_loss: 2334834.7500\n",
      "Epoch 16/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 2577133.7500 - val_loss: 981719.0625\n",
      "Epoch 17/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1270970.7500 - val_loss: 633074.8125\n",
      "Epoch 18/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1268388352.0000 - val_loss: 28741976.0000\n",
      "Epoch 19/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 10124370.0000 - val_loss: 4694397.0000\n",
      "Epoch 20/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 3341725.0000 - val_loss: 1066479.6250\n",
      "Epoch 21/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 2842164736.0000 - val_loss: 18435738.0000\n",
      "Epoch 22/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 14078939.0000 - val_loss: 4208258.0000\n",
      "Epoch 23/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 5094149.0000 - val_loss: 3204554.2500\n",
      "Epoch 24/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 2526610.7500 - val_loss: 1989514.2500\n",
      "Epoch 25/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1312532.2500 - val_loss: 720707.6250\n",
      "Epoch 26/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 6562566656.0000 - val_loss: 40746652.0000\n",
      "Epoch 27/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 27492646.0000 - val_loss: 15473162.0000\n",
      "Epoch 28/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 12853514.0000 - val_loss: 21488220.0000\n",
      "Epoch 29/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 5924395.0000 - val_loss: 1464921.1250\n",
      "Epoch 30/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 3257425.7500 - val_loss: 2553851.5000\n",
      "Epoch 31/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 4032552960.0000 - val_loss: 32811476.0000\n",
      "Epoch 32/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 22898388.0000 - val_loss: 10543454.0000\n",
      "Epoch 33/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 8880031.0000 - val_loss: 3293115.5000\n",
      "Epoch 34/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 4973853.0000 - val_loss: 2369370.0000\n",
      "Epoch 35/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 8179208.5000 - val_loss: 22371184640.0000\n",
      "Epoch 36/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 6466873856.0000 - val_loss: 24920564.0000\n",
      "Epoch 37/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 23539798.0000 - val_loss: 9449660.0000\n",
      "Epoch 38/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 12483694.0000 - val_loss: 7027580.0000\n",
      "Epoch 39/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 6653784.0000 - val_loss: 3391689.7500\n",
      "Epoch 40/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 3617587.0000 - val_loss: 1420910.8750\n",
      "Epoch 41/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1754781.3750 - val_loss: 753074.6250\n",
      "Epoch 42/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 4419286528.0000 - val_loss: 47554960.0000\n",
      "Epoch 43/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 32921256.0000 - val_loss: 13184942.0000\n",
      "Epoch 44/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 15537899.0000 - val_loss: 8380874.5000\n",
      "Epoch 45/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 7705901.0000 - val_loss: 2577011.2500\n",
      "Epoch 46/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 4202702.0000 - val_loss: 1673265.3750\n",
      "Epoch 47/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 2055746.3750 - val_loss: 1019046.5000\n",
      "Epoch 48/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 2031598464.0000 - val_loss: 10250802.0000\n",
      "Epoch 49/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 9073507.0000 - val_loss: 2666098.2500\n",
      "Epoch 50/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 4660477.0000 - val_loss: 2431089.2500\n",
      "Epoch 51/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 2277033.7500 - val_loss: 1001120.0000\n",
      "Epoch 52/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1036989.2500 - val_loss: 564740.3750\n",
      "Epoch 53/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 2019198976.0000 - val_loss: 15660457.0000\n",
      "Epoch 54/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 10718725.0000 - val_loss: 8713095.0000\n",
      "Epoch 55/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 5240828.0000 - val_loss: 1651521.2500\n",
      "Epoch 56/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 2590056.5000 - val_loss: 1880743.6250\n",
      "Epoch 57/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 4387261440.0000 - val_loss: 18185978.0000\n",
      "Epoch 58/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 21767886.0000 - val_loss: 14112393.0000\n",
      "Epoch 59/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 13367674.0000 - val_loss: 4427822.5000\n",
      "Epoch 60/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 5811502.0000 - val_loss: 3265412.5000\n",
      "Epoch 61/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 2708277.2500 - val_loss: 1390920.7500\n",
      "Epoch 62/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1781928.7500 - val_loss: 1510995.3750\n",
      "Epoch 63/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1982196352.0000 - val_loss: 20972968.0000\n",
      "Epoch 64/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 17748380.0000 - val_loss: 12860560.0000\n",
      "Epoch 65/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 6906934.5000 - val_loss: 5115076.0000\n",
      "Epoch 66/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 3851178.5000 - val_loss: 3722502.2500\n",
      "Epoch 67/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1971940.0000 - val_loss: 1126230.0000\n",
      "Epoch 68/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1037175.6875 - val_loss: 9154021.0000\n",
      "Epoch 69/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1829127808.0000 - val_loss: 9612713.0000\n",
      "Epoch 70/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 7409917.5000 - val_loss: 3803332.7500\n",
      "Epoch 71/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 3926631.0000 - val_loss: 1780031.5000\n",
      "Epoch 72/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1950035.7500 - val_loss: 1048930.7500\n",
      "Epoch 73/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1219716.6250 - val_loss: 548089.0625\n",
      "Epoch 74/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1433102464.0000 - val_loss: 14761829.0000\n",
      "Epoch 75/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 10198327.0000 - val_loss: 5956182.5000\n",
      "Epoch 76/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 4400332.5000 - val_loss: 1715847.8750\n",
      "Epoch 77/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 2301902.7500 - val_loss: 1265866.5000\n",
      "Epoch 78/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 883124544.0000 - val_loss: 18125700.0000\n",
      "Epoch 79/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 11100420.0000 - val_loss: 4600075.5000\n",
      "Epoch 80/80\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 4003359.0000 - val_loss: 1608270.8750\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁▁▁▁▅▁▁▁▁▁▆▁▁▁▁▇▁▁▁▁▁▁▁▁▁▁▄▁█▁▁▄▁▁▄▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>2</td></tr><tr><td>best_val_loss</td><td>0.87131</td></tr><tr><td>epoch</td><td>79</td></tr><tr><td>loss</td><td>4003359.0</td></tr><tr><td>val_loss</td><td>1608270.875</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">ethereal-sweep-98</strong>: <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/js7eruzy\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/js7eruzy</a><br/>Synced 6 W&B file(s), 1 media file(s), 13 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_105610-js7eruzy/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _WandbInit._pause_backend at 0x7f65a4f4a700> (for post_run_cell):\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/backcall/backcall.py\u001b[0m in \u001b[0;36madapted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0madapted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_pause_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"saved code: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resume_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mpublish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m         \u001b[0mpause\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/wandb/sdk/interface/interface_shared.py\u001b[0m in \u001b[0;36m_publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpause\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/wandb/sdk/interface/interface_sock.py\u001b[0m in \u001b[0;36m_publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pb.Record\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_record_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_communicate_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pb.Record\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mMessageFuture\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mserver_req\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mServerRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mserver_req\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_publish\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver_req\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_extract_packet_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<BI\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"W\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sendall_with_error_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m                 \u001b[0;31m# sent equal to 0 indicates a closed socket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "# file to load the nn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "# read in our data\n",
    "DATA_DIR = '/home/oscar47/Desktop/astro101/data/g_band/var_output/'\n",
    "\n",
    "# check if keras recognizes gpu\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "train_x_ds = np.load(os.path.join(DATA_DIR, 'train_x_ds.npy'))\n",
    "val_x_ds = np.load(os.path.join(DATA_DIR, 'val_x_ds.npy'))\n",
    "train_y_ds = np.load(os.path.join(DATA_DIR, 'train_y_ds.npy'))\n",
    "val_y_ds = np.load(os.path.join(DATA_DIR, 'val_y_ds.npy'))\n",
    "\n",
    "input_shape = train_x_ds[0].shape\n",
    "output_len = len(train_y_ds[0])\n",
    "\n",
    "# build model functions--------------------------------\n",
    "def build_model(size1, size2, size3, size4, size5, dropout, learning_rate):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(layers.Dense(size1))\n",
    "    model.add(layers.Dense(size2))\n",
    "    model.add(layers.Dense(size3))\n",
    "    model.add(layers.Dense(size4))\n",
    "    model.add(layers.Dense(size5))\n",
    "\n",
    "    model.add(layers.Dropout(dropout))\n",
    "    model.add(layers.Dense(output_len))\n",
    "\n",
    "    # return len of class size\n",
    "    model.add(layers.Dense(output_len))\n",
    "    model.add(layers.Activation('softmax'))\n",
    "\n",
    "    optimizer = Adam(learning_rate = learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def train(config=None):\n",
    "    with wandb.init(config=config):\n",
    "    # If called by wandb.agent, as below,\n",
    "    # this config will be set by Sweep Controller\n",
    "      config = wandb.config\n",
    "\n",
    "      #pprint.pprint(config)\n",
    "\n",
    "      #initialize the neural net; \n",
    "      global model\n",
    "      model = build_model(config.size_1,  config.size_2, config.size_3, \n",
    "              config.size_4, config.size_5, \n",
    "              config.dropout, config.learning_rate)\n",
    "      \n",
    "      #now run training\n",
    "      history = model.fit(\n",
    "        train_x_ds, train_y_ds,\n",
    "        batch_size = config.batch_size,\n",
    "        validation_data=(val_x_ds, val_y_ds),\n",
    "        epochs=config.epochs,\n",
    "        callbacks=[WandbCallback()] #use callbacks to have w&b log stats; will automatically save best model                     \n",
    "      )\n",
    "\n",
    "def train_manual():\n",
    "    global model\n",
    "    model = build_model(128, 128, 128, \n",
    "            128, 128, \n",
    "            .1, .001)\n",
    "    \n",
    "    #now run training\n",
    "    history = model.fit(\n",
    "    train_x_ds, train_y_ds,\n",
    "    batch_size = 64,\n",
    "    validation_data=(val_x_ds, val_y_ds),\n",
    "    epochs=10\n",
    "    )\n",
    "\n",
    "# set dictionary with random search; optimizing val_loss--------------------------\n",
    "sweep_config= {\n",
    "    'method': 'random',\n",
    "    'name': 'val_accuracy',\n",
    "    'goal': 'maximize'\n",
    "}\n",
    "\n",
    "sweep_config['metric']= 'val_accuracy'\n",
    "\n",
    "# now name hyperparameters with nested dictionary\n",
    "# parameters_dict = {\n",
    "#     'epochs': {\n",
    "#        'distribution': 'int_uniform',\n",
    "#        'min': 10,\n",
    "#        'max': 20\n",
    "#     },\n",
    "#     # for build_dataset\n",
    "#      'batch_size': {\n",
    "#        'distribution': 'q_log_uniform',  #we want to specify a distribution type to more efficiently iterate through these hyperparams\n",
    "#        'q': 8,\n",
    "#        'min': np.log(64),\n",
    "#        'max': np.log(256)\n",
    "#     },\n",
    "#     'size_1': {\n",
    "#        'distribution': 'q_log_uniform',\n",
    "#        'q': 8,\n",
    "#        'min': np.log(64),\n",
    "#        'max': np.log(256)\n",
    "#     },\n",
    "#     'size_2': {\n",
    "#        'distribution': 'q_log_uniform',\n",
    "#        'q': 8,\n",
    "#        'min': np.log(64),\n",
    "#        'max': np.log(256)\n",
    "#     },\n",
    "#      'size_3': {\n",
    "#        'distribution': 'q_log_uniform',\n",
    "#        'q': 8,\n",
    "#        'min': np.log(64),\n",
    "#        'max': np.log(256)\n",
    "#     },\n",
    "#      'size_4': {\n",
    "#        'distribution': 'q_log_uniform',\n",
    "#        'q': 8,\n",
    "#        'min': np.log(64),\n",
    "#        'max': np.log(256)\n",
    "#     },\n",
    "#      'size_5': {\n",
    "#        'distribution': 'q_log_uniform',\n",
    "#        'q': 8,\n",
    "#        'min': np.log(64),\n",
    "#        'max': np.log(256)\n",
    "#     },\n",
    "#     'dropout': {\n",
    "#       'distribution': 'uniform',\n",
    "#        'min': 0,\n",
    "#        'max': 0.6\n",
    "#     },\n",
    "#     'learning_rate':{\n",
    "#          #uniform distribution between 0 and 1\n",
    "#          'distribution': 'uniform', \n",
    "#          'min': 0,\n",
    "#          'max': 0.1\n",
    "#      }\n",
    "# }\n",
    "\n",
    "parameters_dict = {\n",
    "    'epochs': {\n",
    "       'distribution': 'int_uniform',\n",
    "       'min': 20,\n",
    "       'max': 100\n",
    "    },\n",
    "    # for build_dataset\n",
    "     'batch_size': {\n",
    "       'values': [32, 64, 96, 128]\n",
    "    },\n",
    "    'size_1': {\n",
    "       'distribution': 'int_uniform',\n",
    "       'min': 64,\n",
    "       'max': 256\n",
    "    },\n",
    "    'size_2': {\n",
    "       'distribution': 'int_uniform',\n",
    "       'min': 64,\n",
    "       'max': 256\n",
    "    },'size_3': {\n",
    "       'distribution': 'int_uniform',\n",
    "       'min': 64,\n",
    "       'max': 256\n",
    "    },'size_4': {\n",
    "       'distribution': 'int_uniform',\n",
    "       'min': 64,\n",
    "       'max': 256\n",
    "    },'size_5': {\n",
    "       'distribution': 'int_uniform',\n",
    "       'min': 64,\n",
    "       'max': 256\n",
    "    },\n",
    "    'dropout': {\n",
    "      'distribution': 'uniform',\n",
    "       'min': 0,\n",
    "       'max': 0.6\n",
    "    },\n",
    "    'learning_rate':{\n",
    "         #uniform distribution between 0 and 1\n",
    "         'distribution': 'uniform', \n",
    "         'min': 0,\n",
    "         'max': 0.1\n",
    "     }\n",
    "}\n",
    "\n",
    "# append parameters to sweep config\n",
    "sweep_config['parameters'] = parameters_dict \n",
    "\n",
    "# login to wandb----------------\n",
    "wandb.init(project=\"Astro101_Project_v2\", entity=\"oscarscholin\")\n",
    "\n",
    "# initialize sweep agent\n",
    "sweep_id = wandb.sweep(sweep_config, project='Astro101_Project_v2', entity=\"oscarscholin\")\n",
    "wandb.agent(sweep_id, train, count=100)\n",
    "\n",
    "#train_manual()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aaf8a3611b879056867134183afc22ea709e115b10fb7684e1dbf805b3500c4a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
