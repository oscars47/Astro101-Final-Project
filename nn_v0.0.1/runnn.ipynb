{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File to implement nn with wandb\n",
    "(note that we can't run wandb in terminal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-18 04:45:40.620608: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-18 04:45:40.690566: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-18 04:45:40.692276: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-18 04:45:40.692282: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-11-18 04:45:40.940585: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-18 04:45:40.940616: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-18 04:45:40.940618: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-18 04:45:41.565993: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-18 04:45:41.566456: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-18 04:45:41.566478: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-11-18 04:45:41.566493: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-11-18 04:45:41.566508: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-11-18 04:45:41.566523: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-11-18 04:45:41.566536: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-11-18 04:45:41.566549: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-11-18 04:45:41.566562: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-11-18 04:45:41.566566: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33moscarscholin\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_044542-2bk9pzob</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/2bk9pzob\" target=\"_blank\">chocolate-wind-1</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Malformed sweep config detected! This may cause your sweep to behave in unexpected ways.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m To avoid this, please fix the sweep config schema violations below:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m   Violation 1. Additional properties are not allowed ('goal' was unexpected)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m   Violation 2. 'val_accuracy' is not of type 'object'\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: jp6ffgsr\n",
      "Sweep URL: https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Waiting for W&B process to finish... (success).\n",
      "wandb: Synced chocolate-wind-1: https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/2bk9pzob\n",
      "wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "wandb: Find logs at: ./wandb/run-20221118_044542-2bk9pzob/logs\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: o2j2quim with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1886337325733656\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 41\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.04671489595440448\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_1: 238\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_2: 182\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_3: 209\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_4: 162\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsize_5: 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_044555-o2j2quim</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/runs/o2j2quim\" target=\"_blank\">happy-sweep-1</a></strong> to <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr\" target=\"_blank\">https://wandb.ai/oscarscholin/Astro101_Project_v2/sweeps/jp6ffgsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-18 04:45:59.605961: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/41\n",
      "1505/1527 [============================>.] - ETA: 0s - loss: 173.9023INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_044555-o2j2quim/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_044555-o2j2quim/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 4s 2ms/step - loss: 171.4386 - val_loss: 0.8265\n",
      "Epoch 2/41\n",
      "1526/1527 [============================>.] - ETA: 0s - loss: 0.8970INFO:tensorflow:Assets written to: /home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_044555-o2j2quim/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/oscar47/Desktop/astro101/Astro101-Final-Project/nn_v0.0.1/wandb/run-20221118_044555-o2j2quim/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 3s 2ms/step - loss: 0.8969 - val_loss: 0.8093\n",
      "Epoch 3/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 16084233.0000 - val_loss: 135869440.0000\n",
      "Epoch 4/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 783053.6875 - val_loss: 66184.6797\n",
      "Epoch 5/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 35002.7734 - val_loss: 9758.3955\n",
      "Epoch 6/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 14502.5322 - val_loss: 6026.7856\n",
      "Epoch 7/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 7930953.5000 - val_loss: 39818.8125\n",
      "Epoch 8/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 34942.1758 - val_loss: 9394.0322\n",
      "Epoch 9/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 13231.7080 - val_loss: 5335.3818\n",
      "Epoch 10/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 6084.6099 - val_loss: 2376.6833\n",
      "Epoch 11/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 2899.0608 - val_loss: 1457.4109\n",
      "Epoch 12/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 1283.4584 - val_loss: 548.0749\n",
      "Epoch 13/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 19427192.0000 - val_loss: 69436.2969\n",
      "Epoch 14/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 63726.5859 - val_loss: 30404.8281\n",
      "Epoch 15/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 30872.0098 - val_loss: 10119.2158\n",
      "Epoch 16/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 14572.3984 - val_loss: 6774.0933\n",
      "Epoch 17/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 48635716.0000 - val_loss: 467995.9688\n",
      "Epoch 18/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 231979.3750 - val_loss: 241044.6250\n",
      "Epoch 19/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 89311.6641 - val_loss: 32465.7148\n",
      "Epoch 20/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 14795392.0000 - val_loss: 1732714.0000\n",
      "Epoch 21/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 283173.1250 - val_loss: 76046.6875\n",
      "Epoch 22/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 56149.9727 - val_loss: 25516.9180\n",
      "Epoch 23/41\n",
      "1527/1527 [==============================] - 3s 2ms/step - loss: 26178.3066 - val_loss: 11322.8867\n",
      "Epoch 24/41\n",
      " 383/1527 [======>.......................] - ETA: 1s - loss: 13384.3398"
     ]
    }
   ],
   "source": [
    "# file to load the nn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "# read in our data\n",
    "DATA_DIR = '/home/oscar47/Desktop/astro101/data/g_band/var_output/'\n",
    "\n",
    "# check if keras recognizes gpu\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "train_x_ds = np.load(os.path.join(DATA_DIR, 'train_x_ds.npy'))\n",
    "val_x_ds = np.load(os.path.join(DATA_DIR, 'val_x_ds.npy'))\n",
    "train_y_ds = np.load(os.path.join(DATA_DIR, 'train_y_ds.npy'))\n",
    "val_y_ds = np.load(os.path.join(DATA_DIR, 'val_y_ds.npy'))\n",
    "\n",
    "input_shape = train_x_ds[0].shape\n",
    "output_len = len(train_y_ds[0])\n",
    "\n",
    "# build model functions--------------------------------\n",
    "def build_model(size1, size2, size3, size4, size5, dropout, learning_rate):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(layers.Dense(size1))\n",
    "    model.add(layers.Dense(size2))\n",
    "    model.add(layers.Dense(size3))\n",
    "    model.add(layers.Dense(size4))\n",
    "    model.add(layers.Dense(size5))\n",
    "\n",
    "    model.add(layers.Dropout(dropout))\n",
    "    model.add(layers.Dense(output_len))\n",
    "\n",
    "    # return len of class size\n",
    "    model.add(layers.Dense(output_len))\n",
    "    model.add(layers.Activation('softmax'))\n",
    "\n",
    "    optimizer = Adam(learning_rate = learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def train(config=None):\n",
    "    with wandb.init(config=config):\n",
    "    # If called by wandb.agent, as below,\n",
    "    # this config will be set by Sweep Controller\n",
    "      config = wandb.config\n",
    "\n",
    "      #pprint.pprint(config)\n",
    "\n",
    "      #initialize the neural net; \n",
    "      global model\n",
    "      model = build_model(config.size_1,  config.size_2, config.size_3, \n",
    "              config.size_4, config.size_5, \n",
    "              config.dropout, config.learning_rate)\n",
    "      \n",
    "      #now run training\n",
    "      history = model.fit(\n",
    "        train_x_ds, train_y_ds,\n",
    "        batch_size = config.batch_size,\n",
    "        validation_data=(val_x_ds, val_y_ds),\n",
    "        epochs=config.epochs,\n",
    "        callbacks=[WandbCallback()] #use callbacks to have w&b log stats; will automatically save best model                     \n",
    "      )\n",
    "\n",
    "def train_manual():\n",
    "    global model\n",
    "    model = build_model(128, 128, 128, \n",
    "            128, 128, \n",
    "            .1, .001)\n",
    "    \n",
    "    #now run training\n",
    "    history = model.fit(\n",
    "    train_x_ds, train_y_ds,\n",
    "    batch_size = 64,\n",
    "    validation_data=(val_x_ds, val_y_ds),\n",
    "    epochs=10\n",
    "    )\n",
    "\n",
    "# set dictionary with random search; optimizing val_loss--------------------------\n",
    "sweep_config= {\n",
    "    'method': 'random',\n",
    "    'name': 'val_accuracy',\n",
    "    'goal': 'maximize'\n",
    "}\n",
    "\n",
    "sweep_config['metric']= 'val_accuracy'\n",
    "\n",
    "# now name hyperparameters with nested dictionary\n",
    "# parameters_dict = {\n",
    "#     'epochs': {\n",
    "#        'distribution': 'int_uniform',\n",
    "#        'min': 10,\n",
    "#        'max': 20\n",
    "#     },\n",
    "#     # for build_dataset\n",
    "#      'batch_size': {\n",
    "#        'distribution': 'q_log_uniform',  #we want to specify a distribution type to more efficiently iterate through these hyperparams\n",
    "#        'q': 8,\n",
    "#        'min': np.log(64),\n",
    "#        'max': np.log(256)\n",
    "#     },\n",
    "#     'size_1': {\n",
    "#        'distribution': 'q_log_uniform',\n",
    "#        'q': 8,\n",
    "#        'min': np.log(64),\n",
    "#        'max': np.log(256)\n",
    "#     },\n",
    "#     'size_2': {\n",
    "#        'distribution': 'q_log_uniform',\n",
    "#        'q': 8,\n",
    "#        'min': np.log(64),\n",
    "#        'max': np.log(256)\n",
    "#     },\n",
    "#      'size_3': {\n",
    "#        'distribution': 'q_log_uniform',\n",
    "#        'q': 8,\n",
    "#        'min': np.log(64),\n",
    "#        'max': np.log(256)\n",
    "#     },\n",
    "#      'size_4': {\n",
    "#        'distribution': 'q_log_uniform',\n",
    "#        'q': 8,\n",
    "#        'min': np.log(64),\n",
    "#        'max': np.log(256)\n",
    "#     },\n",
    "#      'size_5': {\n",
    "#        'distribution': 'q_log_uniform',\n",
    "#        'q': 8,\n",
    "#        'min': np.log(64),\n",
    "#        'max': np.log(256)\n",
    "#     },\n",
    "#     'dropout': {\n",
    "#       'distribution': 'uniform',\n",
    "#        'min': 0,\n",
    "#        'max': 0.6\n",
    "#     },\n",
    "#     'learning_rate':{\n",
    "#          #uniform distribution between 0 and 1\n",
    "#          'distribution': 'uniform', \n",
    "#          'min': 0,\n",
    "#          'max': 0.1\n",
    "#      }\n",
    "# }\n",
    "\n",
    "parameters_dict = {\n",
    "    'epochs': {\n",
    "       'distribution': 'int_uniform',\n",
    "       'min': 20,\n",
    "       'max': 100\n",
    "    },\n",
    "    # for build_dataset\n",
    "     'batch_size': {\n",
    "       'values': [32, 64, 96, 128]\n",
    "    },\n",
    "    'size_1': {\n",
    "       'distribution': 'int_uniform',\n",
    "       'min': 64,\n",
    "       'max': 256\n",
    "    },\n",
    "    'size_2': {\n",
    "       'distribution': 'int_uniform',\n",
    "       'min': 64,\n",
    "       'max': 256\n",
    "    },'size_3': {\n",
    "       'distribution': 'int_uniform',\n",
    "       'min': 64,\n",
    "       'max': 256\n",
    "    },'size_4': {\n",
    "       'distribution': 'int_uniform',\n",
    "       'min': 64,\n",
    "       'max': 256\n",
    "    },'size_5': {\n",
    "       'distribution': 'int_uniform',\n",
    "       'min': 64,\n",
    "       'max': 256\n",
    "    },\n",
    "    'dropout': {\n",
    "      'distribution': 'uniform',\n",
    "       'min': 0,\n",
    "       'max': 0.6\n",
    "    },\n",
    "    'learning_rate':{\n",
    "         #uniform distribution between 0 and 1\n",
    "         'distribution': 'uniform', \n",
    "         'min': 0,\n",
    "         'max': 0.1\n",
    "     }\n",
    "}\n",
    "\n",
    "# append parameters to sweep config\n",
    "sweep_config['parameters'] = parameters_dict \n",
    "\n",
    "# login to wandb----------------\n",
    "wandb.init(project=\"Astro101_Project_v2\", entity=\"oscarscholin\")\n",
    "\n",
    "# initialize sweep agent\n",
    "sweep_id = wandb.sweep(sweep_config, project='Astro101_Project_v2', entity=\"oscarscholin\")\n",
    "wandb.agent(sweep_id, train, count=100)\n",
    "\n",
    "#train_manual()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aaf8a3611b879056867134183afc22ea709e115b10fb7684e1dbf805b3500c4a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
